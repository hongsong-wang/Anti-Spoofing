<!DOCTYPE html>
<html>
<head>
<title>Paper collected by Wang</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<style type="text/css">


/* BODY
=============================================================================*/

body {
  font-family: Helvetica, arial, freesans, clean, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  color: #333;
  background-color: #fff;
  padding: 20px;
  max-width: 960px;
  margin: 0 auto;
}

span#pid {
  color:red;
  
}
span#filename{
  font-style: oblique;
}

span#title{
  font-family: Times New Roman, freesans, clean, sans-serif;
  font-style: italic;
  font-size: 20px;
  border:1px solid #B50;
}
span#abs{
  font-family: Times New Roman, freesans, clean, sans-serif;
  font-style: oblique;
  font-size: 18px;
}
</style>
</head>
<body>

</p></br></br><div id='section'>Paperid: <span id='pid'>1, <a href='https://arxiv.org/pdf/2510.10663.pdf' target='_blank'>https://arxiv.org/pdf/2510.10663.pdf</a></span>   <span><a href='https://fsfm-3c.github.io/fsvfm.html' target='_blank'>  GitHub</a></span> <span><a href='https://fsfm-3c.github.io/fsvfm.html' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Gaojian Wang, Feng Lin, Tong Wu, Zhisheng Yan, Kui Ren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.10663">Scalable Face Security Vision Foundation Model for Deepfake, Diffusion, and Spoofing Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With abundant, unlabeled real faces, how can we learn robust and transferable facial representations to boost generalization across various face security tasks? We make the first attempt and propose FS-VFM, a scalable self-supervised pre-training framework, to learn fundamental representations of real face images. We introduce three learning objectives, namely 3C, that synergize masked image modeling (MIM) and instance discrimination (ID), empowering FS-VFM to encode both local patterns and global semantics of real faces. Specifically, we formulate various facial masking strategies for MIM and devise a simple yet effective CRFR-P masking, which explicitly prompts the model to pursue meaningful intra-region Consistency and challenging inter-region Coherency. We present a reliable self-distillation mechanism that seamlessly couples MIM with ID to establish underlying local-to-global Correspondence. After pre-training, vanilla vision transformers (ViTs) serve as universal Vision Foundation Models for downstream Face Security tasks: cross-dataset deepfake detection, cross-domain face anti-spoofing, and unseen diffusion facial forensics. To efficiently transfer the pre-trained FS-VFM, we further propose FS-Adapter, a lightweight plug-and-play bottleneck atop the frozen backbone with a novel real-anchor contrastive objective. Extensive experiments on 11 public benchmarks demonstrate that our FS-VFM consistently generalizes better than diverse VFMs, spanning natural and facial domains, fully, weakly, and self-supervised paradigms, small, base, and large ViT scales, and even outperforms SOTA task-specific methods, while FS-Adapter offers an excellent efficiency-performance trade-off. The code and models are available on https://fsfm-3c.github.io/fsvfm.html.
<div id='section'>Paperid: <span id='pid'>2, <a href='https://arxiv.org/pdf/2509.20736.pdf' target='_blank'>https://arxiv.org/pdf/2509.20736.pdf</a></span>   <span><a href='https://github.com/Alphawarheads/Watermark_Spoofing.git' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenshan Zhang, Xueping Zhang, Yechen Wang, Liwei Jin, Ming Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.20736">The Impact of Audio Watermarking on Audio Anti-Spoofing Countermeasures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents the first study on the impact of audio watermarking on spoofing countermeasures. While anti-spoofing systems are essential for securing speech-based applications, the influence of widely used audio watermarking, originally designed for copyright protection, remains largely unexplored. We construct watermark-augmented training and evaluation datasets, named the Watermark-Spoofing dataset, by applying diverse handcrafted and neural watermarking methods to existing anti-spoofing datasets. Experiments show that watermarking consistently degrades anti-spoofing performance, with higher watermark density correlating with higher Equal Error Rates (EERs). To mitigate this, we propose the Knowledge-Preserving Watermark Learning (KPWL) framework, enabling models to adapt to watermark-induced shifts while preserving their original-domain spoofing detection capability. These findings reveal audio watermarking as a previously overlooked domain shift and establish the first benchmark for developing watermark-resilient anti-spoofing systems. All related protocols are publicly available at https://github.com/Alphawarheads/Watermark_Spoofing.git
<div id='section'>Paperid: <span id='pid'>3, <a href='https://arxiv.org/pdf/2509.15804.pdf' target='_blank'>https://arxiv.org/pdf/2509.15804.pdf</a></span>   <span><a href='https://github.com/XuepingZhang/CompSpoof' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xueping Zhang, Liwei Jin, Yechen Wang, Linxi Li, Ming Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.15804">CompSpoof: A Dataset and Joint Learning Framework for Component-Level Audio Anti-spoofing Countermeasures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Component-level audio Spoofing (Comp-Spoof) targets a new form of audio manipulation where only specific components of a signal, such as speech or environmental sound, are forged or substituted while other components remain genuine. Existing anti-spoofing datasets and methods treat an utterance or a segment as entirely bona fide or entirely spoofed, and thus cannot accurately detect component-level spoofing. To address this, we construct a new dataset, CompSpoof, covering multiple combinations of bona fide and spoofed speech and environmental sound. We further propose a separation-enhanced joint learning framework that separates audio components apart and applies anti-spoofing models to each one. Joint learning is employed, preserving information relevant for detection. Extensive experiments demonstrate that our method outperforms the baseline, highlighting the necessity of separate components and the importance of detecting spoofing for each component separately. Datasets and code are available at: https://github.com/XuepingZhang/CompSpoof.
<div id='section'>Paperid: <span id='pid'>4, <a href='https://arxiv.org/pdf/2509.06336.pdf' target='_blank'>https://arxiv.org/pdf/2509.06336.pdf</a></span>   <span><a href='https://github.com/Elune001/MVP-FAS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeongmin Yu, Susang Kim, Kisu Lee, Taekyoung Kwon, Won-Yong Shin, Ha Young Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.06336">Multi-View Slot Attention Using Paraphrased Texts for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent face anti-spoofing (FAS) methods have shown remarkable cross-domain performance by employing vision-language models like CLIP. However, existing CLIP-based FAS models do not fully exploit CLIP's patch embedding tokens, failing to detect critical spoofing clues. Moreover, these models rely on a single text prompt per class (e.g., 'live' or 'fake'), which limits generalization. To address these issues, we propose MVP-FAS, a novel framework incorporating two key modules: Multi-View Slot attention (MVS) and Multi-Text Patch Alignment (MTPA). Both modules utilize multiple paraphrased texts to generate generalized features and reduce dependence on domain-specific text. MVS extracts local detailed spatial features and global context from patch embeddings by leveraging diverse texts with multiple perspectives. MTPA aligns patches with multiple text representations to improve semantic robustness. Extensive experiments demonstrate that MVP-FAS achieves superior generalization performance, outperforming previous state-of-the-art methods on cross-domain datasets. Code: https://github.com/Elune001/MVP-FAS.
<div id='section'>Paperid: <span id='pid'>5, <a href='https://arxiv.org/pdf/2508.14980.pdf' target='_blank'>https://arxiv.org/pdf/2508.14980.pdf</a></span>   <span><a href='https://github.com/xPONYx/iccv2025_deepfake_challenge' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Andrei Balykin, Anvar Ganiev, Denis Kondranin, Kirill Polevoda, Nikolai Liudkevich, Artem Petrov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.14980">Paired-Sampling Contrastive Framework for Joint Physical-Digital Face Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Modern face recognition systems remain vulnerable to spoofing attempts, including both physical presentation attacks and digital forgeries. Traditionally, these two attack vectors have been handled by separate models, each targeting its own artifacts and modalities. However, maintaining distinct detectors increases system complexity and inference latency and leaves systems exposed to combined attack vectors. We propose the Paired-Sampling Contrastive Framework, a unified training approach that leverages automatically matched pairs of genuine and attack selfies to learn modality-agnostic liveness cues. Evaluated on the 6th Face Anti-Spoofing Challenge Unified Physical-Digital Attack Detection benchmark, our method achieves an average classification error rate (ACER) of 2.10 percent, outperforming prior solutions. The framework is lightweight (4.46 GFLOPs) and trains in under one hour, making it practical for real-world deployment. Code and pretrained models are available at https://github.com/xPONYx/iccv2025_deepfake_challenge.
<div id='section'>Paperid: <span id='pid'>6, <a href='https://arxiv.org/pdf/2507.12060.pdf' target='_blank'>https://arxiv.org/pdf/2507.12060.pdf</a></span>   <span><a href='https://kunkunlin1221.github.io/InstructFLIP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kun-Hsiang Lin, Yu-Wen Tseng, Kang-Yang Huang, Jhih-Ciang Wu, Wen-Huang Cheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.12060">InstructFLIP: Exploring Unified Vision-Language Model for Face Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) aims to construct a robust system that can withstand diverse attacks. While recent efforts have concentrated mainly on cross-domain generalization, two significant challenges persist: limited semantic understanding of attack types and training redundancy across domains. We address the first by integrating vision-language models (VLMs) to enhance the perception of visual input. For the second challenge, we employ a meta-domain strategy to learn a unified model that generalizes well across multiple domains. Our proposed InstructFLIP is a novel instruction-tuned framework that leverages VLMs to enhance generalization via textual guidance trained solely on a single domain. At its core, InstructFLIP explicitly decouples instructions into content and style components, where content-based instructions focus on the essential semantics of spoofing, and style-based instructions consider variations related to the environment and camera characteristics. Extensive experiments demonstrate the effectiveness of InstructFLIP by outperforming SOTA models in accuracy and substantially reducing training redundancy across diverse domains in FAS. Project website is available at https://kunkunlin1221.github.io/InstructFLIP.
<div id='section'>Paperid: <span id='pid'>7, <a href='https://arxiv.org/pdf/2507.11777.pdf' target='_blank'>https://arxiv.org/pdf/2507.11777.pdf</a></span>   <span><a href='https://github.com/KORALLLL/AASIST_SCALING' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Ivan Viakhirev, Daniil Sirota, Aleksandr Smirnov, Kirill Borodin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11777">Towards Scalable AASIST: Refining Graph Attention for Speech Deepfake Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advances in voice conversion and text-to-speech synthesis have made automatic speaker verification (ASV) systems more susceptible to spoofing attacks. This work explores modest refinements to the AASIST anti-spoofing architecture. It incorporates a frozen Wav2Vec 2.0 encoder to retain self-supervised speech representations in limited-data settings, substitutes the original graph attention block with a standardized multi-head attention module using heterogeneous query projections, and replaces heuristic frame-segment fusion with a trainable, context-aware integration layer. When evaluated on the ASVspoof 5 corpus, the proposed system reaches a 7.6\% equal error rate (EER), improving on a re-implemented AASIST baseline under the same training conditions. Ablation experiments suggest that each architectural change contributes to the overall performance, indicating that targeted adjustments to established models may help strengthen speech deepfake detection in practical scenarios. The code is publicly available at https://github.com/KORALLLL/AASIST_SCALING.
<div id='section'>Paperid: <span id='pid'>8, <a href='https://arxiv.org/pdf/2507.04006.pdf' target='_blank'>https://arxiv.org/pdf/2507.04006.pdf</a></span>   <span><a href='https://github.com/SeungjinJung/GD-FAS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Seungjin Jung, Kanghee Lee, Yonghyun Jeong, Haeun Noh, Jungmin Lee, Jongwon Choi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.04006">Group-wise Scaling and Orthogonal Decomposition for Domain-Invariant Feature Extraction in Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Domain Generalizable Face Anti-Spoofing (DGFAS) methods effectively capture domain-invariant features by aligning the directions (weights) of local decision boundaries across domains. However, the bias terms associated with these boundaries remain misaligned, leading to inconsistent classification thresholds and degraded performance on unseen target domains. To address this issue, we propose a novel DGFAS framework that jointly aligns weights and biases through Feature Orthogonal Decomposition (FOD) and Group-wise Scaling Risk Minimization (GS-RM). Specifically, GS-RM facilitates bias alignment by balancing group-wise losses across multiple domains. FOD employs the Gram-Schmidt orthogonalization process to decompose the feature space explicitly into domain-invariant and domain-specific subspaces. By enforcing orthogonality between domain-specific and domain-invariant features during training using domain labels, FOD ensures effective weight alignment across domains without negatively impacting bias alignment. Additionally, we introduce Expected Calibration Error (ECE) as a novel evaluation metric for quantitatively assessing the effectiveness of our method in aligning bias terms across domains. Extensive experiments on benchmark datasets demonstrate that our approach achieves state-of-the-art performance, consistently improving accuracy, reducing bias misalignment, and enhancing generalization stability on unseen target domains.
<div id='section'>Paperid: <span id='pid'>9, <a href='https://arxiv.org/pdf/2506.06759.pdf' target='_blank'>https://arxiv.org/pdf/2506.06759.pdf</a></span>   <span><a href='https://github.com/IAB-IITJ/LitMAS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Nidheesh Gorthi, Kartik Thakral, Rishabh Ranjan, Richa Singh, Mayank Vatsa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06759">LitMAS: A Lightweight and Generalized Multi-Modal Anti-Spoofing Framework for Biometric Security</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biometric authentication systems are increasingly being deployed in critical applications, but they remain susceptible to spoofing. Since most of the research efforts focus on modality-specific anti-spoofing techniques, building a unified, resource-efficient solution across multiple biometric modalities remains a challenge. To address this, we propose LitMAS, a $\textbf{Li}$gh$\textbf{t}$ weight and generalizable $\textbf{M}$ulti-modal $\textbf{A}$nti-$\textbf{S}$poofing framework designed to detect spoofing attacks in speech, face, iris, and fingerprint-based biometric systems. At the core of LitMAS is a Modality-Aligned Concentration Loss, which enhances inter-class separability while preserving cross-modal consistency and enabling robust spoof detection across diverse biometric traits. With just 6M parameters, LitMAS surpasses state-of-the-art methods by $1.36\%$ in average EER across seven datasets, demonstrating high efficiency, strong generalizability, and suitability for edge deployment. Code and trained models are available at https://github.com/IAB-IITJ/LitMAS.
<div id='section'>Paperid: <span id='pid'>10, <a href='https://arxiv.org/pdf/2505.24402.pdf' target='_blank'>https://arxiv.org/pdf/2505.24402.pdf</a></span>   <span><a href='https://gsisaoki.github.io/FAS-ViT-CVPRW/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Mika Feng, Koichi Ito, Takafumi Aoki, Tetsushi Ohki, Masakatsu Nishigaki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.24402">Leveraging Intermediate Features of Vision Transformer for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition systems are designed to be robust against changes in head pose, illumination, and blurring during image capture. If a malicious person presents a face photo of the registered user, they may bypass the authentication process illegally. Such spoofing attacks need to be detected before face recognition. In this paper, we propose a spoofing attack detection method based on Vision Transformer (ViT) to detect minute differences between live and spoofed face images. The proposed method utilizes the intermediate features of ViT, which have a good balance between local and global features that are important for spoofing attack detection, for calculating loss in training and score in inference. The proposed method also introduces two data augmentation methods: face anti-spoofing data augmentation and patch-wise data augmentation, to improve the accuracy of spoofing attack detection. We demonstrate the effectiveness of the proposed method through experiments using the OULU-NPU and SiW datasets. The project page is available at: https://gsisaoki.github.io/FAS-ViT-CVPRW/ .
<div id='section'>Paperid: <span id='pid'>11, <a href='https://arxiv.org/pdf/2505.23962.pdf' target='_blank'>https://arxiv.org/pdf/2505.23962.pdf</a></span>   <span><a href='https://emospoof-tts.github.io/Dataset/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Aurosweta Mahapatra, Ismail Rasim Ulgen, Abinay Reddy Naini, Carlos Busso, Berrak Sisman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.23962">Can Emotion Fool Anti-spoofing?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Traditional anti-spoofing focuses on models and datasets built on synthetic speech with mostly neutral state, neglecting diverse emotional variations. As a result, their robustness against high-quality, emotionally expressive synthetic speech is uncertain. We address this by introducing EmoSpoof-TTS, a corpus of emotional text-to-speech samples. Our analysis shows existing anti-spoofing models struggle with emotional synthetic speech, exposing risks of emotion-targeted attacks. Even trained on emotional data, the models underperform due to limited focus on emotional aspect and show performance disparities across emotions. This highlights the need for emotion-focused anti-spoofing paradigm in both dataset and methodology. We propose GEM, a gated ensemble of emotion-specialized models with a speech emotion recognition gating network. GEM performs effectively across all emotions and neutral state, improving defenses against spoofing attacks. We release the EmoSpoof-TTS Dataset: https://emospoof-tts.github.io/Dataset/
<div id='section'>Paperid: <span id='pid'>12, <a href='https://arxiv.org/pdf/2504.05657.pdf' target='_blank'>https://arxiv.org/pdf/2504.05657.pdf</a></span>   <span><a href='https://github.com/Liu-Tianchi/Nes2Net' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianchi Liu, Duc-Tuan Truong, Rohan Kumar Das, Kong Aik Lee, Haizhou Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.05657">Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven Speech Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Speech foundation models have significantly advanced various speech-related tasks by providing exceptional representation capabilities. However, their high-dimensional output features often create a mismatch with downstream task models, which typically require lower-dimensional inputs. A common solution is to apply a dimensionality reduction (DR) layer, but this approach increases parameter overhead, computational costs, and risks losing valuable information. To address these issues, we propose Nested Res2Net (Nes2Net), a lightweight back-end architecture designed to directly process high-dimensional features without DR layers. The nested structure enhances multi-scale feature extraction, improves feature interaction, and preserves high-dimensional information. We first validate Nes2Net on CtrSVDD, a singing voice deepfake detection dataset, and report a 22% performance improvement and an 87% back-end computational cost reduction over the state-of-the-art baseline. Additionally, extensive testing across four diverse datasets: ASVspoof 2021, ASVspoof 5, PartialSpoof, and In-the-Wild, covering fully spoofed speech, adversarial attacks, partial spoofing, and real-world scenarios, consistently highlights Nes2Net's superior robustness and generalization capabilities. The code package and pre-trained models are available at https://github.com/Liu-Tianchi/Nes2Net.
<div id='section'>Paperid: <span id='pid'>13, <a href='https://arxiv.org/pdf/2504.02272.pdf' target='_blank'>https://arxiv.org/pdf/2504.02272.pdf</a></span>   <span><a href='https://github.com/longshaocong/GCDG' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Shaocong Long, Qianyu Zhou, Xiangtai Li, Chenhao Ying, Yunhai Tong, Lizhuang Ma, Yuan Luo, Dacheng Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.02272">Generative Classifier for Domain Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Domain generalization (DG) aims to improve the generalizability of computer vision models toward distribution shifts. The mainstream DG methods focus on learning domain invariance, however, such methods overlook the potential inherent in domain-specific information. While the prevailing practice of discriminative linear classifier has been tailored to domain-invariant features, it struggles when confronted with diverse domain-specific information, e.g., intra-class shifts, that exhibits multi-modality. To address these issues, we explore the theoretical implications of relying on domain invariance, revealing the crucial role of domain-specific information in mitigating the target risk for DG. Drawing from these insights, we propose Generative Classifier-driven Domain Generalization (GCDG), introducing a generative paradigm for the DG classifier based on Gaussian Mixture Models (GMMs) for each class across domains. GCDG consists of three key modules: Heterogeneity Learning Classifier~(HLC), Spurious Correlation Blocking~(SCB), and Diverse Component Balancing~(DCB). Concretely, HLC attempts to model the feature distributions and thereby capture valuable domain-specific information via GMMs. SCB identifies the neural units containing spurious correlations and perturbs them, mitigating the risk of HLC learning spurious patterns. Meanwhile, DCB ensures a balanced contribution of components in HLC, preventing the underestimation or neglect of critical components. In this way, GCDG excels in capturing the nuances of domain-specific information characterized by diverse distributions. GCDG demonstrates the potential to reduce the target risk and encourage flat minima, improving the generalizability. Extensive experiments show GCDG's comparable performance on five DG benchmarks and one face anti-spoofing dataset, seamlessly integrating into existing DG methods with consistent improvements.
<div id='section'>Paperid: <span id='pid'>14, <a href='https://arxiv.org/pdf/2503.00429.pdf' target='_blank'>https://arxiv.org/pdf/2503.00429.pdf</a></span>   <span><a href='https://github.com/yjyddq/DADM' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingyi Yang, Xun Lin, Zitong Yu, Liepiao Zhang, Xin Liu, Hui Li, Xiaochen Yuan, Xiaochun Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00429">DADM: Dual Alignment of Domain and Modality for Face Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the availability of diverse sensor modalities (i.e., RGB, Depth, Infrared) and the success of multi-modal learning, multi-modal face anti-spoofing (FAS) has emerged as a prominent research focus. The intuition behind it is that leveraging multiple modalities can uncover more intrinsic spoofing traces. However, this approach presents more risk of misalignment. We identify two main types of misalignment: (1) \textbf{Intra-domain modality misalignment}, where the importance of each modality varies across different attacks. For instance, certain modalities (e.g., Depth) may be non-defensive against specific attacks (e.g., 3D mask), indicating that each modality has unique strengths and weaknesses in countering particular attacks. Consequently, simple fusion strategies may fall short. (2) \textbf{Inter-domain modality misalignment}, where the introduction of additional modalities exacerbates domain shifts, potentially overshadowing the benefits of complementary fusion. To tackle (1), we propose a alignment module between modalities based on mutual information, which adaptively enhances favorable modalities while suppressing unfavorable ones. To address (2), we employ a dual alignment optimization method that aligns both sub-domain hyperplanes and modality angle margins, thereby mitigating domain gaps. Our method, dubbed \textbf{D}ual \textbf{A}lignment of \textbf{D}omain and \textbf{M}odality (DADM), achieves state-of-the-art performance in extensive experiments across four challenging protocols demonstrating its robustness in multi-modal domain generalization scenarios. The codes will be released soon.
<div id='section'>Paperid: <span id='pid'>15, <a href='https://arxiv.org/pdf/2501.02892.pdf' target='_blank'>https://arxiv.org/pdf/2501.02892.pdf</a></span>   <span><a href='https://github.com/gurayozgur/FoundPAD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Guray Ozgur, Eduarda Caldeira, Tahar Chettaoui, Fadi Boutros, Raghavendra Ramachandra, Naser Damer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.02892">FoundPAD: Foundation Models Reloaded for Face Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although face recognition systems have seen a massive performance enhancement in recent years, they are still targeted by threats such as presentation attacks, leading to the need for generalizable presentation attack detection (PAD) algorithms. Current PAD solutions suffer from two main problems: low generalization to unknown cenarios and large training data requirements. Foundation models (FM) are pre-trained on extensive datasets, achieving remarkable results when generalizing to unseen domains and allowing for efficient task-specific adaption even when little training data are available. In this work, we recognize the potential of FMs to address common PAD problems and tackle the PAD task with an adapted FM for the first time. The FM under consideration is adapted with LoRA weights while simultaneously training a classification header. The resultant architecture, FoundPAD, is highly generalizable to unseen domains, achieving competitive results in several settings under different data availability scenarios and even when using synthetic training data. To encourage reproducibility and facilitate further research in PAD, we publicly release the implementation of FoundPAD at https://github.com/gurayozgur/FoundPAD .
<div id='section'>Paperid: <span id='pid'>16, <a href='https://arxiv.org/pdf/2412.18065.pdf' target='_blank'>https://arxiv.org/pdf/2412.18065.pdf</a></span>   <span><a href='https://github.com/murInJ/BIG-MoE' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingjie Ma, Zitong Yu, Xun Lin, Weicheng Xie, Linlin Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.18065">BIG-MoE: Bypass Isolated Gating MoE for Generalized Multimodal Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the domain of facial recognition security, multimodal Face Anti-Spoofing (FAS) is essential for countering presentation attacks. However, existing technologies encounter challenges due to modality biases and imbalances, as well as domain shifts. Our research introduces a Mixture of Experts (MoE) model to address these issues effectively. We identified three limitations in traditional MoE approaches to multimodal FAS: (1) Coarse-grained experts' inability to capture nuanced spoofing indicators; (2) Gated networks' susceptibility to input noise affecting decision-making; (3) MoE's sensitivity to prompt tokens leading to overfitting with conventional learning methods. To mitigate these, we propose the Bypass Isolated Gating MoE (BIG-MoE) framework, featuring: (1) Fine-grained experts for enhanced detection of subtle spoofing cues; (2) An isolation gating mechanism to counteract input noise; (3) A novel differential convolutional prompt bypass enriching the gating network with critical local features, thereby improving perceptual capabilities. Extensive experiments on four benchmark datasets demonstrate significant generalization performance improvement in multimodal FAS task. The code is released at https://github.com/murInJ/BIG-MoE.
<div id='section'>Paperid: <span id='pid'>17, <a href='https://arxiv.org/pdf/2412.07199.pdf' target='_blank'>https://arxiv.org/pdf/2412.07199.pdf</a></span>   <span><a href='https://github.com/iPRoBe-lab/ADV-GEN-IrisPAD' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Debasmita Pal, Redwan Sony, Arun Ross
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.07199">A Parametric Approach to Adversarial Augmentation for Cross-Domain Iris Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Iris-based biometric systems are vulnerable to presentation attacks (PAs), where adversaries present physical artifacts (e.g., printed iris images, textured contact lenses) to defeat the system. This has led to the development of various presentation attack detection (PAD) algorithms, which typically perform well in intra-domain settings. However, they often struggle to generalize effectively in cross-domain scenarios, where training and testing employ different sensors, PA instruments, and datasets. In this work, we use adversarial training samples of both bonafide irides and PAs to improve the cross-domain performance of a PAD classifier. The novelty of our approach lies in leveraging transformation parameters from classical data augmentation schemes (e.g., translation, rotation) to generate adversarial samples. We achieve this through a convolutional autoencoder, ADV-GEN, that inputs original training samples along with a set of geometric and photometric transformations. The transformation parameters act as regularization variables, guiding ADV-GEN to generate adversarial samples in a constrained search space. Experiments conducted on the LivDet-Iris 2017 database, comprising four datasets, and the LivDet-Iris 2020 dataset, demonstrate the efficacy of our proposed method. The code is available at https://github.com/iPRoBe-lab/ADV-GEN-IrisPAD.
<div id='section'>Paperid: <span id='pid'>18, <a href='https://arxiv.org/pdf/2410.02693.pdf' target='_blank'>https://arxiv.org/pdf/2410.02693.pdf</a></span>   <span><a href='https://github.com/eth-sri/watermark-spoofing-detection' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Thibaud Gloaguen, Nikola JovanoviÄ, Robin Staab, Martin Vechev
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.02693">Discovering Spoofing Attempts on Language Model Watermarks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>LLM watermarks stand out as a promising way to attribute ownership of LLM-generated text. One threat to watermark credibility comes from spoofing attacks, where an unauthorized third party forges the watermark, enabling it to falsely attribute arbitrary texts to a particular LLM. Despite recent work demonstrating that state-of-the-art schemes are, in fact, vulnerable to spoofing, no prior work has focused on post-hoc methods to discover spoofing attempts. In this work, we for the first time propose a reliable statistical method to distinguish spoofed from genuinely watermarked text, suggesting that current spoofing attacks are less effective than previously thought. In particular, we show that regardless of their underlying approach, all current learning-based spoofing methods consistently leave observable artifacts in spoofed texts, indicative of watermark forgery. We build upon these findings to propose rigorous statistical tests that reliably reveal the presence of such artifacts and thus demonstrate that a watermark has been spoofed. Our experimental evaluation shows high test power across all learning-based spoofing methods, providing insights into their fundamental limitations and suggesting a way to mitigate this threat. We make all our code available at https://github.com/eth-sri/watermark-spoofing-detection .
<div id='section'>Paperid: <span id='pid'>19, <a href='https://arxiv.org/pdf/2409.16945.pdf' target='_blank'>https://arxiv.org/pdf/2409.16945.pdf</a></span>   <span><a href='https://github.com/zhenglab/FFDBackbone' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zonghui Guo, Yingjie Liu, Jie Zhang, Haiyong Zheng, Shiguang Shan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.16945">Face Forgery Detection with Elaborate Backbone</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face Forgery Detection (FFD), or Deepfake detection, aims to determine whether a digital face is real or fake. Due to different face synthesis algorithms with diverse forgery patterns, FFD models often overfit specific patterns in training datasets, resulting in poor generalization to other unseen forgeries. This severe challenge requires FFD models to possess strong capabilities in representing complex facial features and extracting subtle forgery cues. Although previous FFD models directly employ existing backbones to represent and extract facial forgery cues, the critical role of backbones is often overlooked, particularly as their knowledge and capabilities are insufficient to address FFD challenges, inevitably limiting generalization. Therefore, it is essential to integrate the backbone pre-training configurations and seek practical solutions by revisiting the complete FFD workflow, from backbone pre-training and fine-tuning to inference of discriminant results. Specifically, we analyze the crucial contributions of backbones with different configurations in FFD task and propose leveraging the ViT network with self-supervised learning on real-face datasets to pre-train a backbone, equipping it with superior facial representation capabilities. We then build a competitive backbone fine-tuning framework that strengthens the backbone's ability to extract diverse forgery cues within a competitive learning mechanism. Moreover, we devise a threshold optimization mechanism that utilizes prediction confidence to improve the inference reliability. Comprehensive experiments demonstrate that our FFD model with the elaborate backbone achieves excellent performance in FFD and extra face-related tasks, i.e., presentation attack detection. Code and models are available at https://github.com/zhenglab/FFDBackbone.
<div id='section'>Paperid: <span id='pid'>20, <a href='https://arxiv.org/pdf/2409.08572.pdf' target='_blank'>https://arxiv.org/pdf/2409.08572.pdf</a></span>   <span><a href='https://github.com/murphytju/DiffFAS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xinxu Ge, Xin Liu, Zitong Yu, Jingang Shi, Chun Qi, Jie Li, Heikki KÃ¤lviÃ¤inen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08572">DiffFAS: Face Anti-Spoofing via Generative Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) plays a vital role in preventing face recognition (FR) systems from presentation attacks. Nowadays, FAS systems face the challenge of domain shift, impacting the generalization performance of existing FAS methods. In this paper, we rethink about the inherence of domain shift and deconstruct it into two factors: image style and image quality. Quality influences the purity of the presentation of spoof information, while style affects the manner in which spoof information is presented. Based on our analysis, we propose DiffFAS framework, which quantifies quality as prior information input into the network to counter image quality shift, and performs diffusion-based high-fidelity cross-domain and cross-attack types generation to counter image style shift. DiffFAS transforms easily collectible live faces into high-fidelity attack faces with precise labels while maintaining consistency between live and spoof face identities, which can also alleviate the scarcity of labeled data with novel type attacks faced by nowadays FAS system. We demonstrate the effectiveness of our framework on challenging cross-domain and cross-attack FAS datasets, achieving the state-of-the-art performance. Available at https://github.com/murphytju/DiffFAS.
<div id='section'>Paperid: <span id='pid'>21, <a href='https://arxiv.org/pdf/2409.03501.pdf' target='_blank'>https://arxiv.org/pdf/2409.03501.pdf</a></span>   <span><a href='https://github.com/RizhaoCai/FAS_Aug' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Rizhao Cai, Cecelia Soh, Zitong Yu, Haoliang Li, Wenhan Yang, Alex Kot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.03501">Towards Data-Centric Face Anti-Spoofing: Improving Cross-domain Generalization via Physics-based Data Synthesis</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face Anti-Spoofing (FAS) research is challenged by the cross-domain problem, where there is a domain gap between the training and testing data. While recent FAS works are mainly model-centric, focusing on developing domain generalization algorithms for improving cross-domain performance, data-centric research for face anti-spoofing, improving generalization from data quality and quantity, is largely ignored. Therefore, our work starts with data-centric FAS by conducting a comprehensive investigation from the data perspective for improving cross-domain generalization of FAS models. More specifically, at first, based on physical procedures of capturing and recapturing, we propose task-specific FAS data augmentation (FAS-Aug), which increases data diversity by synthesizing data of artifacts, such as printing noise, color distortion, moirÃ© pattern, \textit{etc}. Our experiments show that using our FAS augmentation can surpass traditional image augmentation in training FAS models to achieve better cross-domain performance. Nevertheless, we observe that models may rely on the augmented artifacts, which are not environment-invariant, and using FAS-Aug may have a negative effect. As such, we propose Spoofing Attack Risk Equalization (SARE) to prevent models from relying on certain types of artifacts and improve the generalization performance. Last but not least, our proposed FAS-Aug and SARE with recent Vision Transformer backbones can achieve state-of-the-art performance on the FAS cross-domain generalization protocols. The implementation is available at https://github.com/RizhaoCai/FAS_Aug.
<div id='section'>Paperid: <span id='pid'>22, <a href='https://arxiv.org/pdf/2409.02302.pdf' target='_blank'>https://arxiv.org/pdf/2409.02302.pdf</a></span>   <span><a href='https://github.com/Anmol2059/SVDD2024' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Anmol Guragain, Tianchi Liu, Zihan Pan, Hardik B. Sailor, Qiongqiong Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.02302">Speech Foundation Model Ensembles for the Controlled Singing Voice Deepfake Detection (CtrSVDD) Challenge 2024</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work details our approach to achieving a leading system with a 1.79% pooled equal error rate (EER) on the evaluation set of the Controlled Singing Voice Deepfake Detection (CtrSVDD). The rapid advancement of generative AI models presents significant challenges for detecting AI-generated deepfake singing voices, attracting increased research attention. The Singing Voice Deepfake Detection (SVDD) Challenge 2024 aims to address this complex task. In this work, we explore the ensemble methods, utilizing speech foundation models to develop robust singing voice anti-spoofing systems. We also introduce a novel Squeeze-and-Excitation Aggregation (SEA) method, which efficiently and effectively integrates representation features from the speech foundation models, surpassing the performance of our other individual systems. Evaluation results confirm the efficacy of our approach in detecting deepfake singing voices. The codes can be accessed at https://github.com/Anmol2059/SVDD2024.
<div id='section'>Paperid: <span id='pid'>23, <a href='https://arxiv.org/pdf/2404.14406.pdf' target='_blank'>https://arxiv.org/pdf/2404.14406.pdf</a></span>   <span><a href='https://kartik-3004.github.io/hyp-oc/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Kartik Narayan, Vishal M. Patel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.14406">Hyp-OC: Hyperbolic One Class Classification for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition technology has become an integral part of modern security systems and user authentication processes. However, these systems are vulnerable to spoofing attacks and can easily be circumvented. Most prior research in face anti-spoofing (FAS) approaches it as a two-class classification task where models are trained on real samples and known spoof attacks and tested for detection performance on unknown spoof attacks. However, in practice, FAS should be treated as a one-class classification task where, while training, one cannot assume any knowledge regarding the spoof samples a priori. In this paper, we reformulate the face anti-spoofing task from a one-class perspective and propose a novel hyperbolic one-class classification framework. To train our network, we use a pseudo-negative class sampled from the Gaussian distribution with a weighted running mean and propose two novel loss functions: (1) Hyp-PC: Hyperbolic Pairwise Confusion loss, and (2) Hyp-CE: Hyperbolic Cross Entropy loss, which operate in the hyperbolic space. Additionally, we employ Euclidean feature clipping and gradient clipping to stabilize the training in the hyperbolic space. To the best of our knowledge, this is the first work extending hyperbolic embeddings for face anti-spoofing in a one-class manner. With extensive experiments on five benchmark datasets: Rose-Youtu, MSU-MFSD, CASIA-MFSD, Idiap Replay-Attack, and OULU-NPU, we demonstrate that our method significantly outperforms the state-of-the-art, achieving better spoof detection performance.
<div id='section'>Paperid: <span id='pid'>24, <a href='https://arxiv.org/pdf/2404.12602.pdf' target='_blank'>https://arxiv.org/pdf/2404.12602.pdf</a></span>   <span><a href='https://github.com/SeaRecluse/CVPRW2024' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Minzhe Huang, Changwei Nie, Weihong Zhong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.12602">A visualization method for data domain changes in CNN networks and the optimization method for selecting thresholds in classification tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In recent years, Face Anti-Spoofing (FAS) has played a crucial role in preserving the security of face recognition technology. With the rise of counterfeit face generation techniques, the challenge posed by digitally edited faces to face anti-spoofing is escalating. Existing FAS technologies primarily focus on intercepting physically forged faces and lack a robust solution for cross-domain FAS challenges. Moreover, determining an appropriate threshold to achieve optimal deployment results remains an issue for intra-domain FAS. To address these issues, we propose a visualization method that intuitively reflects the training outcomes of models by visualizing the prediction results on datasets. Additionally, we demonstrate that employing data augmentation techniques, such as downsampling and Gaussian blur, can effectively enhance performance on cross-domain tasks. Building upon our data visualization approach, we also introduce a methodology for setting threshold values based on the distribution of the training dataset. Ultimately, our methods secured us second place in both the Unified Physical-Digital Face Attack Detection competition and the Snapshot Spectral Imaging Face Anti-spoofing contest. The training code is available at https://github.com/SeaRecluse/CVPRW2024.
<div id='section'>Paperid: <span id='pid'>25, <a href='https://arxiv.org/pdf/2404.08450.pdf' target='_blank'>https://arxiv.org/pdf/2404.08450.pdf</a></span>   <span><a href='https://github.com/Xianhua-He/cvpr2024-face-anti-spoofing-challenge' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xianhua He, Dashuang Liang, Song Yang, Zhanlong Hao, Hui Ma, Binjie Mao, Xi Li, Yao Wang, Pengfei Yan, Ajian Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.08450">Joint Physical-Digital Facial Attack Detection Via Simulating Spoofing Clues</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition systems are frequently subjected to a variety of physical and digital attacks of different types. Previous methods have achieved satisfactory performance in scenarios that address physical attacks and digital attacks, respectively. However, few methods are considered to integrate a model that simultaneously addresses both physical and digital attacks, implying the necessity to develop and maintain multiple models. To jointly detect physical and digital attacks within a single model, we propose an innovative approach that can adapt to any network architecture. Our approach mainly contains two types of data augmentation, which we call Simulated Physical Spoofing Clues augmentation (SPSC) and Simulated Digital Spoofing Clues augmentation (SDSC). SPSC and SDSC augment live samples into simulated attack samples by simulating spoofing clues of physical and digital attacks, respectively, which significantly improve the capability of the model to detect "unseen" attack types. Extensive experiments show that SPSC and SDSC can achieve state-of-the-art generalization in Protocols 2.1 and 2.2 of the UniAttackData dataset, respectively. Our method won first place in "Unified Physical-Digital Face Attack Detection" of the 5th Face Anti-spoofing Challenge@CVPR2024. Our final submission obtains 3.75% APCER, 0.93% BPCER, and 2.34% ACER, respectively. Our code is available at https://github.com/Xianhua-He/cvpr2024-face-anti-spoofing-challenge.
<div id='section'>Paperid: <span id='pid'>26, <a href='https://arxiv.org/pdf/2404.06483.pdf' target='_blank'>https://arxiv.org/pdf/2404.06483.pdf</a></span>   <span><a href='https://github.com/zizheng-guo/RhythmMamba' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Bochao Zou, Zizheng Guo, Xiaocheng Hu, Huimin Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06483">RhythmMamba: Fast, Lightweight, and Accurate Remote Physiological Measurement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Remote photoplethysmography (rPPG) is a method for non-contact measurement of physiological signals from facial videos, holding great potential in various applications such as healthcare, affective computing, and anti-spoofing. Existing deep learning methods struggle to address two core issues of rPPG simultaneously: understanding the periodic pattern of rPPG among long contexts and addressing large spatiotemporal redundancy in video segments. These represent a trade-off between computational complexity and the ability to capture long-range dependencies. In this paper, we introduce RhythmMamba, a state space model-based method that captures long-range dependencies while maintaining linear complexity. By viewing rPPG as a time series task through the proposed frame stem, the periodic variations in pulse waves are modeled as state transitions. Additionally, we design multi-temporal constraint and frequency domain feed-forward, both aligned with the characteristics of rPPG time series, to improve the learning capacity of Mamba for rPPG signals. Extensive experiments show that RhythmMamba achieves state-of-the-art performance with 319% throughput and 23% peak GPU memory. The codes are available at https://github.com/zizheng-guo/RhythmMamba.
<div id='section'>Paperid: <span id='pid'>27, <a href='https://arxiv.org/pdf/2402.19298.pdf' target='_blank'>https://arxiv.org/pdf/2402.19298.pdf</a></span>   <span><a href='https://github.com/OMGGGGG/mmdg' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Xun Lin, Shuai Wang, Rizhao Cai, Yizhong Liu, Ying Fu, Zitong Yu, Wenzhong Tang, Alex Kot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.19298">Suppress and Rebalance: Towards Generalized Multi-Modal Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face Anti-Spoofing (FAS) is crucial for securing face recognition systems against presentation attacks. With advancements in sensor manufacture and multi-modal learning techniques, many multi-modal FAS approaches have emerged. However, they face challenges in generalizing to unseen attacks and deployment conditions. These challenges arise from (1) modality unreliability, where some modality sensors like depth and infrared undergo significant domain shifts in varying environments, leading to the spread of unreliable information during cross-modal feature fusion, and (2) modality imbalance, where training overly relies on a dominant modality hinders the convergence of others, reducing effectiveness against attack types that are indistinguishable sorely using the dominant modality. To address modality unreliability, we propose the Uncertainty-Guided Cross-Adapter (U-Adapter) to recognize unreliably detected regions within each modality and suppress the impact of unreliable regions on other modalities. For modality imbalance, we propose a Rebalanced Modality Gradient Modulation (ReGrad) strategy to rebalance the convergence speed of all modalities by adaptively adjusting their gradients. Besides, we provide the first large-scale benchmark for evaluating multi-modal FAS performance under domain generalization scenarios. Extensive experiments demonstrate that our method outperforms state-of-the-art methods. Source code and protocols will be released on https://github.com/OMGGGGG/mmdg.
<div id='section'>Paperid: <span id='pid'>28, <a href='https://arxiv.org/pdf/2402.18817.pdf' target='_blank'>https://arxiv.org/pdf/2402.18817.pdf</a></span>   <span><a href='https://github.com/leminhbinh0209/CVPR24-FAS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Binh M. Le, Simon S. Woo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.18817">Gradient Alignment for Cross-Domain Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in domain generalization (DG) for face anti-spoofing (FAS) have garnered considerable attention. Traditional methods have focused on designing learning objectives and additional modules to isolate domain-specific features while retaining domain-invariant characteristics in their representations. However, such approaches often lack guarantees of consistent maintenance of domain-invariant features or the complete removal of domain-specific features. Furthermore, most prior works of DG for FAS do not ensure convergence to a local flat minimum, which has been shown to be advantageous for DG. In this paper, we introduce GAC-FAS, a novel learning objective that encourages the model to converge towards an optimal flat minimum without necessitating additional learning modules. Unlike conventional sharpness-aware minimizers, GAC-FAS identifies ascending points for each domain and regulates the generalization gradient updates at these points to align coherently with empirical risk minimization (ERM) gradient updates. This unique approach specifically guides the model to be robust against domain shifts. We demonstrate the efficacy of GAC-FAS through rigorous testing on challenging cross-domain FAS datasets, where it establishes state-of-the-art performance. The code is available at https://github.com/leminhbinh0209/CVPR24-FAS.
<div id='section'>Paperid: <span id='pid'>29, <a href='https://arxiv.org/pdf/2311.12764.pdf' target='_blank'>https://arxiv.org/pdf/2311.12764.pdf</a></span>   <span><a href='https://github.com/redwankarimsony/WeightPerturbation-MSU' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Renu Sharma, Redwan Sony, Arun Ross
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.12764">Investigating Weight-Perturbed Deep Neural Networks With Application in Iris Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Deep neural networks (DNNs) exhibit superior performance in various machine learning tasks, e.g., image classification, speech recognition, biometric recognition, object detection, etc. However, it is essential to analyze their sensitivity to parameter perturbations before deploying them in real-world applications. In this work, we assess the sensitivity of DNNs against perturbations to their weight and bias parameters. The sensitivity analysis involves three DNN architectures (VGG, ResNet, and DenseNet), three types of parameter perturbations (Gaussian noise, weight zeroing, and weight scaling), and two settings (entire network and layer-wise). We perform experiments in the context of iris presentation attack detection and evaluate on two publicly available datasets: LivDet-Iris-2017 and LivDet-Iris-2020. Based on the sensitivity analysis, we propose improved models simply by perturbing parameters of the network without undergoing training. We further combine these perturbed models at the score-level and at the parameter-level to improve the performance over the original model. The ensemble at the parameter-level shows an average improvement of 43.58% on the LivDet-Iris-2017 dataset and 9.25% on the LivDet-Iris-2020 dataset. The source code is available at https://github.com/redwankarimsony/WeightPerturbation-MSU.
<div id='section'>Paperid: <span id='pid'>30, <a href='https://arxiv.org/pdf/2309.16649.pdf' target='_blank'>https://arxiv.org/pdf/2309.16649.pdf</a></span>   <span><a href='https://koushiksrivats.github.io/FLIP/' target='_blank'>  GitHub</a></span> <span><a href='https://github.com/koushiksrivats/FLIP' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Koushik Srivatsan, Muzammal Naseer, Karthik Nandakumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16649">FLIP: Cross-domain Face Anti-spoofing with Language Guidance</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) or presentation attack detection is an essential component of face recognition systems deployed in security-critical applications. Existing FAS methods have poor generalizability to unseen spoof types, camera sensors, and environmental conditions. Recently, vision transformer (ViT) models have been shown to be effective for the FAS task due to their ability to capture long-range dependencies among image patches. However, adaptive modules or auxiliary loss functions are often required to adapt pre-trained ViT weights learned on large-scale datasets such as ImageNet. In this work, we first show that initializing ViTs with multimodal (e.g., CLIP) pre-trained weights improves generalizability for the FAS task, which is in line with the zero-shot transfer capabilities of vision-language pre-trained (VLP) models. We then propose a novel approach for robust cross-domain FAS by grounding visual representations with the help of natural language. Specifically, we show that aligning the image representation with an ensemble of class descriptions (based on natural language semantics) improves FAS generalizability in low-data regimes. Finally, we propose a multimodal contrastive learning strategy to boost feature generalization further and bridge the gap between source and target domains. Extensive experiments on three standard protocols demonstrate that our method significantly outperforms the state-of-the-art methods, achieving better zero-shot transfer performance than five-shot transfer of adaptive ViTs. Code: https://github.com/koushiksrivats/FLIP
<div id='section'>Paperid: <span id='pid'>31, <a href='https://arxiv.org/pdf/2309.12237.pdf' target='_blank'>https://arxiv.org/pdf/2309.12237.pdf</a></span>   <span><a href='https://github.com/TakHemlata/T-EER' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Tomi Kinnunen, Kong Aik Lee, Hemlata Tak, Nicholas Evans, Andreas Nautsch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.12237">t-EER: Parameter-Free Tandem Evaluation of Countermeasures and Biometric Comparators</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Presentation attack (spoofing) detection (PAD) typically operates alongside biometric verification to improve reliablity in the face of spoofing attacks. Even though the two sub-systems operate in tandem to solve the single task of reliable biometric verification, they address different detection tasks and are hence typically evaluated separately. Evidence shows that this approach is suboptimal. We introduce a new metric for the joint evaluation of PAD solutions operating in situ with biometric verification. In contrast to the tandem detection cost function proposed recently, the new tandem equal error rate (t-EER) is parameter free. The combination of two classifiers nonetheless leads to a \emph{set} of operating points at which false alarm and miss rates are equal and also dependent upon the prevalence of attacks. We therefore introduce the \emph{concurrent} t-EER, a unique operating point which is invariable to the prevalence of attacks. Using both modality (and even application) agnostic simulated scores, as well as real scores for a voice biometrics application, we demonstrate application of the t-EER to a wide range of biometric system evaluations under attack. The proposed approach is a strong candidate metric for the tandem evaluation of PAD systems and biometric comparators.
<div id='section'>Paperid: <span id='pid'>32, <a href='https://arxiv.org/pdf/2308.15346.pdf' target='_blank'>https://arxiv.org/pdf/2308.15346.pdf</a></span>   <span><a href='https://github.com/Chaochao-Lin/ATR-FAS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Weihua Liu, Chaochao Lin, Yu Yan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.15346">Enhancing Mobile Face Anti-Spoofing: A Robust Framework for Diverse Attack Types under Screen Flash</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) is crucial for securing face recognition systems. However, existing FAS methods with handcrafted binary or pixel-wise labels have limitations due to diverse presentation attacks (PAs). In this paper, we propose an attack type robust face anti-spoofing framework under light flash, called ATR-FAS. Due to imaging differences caused by various attack types, traditional FAS methods based on single binary classification network may result in excessive intra-class distance of spoof faces, leading to a challenge of decision boundary learning. Therefore, we employed multiple networks to reconstruct multi-frame depth maps as auxiliary supervision, and each network experts in one type of attack. A dual gate module (DGM) consisting of a type gate and a frame-attention gate is introduced, which perform attack type recognition and multi-frame attention generation, respectively. The outputs of DGM are utilized as weight to mix the result of multiple expert networks. The multi-experts mixture enables ATR-FAS to generate spoof-differentiated depth maps, and stably detects spoof faces without being affected by different types of PAs. Moreover, we design a differential normalization procedure to convert original flash frames into differential frames. This simple but effective processing enhances the details in flash frames, aiding in the generation of depth maps. To verify the effectiveness of our framework, we collected a large-scale dataset containing 12,660 live and spoof videos with diverse PAs under dynamic flash from the smartphone screen. Extensive experiments illustrate that the proposed ATR-FAS significantly outperforms existing state-of-the-art methods. The code and dataset will be available at https://github.com/Chaochao-Lin/ATR-FAS.
<div id='section'>Paperid: <span id='pid'>33, <a href='https://arxiv.org/pdf/2308.10236.pdf' target='_blank'>https://arxiv.org/pdf/2308.10236.pdf</a></span>   <span><a href='https://github.com/Naiftt/FedSIS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Naif Alkhunaizi, Koushik Srivatsan, Faris Almalik, Ibrahim Almakky, Karthik Nandakumar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.10236">FedSIS: Federated Split Learning with Intermediate Representation Sampling for Privacy-preserving Generalized Face Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Lack of generalization to unseen domains/attacks is the Achilles heel of most face presentation attack detection (FacePAD) algorithms. Existing attempts to enhance the generalizability of FacePAD solutions assume that data from multiple source domains are available with a single entity to enable centralized training. In practice, data from different source domains may be collected by diverse entities, who are often unable to share their data due to legal and privacy constraints. While collaborative learning paradigms such as federated learning (FL) can overcome this problem, standard FL methods are ill-suited for domain generalization because they struggle to surmount the twin challenges of handling non-iid client data distributions during training and generalizing to unseen domains during inference. In this work, a novel framework called Federated Split learning with Intermediate representation Sampling (FedSIS) is introduced for privacy-preserving domain generalization. In FedSIS, a hybrid Vision Transformer (ViT) architecture is learned using a combination of FL and split learning to achieve robustness against statistical heterogeneity in the client data distributions without any sharing of raw data (thereby preserving privacy). To further improve generalization to unseen domains, a novel feature augmentation strategy called intermediate representation sampling is employed, and discriminative information from intermediate blocks of a ViT is distilled using a shared adapter network. The FedSIS approach has been evaluated on two well-known benchmarks for cross-domain FacePAD to demonstrate that it is possible to achieve state-of-the-art generalization performance without data sharing. Code: https://github.com/Naiftt/FedSIS
<div id='section'>Paperid: <span id='pid'>34, <a href='https://arxiv.org/pdf/2304.05640.pdf' target='_blank'>https://arxiv.org/pdf/2304.05640.pdf</a></span>   <span><a href='https://github.com/qianyuzqy/IADG' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Qianyu Zhou, Ke-Yue Zhang, Taiping Yao, Xuequan Lu, Ran Yi, Shouhong Ding, Lizhuang Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.05640">Instance-Aware Domain Generalization for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) based on domain generalization (DG) has been recently studied to improve the generalization on unseen scenarios. Previous methods typically rely on domain labels to align the distribution of each domain for learning domain-invariant representations. However, artificial domain labels are coarse-grained and subjective, which cannot reflect real domain distributions accurately. Besides, such domain-aware methods focus on domain-level alignment, which is not fine-grained enough to ensure that learned representations are insensitive to domain styles. To address these issues, we propose a novel perspective for DG FAS that aligns features on the instance level without the need for domain labels. Specifically, Instance-Aware Domain Generalization framework is proposed to learn the generalizable feature by weakening the features' sensitivity to instance-specific styles. Concretely, we propose Asymmetric Instance Adaptive Whitening to adaptively eliminate the style-sensitive feature correlation, boosting the generalization. Moreover, Dynamic Kernel Generator and Categorical Style Assembly are proposed to first extract the instance-specific features and then generate the style-diversified features with large style shifts, respectively, further facilitating the learning of style-insensitive features. Extensive experiments and analysis demonstrate the superiority of our method over state-of-the-art competitors. Code will be publicly available at https://github.com/qianyuzqy/IADG.
<div id='section'>Paperid: <span id='pid'>35, <a href='https://arxiv.org/pdf/2301.12831.pdf' target='_blank'>https://arxiv.org/pdf/2301.12831.pdf</a></span>   <span><a href='https://github.com/ChenqiKONG/M3FAS/' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenqi Kong, Kexin Zheng, Yibing Liu, Shiqi Wang, Anderson Rocha, Haoliang Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.12831">M3FAS: An Accurate and Robust MultiModal Mobile Face Anti-Spoofing System</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face presentation attacks (FPA), also known as face spoofing, have brought increasing concerns to the public through various malicious applications, such as financial fraud and privacy leakage. Therefore, safeguarding face recognition systems against FPA is of utmost importance. Although existing learning-based face anti-spoofing (FAS) models can achieve outstanding detection performance, they lack generalization capability and suffer significant performance drops in unforeseen environments. Many methodologies seek to use auxiliary modality data (e.g., depth and infrared maps) during the presentation attack detection (PAD) to address this limitation. However, these methods can be limited since (1) they require specific sensors such as depth and infrared cameras for data capture, which are rarely available on commodity mobile devices, and (2) they cannot work properly in practical scenarios when either modality is missing or of poor quality. In this paper, we devise an accurate and robust MultiModal Mobile Face Anti-Spoofing system named M3FAS to overcome the issues above. The primary innovation of this work lies in the following aspects: (1) To achieve robust PAD, our system combines visual and auditory modalities using three commonly available sensors: camera, speaker, and microphone; (2) We design a novel two-branch neural network with three hierarchical feature aggregation modules to perform cross-modal feature fusion; (3). We propose a multi-head training strategy, allowing the model to output predictions from the vision, acoustic, and fusion heads, resulting in a more flexible PAD. Extensive experiments have demonstrated the accuracy, robustness, and flexibility of M3FAS under various challenging experimental settings. The source code and dataset are available at: https://github.com/ChenqiKONG/M3FAS/
<div id='section'>Paperid: <span id='pid'>36, <a href='https://arxiv.org/pdf/2202.08192.pdf' target='_blank'>https://arxiv.org/pdf/2202.08192.pdf</a></span>   <span><a href='https://github.com/ZitongYu/Flex-Modal-FAS' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zitong Yu, Ajian Liu, Chenxu Zhao, Kevin H. M. Cheng, Xu Cheng, Guoying Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2202.08192">Flexible-Modal Face Anti-Spoofing: A Benchmark</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) plays a vital role in securing face recognition systems from presentation attacks. Benefitted from the maturing camera sensors, single-modal (RGB) and multi-modal (e.g., RGB+Depth) FAS has been applied in various scenarios with different configurations of sensors/modalities. Existing single- and multi-modal FAS methods usually separately train and deploy models for each possible modality scenario, which might be redundant and inefficient. Can we train a unified model, and flexibly deploy it under various modality scenarios? In this paper, we establish the first flexible-modal FAS benchmark with the principle `train one for all'. To be specific, with trained multi-modal (RGB+Depth+IR) FAS models, both intra- and cross-dataset testings are conducted on four flexible-modal sub-protocols (RGB, RGB+Depth, RGB+IR, and RGB+Depth+IR). We also investigate prevalent deep models and feature fusion strategies for flexible-modal FAS. We hope this new benchmark will facilitate the future research of the multi-modal FAS. The protocols and codes are available at https://github.com/ZitongYu/Flex-Modal-FAS.
<div id='section'>Paperid: <span id='pid'>37, <a href='https://arxiv.org/pdf/2111.07620.pdf' target='_blank'>https://arxiv.org/pdf/2111.07620.pdf</a></span>   <span><a href='https://github.com/kongzhecn/cfd-pad' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Feng Liu, Zhe Kong, Haozhe Liu, Wentian Zhang, Linlin Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2111.07620">Fingerprint Presentation Attack Detection by Channel-wise Feature Denoising</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the diversity of attack materials, fingerprint recognition systems (AFRSs) are vulnerable to malicious attacks. It is thus important to propose effective fingerprint presentation attack detection (PAD) methods for the safety and reliability of AFRSs. However, current PAD methods often exhibit poor robustness under new attack types settings. This paper thus proposes a novel channel-wise feature denoising fingerprint PAD (CFD-PAD) method by handling the redundant noise information ignored in previous studies. The proposed method learns important features of fingerprint images by weighing the importance of each channel and identifying discriminative channels and "noise" channels. Then, the propagation of "noise" channels is suppressed in the feature map to reduce interference. Specifically, a PA-Adaptation loss is designed to constrain the feature distribution to make the feature distribution of live fingerprints more aggregate and that of spoof fingerprints more disperse. Experimental results evaluated on the LivDet 2017 dataset showed that the proposed CFD-PAD can achieve a 2.53% average classification error (ACE) and a 93.83% true detection rate when the false detection rate equals 1.0% (TDR@FDR=1%). Also, the proposed method markedly outperforms the best single-model-based methods in terms of ACE (2.53% vs. 4.56%) and TDR@FDR=1%(93.83% vs. 73.32%), which demonstrates its effectiveness. Although we have achieved a comparable result with the state-of-the-art multiple-model-based methods, there still is an increase in TDR@FDR=1% from 91.19% to 93.83%. In addition, the proposed model is simpler, lighter and more efficient and has achieved a 74.76% reduction in computation time compared with the state-of-the-art multiple-model-based method. The source code is available at https://github.com/kongzhecn/cfd-pad.
<div id='section'>Paperid: <span id='pid'>38, <a href='https://arxiv.org/pdf/2109.04100.pdf' target='_blank'>https://arxiv.org/pdf/2109.04100.pdf</a></span>   <span><a href='https://github.com/kongzhecn/dfdm' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhe Kong, Wentian Zhang, Feng Liu, Wenhan Luo, Haozhe Liu, Linlin Shen, Raghavendra Ramachandra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2109.04100">Taming Self-Supervised Learning for Presentation Attack Detection: De-Folding and De-Mixing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biometric systems are vulnerable to Presentation Attacks (PA) performed using various Presentation Attack Instruments (PAIs). Even though there are numerous Presentation Attack Detection (PAD) techniques based on both deep learning and hand-crafted features, the generalization of PAD for unknown PAI is still a challenging problem. In this work, we empirically prove that the initialization of the PAD model is a crucial factor for the generalization, which is rarely discussed in the community. Based on such observation, we proposed a self-supervised learning-based method, denoted as DF-DM. Specifically, DF-DM is based on a global-local view coupled with De-Folding and De-Mixing to derive the task-specific representation for PAD. During De-Folding, the proposed technique will learn region-specific features to represent samples in a local pattern by explicitly minimizing generative loss. While De-Mixing drives detectors to obtain the instance-specific features with global information for more comprehensive representation by minimizing interpolation-based consistency. Extensive experimental results show that the proposed method can achieve significant improvements in terms of both face and fingerprint PAD in more complicated and hybrid datasets when compared with state-of-the-art methods. When training in CASIA-FASD and Idiap Replay-Attack, the proposed method can achieve an 18.60% Equal Error Rate (EER) in OULU-NPU and MSU-MFSD, exceeding baseline performance by 9.54%. The source code of the proposed technique is available at https://github.com/kongzhecn/dfdm.
<div id='section'>Paperid: <span id='pid'>39, <a href='https://arxiv.org/pdf/2006.14563.pdf' target='_blank'>https://arxiv.org/pdf/2006.14563.pdf</a></span>   <span><a href='https://github.com/asvspoof/D3M' target='_blank'>  GitHub</a></span></div></span></div><div id = 'author'>Authors:<span id = 'author'>Yongqiang Dou, Haocheng Yang, Maolin Yang, Yanyan Xu, Dengfeng Ke
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2006.14563">Dynamically Mitigating Data Discrepancy with Balanced Focal Loss for Replay Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>It becomes urgent to design effective anti-spoofing algorithms for vulnerable automatic speaker verification systems due to the advancement of high-quality playback devices. Current studies mainly treat anti-spoofing as a binary classification problem between bonafide and spoofed utterances, while lack of indistinguishable samples makes it difficult to train a robust spoofing detector. In this paper, we argue that for anti-spoofing, it needs more attention for indistinguishable samples over easily-classified ones in the modeling process, to make correct discrimination a top priority. Therefore, to mitigate the data discrepancy between training and inference, we propose D3M, to leverage a balanced focal loss function as the training objective to dynamically scale the loss based on the traits of the sample itself. Besides, in the experiments, we select three kinds of features that contain both magnitude-based and phase-based information to form complementary and informative features. Experimental results on the ASVspoof2019 dataset demonstrate the superiority of the proposed methods by comparison between our systems and top-performing ones. Systems trained with the balanced focal loss perform significantly better than conventional cross-entropy loss. With complementary features, our fusion system with only three kinds of features outperforms other systems containing five or more complex single models by 22.5% for min-tDCF and 7% for EER, achieving a min-tDCF and an EER of 0.0124 and 0.55% respectively. Furthermore, we present and discuss the evaluation results on real replay data apart from the simulated ASVspoof2019 data, indicating that research for anti-spoofing still has a long way to go. Source code, analysis data, and other details are publicly available at https://github.com/asvspoof/D3M.
<div id='section'>Paperid: <span id='pid'>40, <a href='https://arxiv.org/pdf/2303.15818.pdf' target='_blank'>https://arxiv.org/pdf/2303.15818.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Yang, Chang Liu, Longlong Xu, Yikai Wang, Yinpeng Dong, Ning Chen, Hang Su, Jun Zhu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.15818">Towards Effective Adversarial Textured 3D Meshes on Physical Face Recognition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition is a prevailing authentication solution in numerous biometric applications. Physical adversarial attacks, as an important surrogate, can identify the weaknesses of face recognition systems and evaluate their robustness before deployed. However, most existing physical attacks are either detectable readily or ineffective against commercial recognition systems. The goal of this work is to develop a more reliable technique that can carry out an end-to-end evaluation of adversarial robustness for commercial systems. It requires that this technique can simultaneously deceive black-box recognition models and evade defensive mechanisms. To fulfill this, we design adversarial textured 3D meshes (AT3D) with an elaborate topology on a human face, which can be 3D-printed and pasted on the attacker's face to evade the defenses. However, the mesh-based optimization regime calculates gradients in high-dimensional mesh space, and can be trapped into local optima with unsatisfactory transferability. To deviate from the mesh-based space, we propose to perturb the low-dimensional coefficient space based on 3D Morphable Model, which significantly improves black-box transferability meanwhile enjoying faster search efficiency and better visual quality. Extensive experiments in digital and physical scenarios show that our method effectively explores the security vulnerabilities of multiple popular commercial services, including three recognition APIs, four anti-spoofing APIs, two prevailing mobile phones and two automated access control systems.
<div id='section'>Paperid: <span id='pid'>41, <a href='https://arxiv.org/pdf/2310.02140.pdf' target='_blank'>https://arxiv.org/pdf/2310.02140.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Luis F. Gomez, Julian Fierrez, Aythami Morales, Mahdi Ghafourian, Ruben Tolosana, Imanol Solano, Alejandro Garcia, Francisco Zamora-Martinez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.02140">PAD-Phys: Exploiting Physiology for Presentation Attack Detection in Face Biometrics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Presentation Attack Detection (PAD) is a crucial stage in facial recognition systems to avoid leakage of personal information or spoofing of identity to entities. Recently, pulse detection based on remote photoplethysmography (rPPG) has been shown to be effective in face presentation attack detection.
  This work presents three different approaches to the presentation attack detection based on rPPG: (i) The physiological domain, a domain using rPPG-based models, (ii) the Deepfakes domain, a domain where models were retrained from the physiological domain to specific Deepfakes detection tasks; and (iii) a new Presentation Attack domain was trained by applying transfer learning from the two previous domains to improve the capability to differentiate between bona-fides and attacks.
  The results show the efficiency of the rPPG-based models for presentation attack detection, evidencing a 21.70% decrease in average classification error rate (ACER) (from 41.03% to 19.32%) when the presentation attack domain is compared to the physiological and Deepfakes domains. Our experiments highlight the efficiency of transfer learning in rPPG-based models and perform well in presentation attack detection in instruments that do not allow copying of this physiological feature.
<div id='section'>Paperid: <span id='pid'>42, <a href='https://arxiv.org/pdf/2309.07880.pdf' target='_blank'>https://arxiv.org/pdf/2309.07880.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Roberto Daza, Aythami Morales, Julian Fierrez, Ruben Tolosana, Ruben Vera-Rodriguez
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.07880">mEBAL2 Database and Benchmark: Image-based Multispectral Eyeblink Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work introduces a new multispectral database and novel approaches for eyeblink detection in RGB and Near-Infrared (NIR) individual images. Our contributed dataset (mEBAL2, multimodal Eye Blink and Attention Level estimation, Version 2) is the largest existing eyeblink database, representing a great opportunity to improve data-driven multispectral approaches for blink detection and related applications (e.g., attention level estimation and presentation attack detection in face biometrics). mEBAL2 includes 21,100 image sequences from 180 different students (more than 2 million labeled images in total) while conducting a number of e-learning tasks of varying difficulty or taking a real course on HTML initiation through the edX MOOC platform. mEBAL2 uses multiple sensors, including two Near-Infrared (NIR) and one RGB camera to capture facial gestures during the execution of the tasks, as well as an Electroencephalogram (EEG) band to get the cognitive activity of the user and blinking events. Furthermore, this work proposes a Convolutional Neural Network architecture as benchmark for blink detection on mEBAL2 with performances up to 97%. Different training methodologies are implemented using the RGB spectrum, NIR spectrum, and the combination of both to enhance the performance on existing eyeblink detectors. We demonstrate that combining NIR and RGB images during training improves the performance of RGB eyeblink detectors (i.e., detection based only on a RGB image). Finally, the generalization capacity of the proposed eyeblink detectors is validated in wilder and more challenging environments like the HUST-LEBW dataset to show the usefulness of mEBAL2 to train a new generation of data-driven approaches for eyeblink detection.
<div id='section'>Paperid: <span id='pid'>43, <a href='https://arxiv.org/pdf/2006.05327.pdf' target='_blank'>https://arxiv.org/pdf/2006.05327.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Roberto Daza, Aythami Morales, Julian Fierrez, Ruben Tolosana
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2006.05327">mEBAL: A Multimodal Database for Eye Blink Detection and Attention Level Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work presents mEBAL, a multimodal database for eye blink detection and attention level estimation. The eye blink frequency is related to the cognitive activity and automatic detectors of eye blinks have been proposed for many tasks including attention level estimation, analysis of neuro-degenerative diseases, deception recognition, drive fatigue detection, or face anti-spoofing. However, most existing databases and algorithms in this area are limited to experiments involving only a few hundred samples and individual sensors like face cameras. The proposed mEBAL improves previous databases in terms of acquisition sensors and samples. In particular, three different sensors are simultaneously considered: Near Infrared (NIR) and RGB cameras to capture the face gestures and an Electroencephalography (EEG) band to capture the cognitive activity of the user and blinking events. Regarding the size of mEBAL, it comprises 6,000 samples and the corresponding attention level from 38 different students while conducting a number of e-learning tasks of varying difficulty. In addition to presenting mEBAL, we also include preliminary experiments on: i) eye blink detection using Convolutional Neural Networks (CNN) with the facial images, and ii) attention level estimation of the students based on their eye blink frequency.
<div id='section'>Paperid: <span id='pid'>44, <a href='https://arxiv.org/pdf/2404.09193.pdf' target='_blank'>https://arxiv.org/pdf/2404.09193.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Chen, Xiao Yang, Yinpeng Dong, Hang Su, Zhaoxia Yin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.09193">FaceCat: Enhancing Face Recognition Security with a Unified Diffusion Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) and adversarial detection (FAD) have been regarded as critical technologies to ensure the safety of face recognition systems. However, due to limited practicality, complex deployment, and the additional computational overhead, it is necessary to implement both detection techniques within a unified framework. This paper aims to achieve this goal by breaking through two primary obstacles: 1) the suboptimal face feature representation and 2) the scarcity of training data. To address the limited performance caused by existing feature representations, motivated by the rich structural and detailed features of face diffusion models, we propose FaceCat, the first approach leveraging the diffusion model to simultaneously enhance the performance of FAS and FAD. Specifically, FaceCat elaborately designs a hierarchical fusion mechanism to capture rich face semantic features of the diffusion model. These features then serve as a robust foundation for a lightweight head, designed to execute FAS and FAD simultaneously. Due to the limitations in feature representation that arise from relying solely on single-modality image data, we further propose a novel text-guided multi-modal alignment strategy that utilizes text prompts to enrich feature representation, thereby enhancing performance. To combat data scarcity, we build a comprehensive dataset with a wide range of 28 attack types, offering greater potential for a unified framework in facial security. Extensive experiments validate the effectiveness of FaceCat generalizes significantly better and obtains excellent robustness against common input transformations.
<div id='section'>Paperid: <span id='pid'>45, <a href='https://arxiv.org/pdf/2311.05336.pdf' target='_blank'>https://arxiv.org/pdf/2311.05336.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meiling Fang, Marco Huber, Julian Fierrez, Raghavendra Ramachandra, Naser Damer, Alhasan Alkhaddour, Maksim Kasantcev, Vasiliy Pryadchenko, Ziyuan Yang, Huijie Huangfu, Yingyu Chen, Yi Zhang, Yuchen Pan, Junjun Jiang, Xianming Liu, Xianyun Sun, Caiyong Wang, Xingyu Liu, Zhaohua Chang, Guangzhe Zhao, Juan Tapia, Lazaro Gonzalez-Soler, Carlos Aravena, Daniel Schulz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.05336">SynFacePAD 2023: Competition on Face Presentation Attack Detection Based on Privacy-aware Synthetic Training Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a summary of the Competition on Face Presentation Attack Detection Based on Privacy-aware Synthetic Training Data (SynFacePAD 2023) held at the 2023 International Joint Conference on Biometrics (IJCB 2023). The competition attracted a total of 8 participating teams with valid submissions from academia and industry. The competition aimed to motivate and attract solutions that target detecting face presentation attacks while considering synthetic-based training data motivated by privacy, legal and ethical concerns associated with personal data. To achieve that, the training data used by the participants was limited to synthetic data provided by the organizers. The submitted solutions presented innovations and novel approaches that led to outperforming the considered baseline in the investigated benchmarks.
<div id='section'>Paperid: <span id='pid'>46, <a href='https://arxiv.org/pdf/2412.17541.pdf' target='_blank'>https://arxiv.org/pdf/2412.17541.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haoyuan Zhang, Xiangyu Zhu, Li Gao, Jiawei Pan, Kai Pang, Guoying Zhao, Zhen Lei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.17541">Spoof Trace Discovery for Deep Learning Based Explainable Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the rapid growth usage of face recognition in people's daily life, face anti-spoofing becomes increasingly important to avoid malicious attacks. Recent face anti-spoofing models can reach a high classification accuracy on multiple datasets but these models can only tell people "this face is fake" while lacking the explanation to answer "why it is fake". Such a system undermines trustworthiness and causes user confusion, as it denies their requests without providing any explanations. In this paper, we incorporate XAI into face anti-spoofing and propose a new problem termed X-FAS (eXplainable Face Anti-Spoofing) empowering face anti-spoofing models to provide an explanation. We propose SPTD (SPoof Trace Discovery), an X-FAS method which can discover spoof concepts and provide reliable explanations on the basis of discovered concepts. To evaluate the quality of X-FAS methods, we propose an X-FAS benchmark with annotated spoof traces by experts. We analyze SPTD explanations on face anti-spoofing dataset and compare SPTD quantitatively and qualitatively with previous XAI methods on proposed X-FAS benchmark. Experimental results demonstrate SPTD's ability to generate reliable explanations.
<div id='section'>Paperid: <span id='pid'>47, <a href='https://arxiv.org/pdf/2401.08275.pdf' target='_blank'>https://arxiv.org/pdf/2401.08275.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bin Zhang, Xiangyu Zhu, Xiaoyu Zhang, Zhen Lei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.08275">Modeling Spoof Noise by De-spoofing Diffusion and its Application in Face Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing is crucial for ensuring the security and reliability of face recognition systems. Several existing face anti-spoofing methods utilize GAN-like networks to detect presentation attacks by estimating the noise pattern of a spoof image and recovering the corresponding genuine image. But GAN's limited face appearance space results in the denoised faces cannot cover the full data distribution of genuine faces, thereby undermining the generalization performance of such methods. In this work, we present a pioneering attempt to employ diffusion models to denoise a spoof image and restore the genuine image. The difference between these two images is considered as the spoof noise, which can serve as a discriminative cue for face anti-spoofing. We evaluate our proposed method on several intra-testing and inter-testing protocols, where the experimental results showcase the effectiveness of our method in achieving competitive performance in terms of both accuracy and generalization.
<div id='section'>Paperid: <span id='pid'>48, <a href='https://arxiv.org/pdf/2302.08320.pdf' target='_blank'>https://arxiv.org/pdf/2302.08320.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Carlos Gonzalez-Garcia, Ruben Tolosana, Ruben Vera-Rodriguez, Julian Fierrez, Javier Ortega-Garcia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08320">Introduction to Presentation Attacks in Signature Biometrics and Recent Advances</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Applications based on biometric authentication have received a lot of interest in the last years due to the breathtaking results obtained using personal traits such as face or fingerprint. However, it is important not to forget that these biometric systems have to withstand different types of possible attacks. This chapter carries out an analysis of different Presentation Attack (PA) scenarios for on-line handwritten signature verification. The main contributions of this chapter are: i) an updated overview of representative methods for Presentation Attack Detection (PAD) in signature biometrics; ii) a description of the different levels of PAs existing in on-line signature verification regarding the amount of information available to the impostor, as well as the training, effort, and ability to perform the forgeries; and iii) an evaluation of the system performance in signature biometrics under different scenarios considering recent publicly available signature databases, DeepSignDB and SVC2021_EvalDB. This work is in line with recent efforts in the Common Criteria standardization community towards security evaluation of biometric systems.
<div id='section'>Paperid: <span id='pid'>49, <a href='https://arxiv.org/pdf/2501.01720.pdf' target='_blank'>https://arxiv.org/pdf/2501.01720.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Guosheng Zhang, Keyao Wang, Haixiao Yue, Ajian Liu, Gang Zhang, Kun Yao, Errui Ding, Jingdong Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.01720">Interpretable Face Anti-Spoofing: Enhancing Generalization with Multimodal Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face Anti-Spoofing (FAS) is essential for ensuring the security and reliability of facial recognition systems. Most existing FAS methods are formulated as binary classification tasks, providing confidence scores without interpretation. They exhibit limited generalization in out-of-domain scenarios, such as new environments or unseen spoofing types. In this work, we introduce a multimodal large language model (MLLM) framework for FAS, termed Interpretable Face Anti-Spoofing (I-FAS), which transforms the FAS task into an interpretable visual question answering (VQA) paradigm. Specifically, we propose a Spoof-aware Captioning and Filtering (SCF) strategy to generate high-quality captions for FAS images, enriching the model's supervision with natural language interpretations. To mitigate the impact of noisy captions during training, we develop a Lopsided Language Model (L-LM) loss function that separates loss calculations for judgment and interpretation, prioritizing the optimization of the former. Furthermore, to enhance the model's perception of global visual features, we design a Globally Aware Connector (GAC) to align multi-level visual representations with the language model. Extensive experiments on standard and newly devised One to Eleven cross-domain benchmarks, comprising 12 public datasets, demonstrate that our method significantly outperforms state-of-the-art methods.
<div id='section'>Paperid: <span id='pid'>50, <a href='https://arxiv.org/pdf/2310.08142.pdf' target='_blank'>https://arxiv.org/pdf/2310.08142.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xu Chen, Yunde Jia, Yuwei Wu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.08142">Fine-Grained Annotation for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing plays a critical role in safeguarding facial recognition systems against presentation attacks. While existing deep learning methods show promising results, they still suffer from the lack of fine-grained annotations, which lead models to learn task-irrelevant or unfaithful features. In this paper, we propose a fine-grained annotation method for face anti-spoofing. Specifically, we first leverage the Segment Anything Model (SAM) to obtain pixel-wise segmentation masks by utilizing face landmarks as point prompts. The face landmarks provide segmentation semantics, which segments the face into regions. We then adopt these regions as masks and assemble them into three separate annotation maps: spoof, living, and background maps. Finally, we combine three separate maps into a three-channel map as annotations for model training. Furthermore, we introduce the Multi-Channel Region Exchange Augmentation (MCREA) to diversify training data and reduce overfitting. Experimental results demonstrate that our method outperforms existing state-of-the-art approaches in both intra-dataset and cross-dataset evaluations.
<div id='section'>Paperid: <span id='pid'>51, <a href='https://arxiv.org/pdf/2405.08596.pdf' target='_blank'>https://arxiv.org/pdf/2405.08596.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiaohui Zhang, Jiangyan Yi, Jianhua Tao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.08596">Towards Robust Audio Deepfake Detection: A Evolving Benchmark for Continual Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rise of advanced large language models such as GPT-4, GPT-4o, and the Claude family has made fake audio detection increasingly challenging. Traditional fine-tuning methods struggle to keep pace with the evolving landscape of synthetic speech, necessitating continual learning approaches that can adapt to new audio while retaining the ability to detect older types. Continual learning, which acts as an effective tool for detecting newly emerged deepfake audio while maintaining performance on older types, lacks a well-constructed and user-friendly evaluation framework. To address this gap, we introduce EVDA, a benchmark for evaluating continual learning methods in deepfake audio detection. EVDA includes classic datasets from the Anti-Spoofing Voice series, Chinese fake audio detection series, and newly generated deepfake audio from models like GPT-4 and GPT-4o. It supports various continual learning techniques, such as Elastic Weight Consolidation (EWC), Learning without Forgetting (LwF), and recent methods like Regularized Adaptive Weight Modification (RAWM) and Radian Weight Modification (RWM). Additionally, EVDA facilitates the development of robust algorithms by providing an open interface for integrating new continual learning methods
<div id='section'>Paperid: <span id='pid'>52, <a href='https://arxiv.org/pdf/2409.06327.pdf' target='_blank'>https://arxiv.org/pdf/2409.06327.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chang Zeng, Xiaoxiao Miao, Xin Wang, Erica Cooper, Junichi Yamagishi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06327">Spoofing-Aware Speaker Verification Robust Against Domain and Channel Mismatches</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In real-world applications, it is challenging to build a speaker verification system that is simultaneously robust against common threats, including spoofing attacks, channel mismatch, and domain mismatch. Traditional automatic speaker verification (ASV) systems often tackle these issues separately, leading to suboptimal performance when faced with simultaneous challenges. In this paper, we propose an integrated framework that incorporates pair-wise learning and spoofing attack simulation into the meta-learning paradigm to enhance robustness against these multifaceted threats. This novel approach employs an asymmetric dual-path model and a multi-task learning strategy to handle ASV, anti-spoofing, and spoofing-aware ASV tasks concurrently. A new testing dataset, CNComplex, is introduced to evaluate system performance under these combined threats. Experimental results demonstrate that our integrated model significantly improves performance over traditional ASV systems across various scenarios, showcasing its potential for real-world deployment. Additionally, the proposed framework's ability to generalize across different conditions highlights its robustness and reliability, making it a promising solution for practical ASV applications.
<div id='section'>Paperid: <span id='pid'>53, <a href='https://arxiv.org/pdf/2408.14066.pdf' target='_blank'>https://arxiv.org/pdf/2408.14066.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuechen Liu, Xin Wang, Junichi Yamagishi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.14066">A Preliminary Case Study on Long-Form In-the-Wild Audio Spoofing Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Audio spoofing detection has become increasingly important due to the rise in real-world cases. Current spoofing detectors, referred to as spoofing countermeasures (CM), are mainly trained and focused on audio waveforms with a single speaker and short duration. This study explores spoofing detection in more realistic scenarios, where the audio is long in duration and features multiple speakers and complex acoustic conditions. We test the widely-acquired AASIST under this challenging scenario, looking at the impact of multiple variations such as duration, speaker presence, and acoustic complexities on CM performance. Our work reveals key issues with current methods and suggests preliminary ways to improve them. We aim to make spoofing detection more applicable in more in-the-wild scenarios. This research is served as an important step towards developing detection systems that can handle the challenges of audio spoofing in real-world applications.
<div id='section'>Paperid: <span id='pid'>54, <a href='https://arxiv.org/pdf/2509.14921.pdf' target='_blank'>https://arxiv.org/pdf/2509.14921.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tahar Chettaoui, Naser Damer, Fadi Boutros
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14921">Trade-offs in Cross-Domain Generalization of Foundation Model Fine-Tuned for Biometric Applications</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation models such as CLIP have demonstrated exceptional zero- and few-shot transfer capabilities across diverse vision tasks. However, when fine-tuned for highly specialized biometric tasks, face recognition (FR), morphing attack detection (MAD), and presentation attack detection (PAD), these models may suffer from over-specialization. Thus, they may lose one of their foundational strengths, cross-domain generalization. In this work, we systematically quantify these trade-offs by evaluating three instances of CLIP fine-tuned for FR, MAD, and PAD. We evaluate each adapted model as well as the original CLIP baseline on 14 general vision datasets under zero-shot and linear-probe protocols, alongside common FR, MAD, and PAD benchmarks. Our results indicate that fine-tuned models suffer from over-specialization, especially when fine-tuned for complex tasks of FR. Also, our results pointed out that task complexity and classification head design, multi-class (FR) vs. binary (MAD and PAD), correlate with the degree of catastrophic forgetting. The FRoundation model with the ViT-L backbone outperforms other approaches on the large-scale FR benchmark IJB-C, achieving an improvement of up to 58.52%. However, it experiences a substantial performance drop on ImageNetV2, reaching only 51.63% compared to 69.84% achieved by the baseline CLIP model. Moreover, the larger CLIP architecture consistently preserves more of the model's original generalization ability than the smaller variant, indicating that increased model capacity may help mitigate over-specialization.
<div id='section'>Paperid: <span id='pid'>55, <a href='https://arxiv.org/pdf/2304.13419.pdf' target='_blank'>https://arxiv.org/pdf/2304.13419.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marco Huber, Meiling Fang, Fadi Boutros, Naser Damer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.13419">Are Explainability Tools Gender Biased? A Case Study on Face Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition (FR) systems continue to spread in our daily lives with an increasing demand for higher explainability and interpretability of FR systems that are mainly based on deep learning. While bias across demographic groups in FR systems has already been studied, the bias of explainability tools has not yet been investigated. As such tools aim at steering further development and enabling a better understanding of computer vision problems, the possible existence of bias in their outcome can lead to a chain of biased decisions. In this paper, we explore the existence of bias in the outcome of explainability tools by investigating the use case of face presentation attack detection. By utilizing two different explainability tools on models with different levels of bias, we investigate the bias in the outcome of such tools. Our study shows that these tools show clear signs of gender bias in the quality of their explanations.
<div id='section'>Paperid: <span id='pid'>56, <a href='https://arxiv.org/pdf/2205.02573.pdf' target='_blank'>https://arxiv.org/pdf/2205.02573.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meiling Fang, Fadi Boutros, Naser Damer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.02573">Intra and Cross-spectrum Iris Presentation Attack Detection in the NIR and Visible Domains</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Iris Presentation Attack Detection (PAD) is essential to secure iris recognition systems. Recent iris PAD solutions achieved good performance by leveraging deep learning techniques. However, most results were reported under intra-database scenarios and it is unclear if such solutions can generalize well across databases and capture spectra. These PAD methods run the risk of overfitting because of the binary label supervision during the network training, which serves global information learning but weakens the capture of local discriminative features. This chapter presents a novel attention-based deep pixel-wise binary supervision (A-PBS) method. A-PBS utilizes pixel-wise supervision to capture the fine-grained pixel/patch-level cues and attention mechanism to guide the network to automatically find regions where most contribute to an accurate PAD decision. Extensive experiments are performed on six NIR and one visible-light iris databases to show the effectiveness and robustness of proposed A-PBS methods. We additionally conduct extensive experiments under intra-/cross-database and intra-/cross-spectrum for detailed analysis. The results of our experiments indicates the generalizability of the A-PBS iris PAD approach.
<div id='section'>Paperid: <span id='pid'>57, <a href='https://arxiv.org/pdf/2505.12994.pdf' target='_blank'>https://arxiv.org/pdf/2505.12994.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuanjun Chen, I-Ming Lin, Lin Zhang, Jiawei Du, Haibin Wu, Hung-yi Lee, Jyh-Shing Roger Jang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.12994">Codec-Based Deepfake Source Tracing via Neural Audio Codec Taxonomy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in neural audio codec-based speech generation (CoSG) models have produced remarkably realistic audio deepfakes. We refer to deepfake speech generated by CoSG systems as codec-based deepfake, or CodecFake. Although existing anti-spoofing research on CodecFake predominantly focuses on verifying the authenticity of audio samples, almost no attention was given to tracing the CoSG used in generating these deepfakes. In CodecFake generation, processes such as speech-to-unit encoding, discrete unit modeling, and unit-to-speech decoding are fundamentally based on neural audio codecs. Motivated by this, we introduce source tracing for CodecFake via neural audio codec taxonomy, which dissects neural audio codecs to trace CoSG. Our experimental results on the CodecFake+ dataset provide promising initial evidence for the feasibility of CodecFake source tracing while also highlighting several challenges that warrant further investigation.
<div id='section'>Paperid: <span id='pid'>58, <a href='https://arxiv.org/pdf/2504.10905.pdf' target='_blank'>https://arxiv.org/pdf/2504.10905.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yukang Lin, Yan Hong, Zunnan Xu, Xindi Li, Chao Xu, Chuanbiao Song, Ronghui Li, Haoxing Chen, Jun Lan, Huijia Zhu, Weiqiang Wang, Jianfu Zhang, Xiu Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.10905">InterAnimate: Taming Region-aware Diffusion Model for Realistic Human Interaction Animation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent video generation research has focused heavily on isolated actions, leaving interactive motions-such as hand-face interactions-largely unexamined. These interactions are essential for emerging biometric authentication systems, which rely on interactive motion-based anti-spoofing approaches. From a security perspective, there is a growing need for large-scale, high-quality interactive videos to train and strengthen authentication models. In this work, we introduce a novel paradigm for animating realistic hand-face interactions. Our approach simultaneously learns spatio-temporal contact dynamics and biomechanically plausible deformation effects, enabling natural interactions where hand movements induce anatomically accurate facial deformations while maintaining collision-free contact. To facilitate this research, we present InterHF, a large-scale hand-face interaction dataset featuring 18 interaction patterns and 90,000 annotated videos. Additionally, we propose InterAnimate, a region-aware diffusion model designed specifically for interaction animation. InterAnimate leverages learnable spatial and temporal latents to effectively capture dynamic interaction priors and integrates a region-aware interaction mechanism that injects these priors into the denoising process. To the best of our knowledge, this work represents the first large-scale effort to systematically study human hand-face interactions. Qualitative and quantitative results show InterAnimate produces highly realistic animations, setting a new benchmark. Code and data will be made public to advance research.
<div id='section'>Paperid: <span id='pid'>59, <a href='https://arxiv.org/pdf/2501.08238.pdf' target='_blank'>https://arxiv.org/pdf/2501.08238.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuanjun Chen, Jiawei Du, Haibin Wu, Lin Zhang, I-Ming Lin, I-Hsiang Chiu, Wenze Ren, Yuan Tseng, Yu Tsao, Jyh-Shing Roger Jang, Hung-yi Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08238">CodecFake+: A Large-Scale Neural Audio Codec-Based Deepfake Speech Dataset</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the rapid advancement of neural audio codecs, codec-based speech generation (CoSG) systems have become highly powerful. Unfortunately, CoSG also enables the creation of highly realistic deepfake speech, making it easier to mimic an individual's voice and spread misinformation. We refer to this emerging deepfake speech generated by CoSG systems as CodecFake. Detecting such CodecFake is an urgent challenge, yet most existing systems primarily focus on detecting fake speech generated by traditional speech synthesis models. In this paper, we introduce CodecFake+, a large-scale dataset designed to advance CodecFake detection. To our knowledge, CodecFake+ is the largest dataset encompassing the most diverse range of codec architectures. The training set is generated through re-synthesis using 31 publicly available open-source codec models, while the evaluation set includes web-sourced data from 17 advanced CoSG models. We also propose a comprehensive taxonomy that categorizes codecs by their root components: vector quantizer, auxiliary objectives, and decoder types. Our proposed dataset and taxonomy enable detailed analysis at multiple levels to discern the key factors for successful CodecFake detection. At the individual codec level, we validate the effectiveness of using codec re-synthesized speech (CoRS) as training data for large-scale CodecFake detection. At the taxonomy level, we show that detection performance is strongest when the re-synthesis model incorporates disentanglement auxiliary objectives or a frequency-domain decoder. Furthermore, from the perspective of using all the CoRS training data, we show that our proposed taxonomy can be used to select better training data for improving detection performance. Overall, we envision that CodecFake+ will be a valuable resource for both general and fine-grained exploration to develop better anti-spoofing models against CodecFake.
<div id='section'>Paperid: <span id='pid'>60, <a href='https://arxiv.org/pdf/2409.08731.pdf' target='_blank'>https://arxiv.org/pdf/2409.08731.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Du, I-Ming Lin, I-Hsiang Chiu, Xuanjun Chen, Haibin Wu, Wenze Ren, Yu Tsao, Hung-yi Lee, Jyh-Shing Roger Jang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08731">DFADD: The Diffusion and Flow-Matching Based Audio Deepfake Dataset</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Mainstream zero-shot TTS production systems like Voicebox and Seed-TTS achieve human parity speech by leveraging Flow-matching and Diffusion models, respectively. Unfortunately, human-level audio synthesis leads to identity misuse and information security issues. Currently, many antispoofing models have been developed against deepfake audio. However, the efficacy of current state-of-the-art anti-spoofing models in countering audio synthesized by diffusion and flowmatching based TTS systems remains unknown. In this paper, we proposed the Diffusion and Flow-matching based Audio Deepfake (DFADD) dataset. The DFADD dataset collected the deepfake audio based on advanced diffusion and flowmatching TTS models. Additionally, we reveal that current anti-spoofing models lack sufficient robustness against highly human-like audio generated by diffusion and flow-matching TTS systems. The proposed DFADD dataset addresses this gap and provides a valuable resource for developing more resilient anti-spoofing models.
<div id='section'>Paperid: <span id='pid'>61, <a href='https://arxiv.org/pdf/2406.07237.pdf' target='_blank'>https://arxiv.org/pdf/2406.07237.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haibin Wu, Yuan Tseng, Hung-yi Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.07237">CodecFake: Enhancing Anti-Spoofing Models Against Deepfake Audios from Codec-Based Speech Synthesis Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current state-of-the-art (SOTA) codec-based audio synthesis systems can mimic anyone's voice with just a 3-second sample from that specific unseen speaker. Unfortunately, malicious attackers may exploit these technologies, causing misuse and security issues. Anti-spoofing models have been developed to detect fake speech. However, the open question of whether current SOTA anti-spoofing models can effectively counter deepfake audios from codec-based speech synthesis systems remains unanswered. In this paper, we curate an extensive collection of contemporary SOTA codec models, employing them to re-create synthesized speech. This endeavor leads to the creation of CodecFake, the first codec-based deepfake audio dataset. Additionally, we verify that anti-spoofing models trained on commonly used datasets cannot detect synthesized speech from current codec-based speech generation systems. The proposed CodecFake dataset empowers these models to counter this challenge effectively.
<div id='section'>Paperid: <span id='pid'>62, <a href='https://arxiv.org/pdf/2405.18853.pdf' target='_blank'>https://arxiv.org/pdf/2405.18853.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chuanbiao Song, Yan Hong, Jun Lan, Huijia Zhu, Weiqiang Wang, Jianfu Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.18853">Supervised Contrastive Learning for Snapshot Spectral Imaging Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study reveals a cutting-edge re-balanced contrastive learning strategy aimed at strengthening face anti-spoofing capabilities within facial recognition systems, with a focus on countering the challenges posed by printed photos, and highly realistic silicone or latex masks. Leveraging the HySpeFAS dataset, which benefits from Snapshot Spectral Imaging technology to provide hyperspectral images, our approach harmonizes class-level contrastive learning with data resampling and an innovative real-face oriented reweighting technique. This method effectively mitigates dataset imbalances and reduces identity-related biases. Notably, our strategy achieved an unprecedented 0.0000\% Average Classification Error Rate (ACER) on the HySpeFAS dataset, ranking first at the Chalearn Snapshot Spectral Imaging Face Anti-spoofing Challenge on CVPR 2024.
<div id='section'>Paperid: <span id='pid'>63, <a href='https://arxiv.org/pdf/2504.04470.pdf' target='_blank'>https://arxiv.org/pdf/2504.04470.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiabao Guo, Ajian Liu, Yunfeng Diao, Jin Zhang, Hui Ma, Bo Zhao, Richang Hong, Meng Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04470">Domain Generalization for Face Anti-spoofing via Content-aware Composite Prompt Engineering</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The challenge of Domain Generalization (DG) in Face Anti-Spoofing (FAS) is the significant interference of domain-specific signals on subtle spoofing clues. Recently, some CLIP-based algorithms have been developed to alleviate this interference by adjusting the weights of visual classifiers. However, our analysis of this class-wise prompt engineering suffers from two shortcomings for DG FAS: (1) The categories of facial categories, such as real or spoof, have no semantics for the CLIP model, making it difficult to learn accurate category descriptions. (2) A single form of prompt cannot portray the various types of spoofing. In this work, instead of class-wise prompts, we propose a novel Content-aware Composite Prompt Engineering (CCPE) that generates instance-wise composite prompts, including both fixed template and learnable prompts. Specifically, our CCPE constructs content-aware prompts from two branches: (1) Inherent content prompt explicitly benefits from abundant transferred knowledge from the instruction-based Large Language Model (LLM). (2) Learnable content prompts implicitly extract the most informative visual content via Q-Former. Moreover, we design a Cross-Modal Guidance Module (CGM) that dynamically adjusts unimodal features for fusion to achieve better generalized FAS. Finally, our CCPE has been validated for its effectiveness in multiple cross-domain experiments and achieves state-of-the-art (SOTA) results.
<div id='section'>Paperid: <span id='pid'>64, <a href='https://arxiv.org/pdf/2509.18102.pdf' target='_blank'>https://arxiv.org/pdf/2509.18102.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wangjie Li, Xingjia Xie, Yishuang Li, Wenhao Guan, Kaidi Wang, Pengyu Ren, Lin Li, Qingyang Hong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.18102">XMUspeech Systems for the ASVspoof 5 Challenge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we present our submitted XMUspeech systems to the speech deepfake detection track of the ASVspoof 5 Challenge. Compared to previous challenges, the audio duration in ASVspoof 5 database has significantly increased. And we observed that merely adjusting the input audio length can substantially improve system performance. To capture artifacts at multiple levels, we explored the performance of AASIST, HM-Conformer, Hubert, and Wav2vec2 with various input features and loss functions. Specifically, in order to obtain artifact-related information, we trained self-supervised models on the dataset containing spoofing utterances as the feature extractors. And we applied an adaptive multi-scale feature fusion (AMFF) method to integrate features from multiple Transformer layers with the hand-crafted feature to enhance the detection capability. In addition, we conducted extensive experiments on one-class loss functions and provided optimized configurations to better align with the anti-spoofing task. Our fusion system achieved a minDCF of 0.4783 and an EER of 20.45% in the closed condition, and a minDCF of 0.2245 and an EER of 9.36% in the open condition.
<div id='section'>Paperid: <span id='pid'>65, <a href='https://arxiv.org/pdf/2501.03805.pdf' target='_blank'>https://arxiv.org/pdf/2501.03805.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sung-Feng Huang, Heng-Cheng Kuo, Zhehuai Chen, Xuesong Yang, Chao-Han Huck Yang, Yu Tsao, Yu-Chiang Frank Wang, Hung-yi Lee, Szu-Wei Fu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.03805">Detecting the Undetectable: Assessing the Efficacy of Current Spoof Detection Methods Against Seamless Speech Edits</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Neural speech editing advancements have raised concerns about their misuse in spoofing attacks. Traditional partially edited speech corpora primarily focus on cut-and-paste edits, which, while maintaining speaker consistency, often introduce detectable discontinuities. Recent methods, like A\textsuperscript{3}T and Voicebox, improve transitions by leveraging contextual information. To foster spoofing detection research, we introduce the Speech INfilling Edit (SINE) dataset, created with Voicebox. We detailed the process of re-implementing Voicebox training and dataset creation. Subjective evaluations confirm that speech edited using this novel technique is more challenging to detect than conventional cut-and-paste methods. Despite human difficulty, experimental results demonstrate that self-supervised-based detectors can achieve remarkable performance in detection, localization, and generalization across different edit methods. The dataset and related models will be made publicly available.
<div id='section'>Paperid: <span id='pid'>66, <a href='https://arxiv.org/pdf/2411.01263.pdf' target='_blank'>https://arxiv.org/pdf/2411.01263.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingming Long, Jie Zhang, Shiguang Shan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.01263">Confidence Aware Learning for Reliable Face Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current Face Anti-spoofing (FAS) models tend to make overly confident predictions even when encountering unfamiliar scenarios or unknown presentation attacks, which leads to serious potential risks. To solve this problem, we propose a Confidence Aware Face Anti-spoofing (CA-FAS) model, which is aware of its capability boundary, thus achieving reliable liveness detection within this boundary. To enable the CA-FAS to "know what it doesn't know", we propose to estimate its confidence during the prediction of each sample. Specifically, we build Gaussian distributions for both the live faces and the known attacks. The prediction confidence for each sample is subsequently assessed using the Mahalanobis distance between the sample and the Gaussians for the "known data". We further introduce the Mahalanobis distance-based triplet mining to optimize the parameters of both the model and the constructed Gaussians as a whole. Extensive experiments show that the proposed CA-FAS can effectively recognize samples with low prediction confidence and thus achieve much more reliable performance than other FAS models by filtering out samples that are beyond its reliable range.
<div id='section'>Paperid: <span id='pid'>67, <a href='https://arxiv.org/pdf/2401.09006.pdf' target='_blank'>https://arxiv.org/pdf/2401.09006.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xingming Long, Jie Zhang, Shiguang Shan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.09006">Generalized Face Liveness Detection via De-fake Face Generator</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Previous Face Anti-spoofing (FAS) methods face the challenge of generalizing to unseen domains, mainly because most existing FAS datasets are relatively small and lack data diversity. Thanks to the development of face recognition in the past decade, numerous real face images are available publicly, which are however neglected previously by the existing literature. In this paper, we propose an Anomalous cue Guided FAS (AG-FAS) method, which can effectively leverage large-scale additional real faces for improving model generalization via a De-fake Face Generator (DFG). Specifically, by training on a large-scale real face only dataset, the generator obtains the knowledge of what a real face should be like, and thus has the capability of generating a "real" version of any input face image. Consequently, the difference between the input face and the generated "real" face can be treated as cues of attention for the fake feature learning. With the above ideas, an Off-real Attention Network (OA-Net) is proposed which allocates its attention to the spoof region of the input according to the anomalous cue. Extensive experiments on a total of nine public datasets show our method achieves state-of-the-art results under cross-domain evaluations with unseen scenarios and unknown presentation attacks. Besides, we provide theoretical analysis demonstrating the effectiveness of the proposed anomalous cues.
<div id='section'>Paperid: <span id='pid'>68, <a href='https://arxiv.org/pdf/2508.18085.pdf' target='_blank'>https://arxiv.org/pdf/2508.18085.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Abyad Enan, Mashrur Chowdhury, Sagar Dasgupta, Mizanur Rahman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.18085">Quantum-Classical Hybrid Framework for Zero-Day Time-Push GNSS Spoofing Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Global Navigation Satellite Systems (GNSS) are critical for Positioning, Navigation, and Timing (PNT) applications. However, GNSS are highly vulnerable to spoofing attacks, where adversaries transmit counterfeit signals to mislead receivers. Such attacks can lead to severe consequences, including misdirected navigation, compromised data integrity, and operational disruptions. Most existing spoofing detection methods depend on supervised learning techniques and struggle to detect novel, evolved, and unseen attacks. To overcome this limitation, we develop a zero-day spoofing detection method using a Hybrid Quantum-Classical Autoencoder (HQC-AE), trained solely on authentic GNSS signals without exposure to spoofed data. By leveraging features extracted during the tracking stage, our method enables proactive detection before PNT solutions are computed. We focus on spoofing detection in static GNSS receivers, which are particularly susceptible to time-push spoofing attacks, where attackers manipulate timing information to induce incorrect time computations at the receiver. We evaluate our model against different unseen time-push spoofing attack scenarios: simplistic, intermediate, and sophisticated. Our analysis demonstrates that the HQC-AE consistently outperforms its classical counterpart, traditional supervised learning-based models, and existing unsupervised learning-based methods in detecting zero-day, unseen GNSS time-push spoofing attacks, achieving an average detection accuracy of 97.71% with an average false negative rate of 0.62% (when an attack occurs but is not detected). For sophisticated spoofing attacks, the HQC-AE attains an accuracy of 98.23% with a false negative rate of 1.85%. These findings highlight the effectiveness of our method in proactively detecting zero-day GNSS time-push spoofing attacks across various stationary GNSS receiver platforms.
<div id='section'>Paperid: <span id='pid'>69, <a href='https://arxiv.org/pdf/2205.14851.pdf' target='_blank'>https://arxiv.org/pdf/2205.14851.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Songlin Yang, Wei Wang, Chenye Xu, Ziwen He, Bo Peng, Jing Dong
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2205.14851">Exposing Fine-Grained Adversarial Vulnerability of Face Anti-Spoofing Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing aims to discriminate the spoofing face images (e.g., printed photos) from live ones. However, adversarial examples greatly challenge its credibility, where adding some perturbation noise can easily change the predictions. Previous works conducted adversarial attack methods to evaluate the face anti-spoofing performance without any fine-grained analysis that which model architecture or auxiliary feature is vulnerable to the adversary. To handle this problem, we propose a novel framework to expose the fine-grained adversarial vulnerability of the face anti-spoofing models, which consists of a multitask module and a semantic feature augmentation (SFA) module. The multitask module can obtain different semantic features for further evaluation, but only attacking these semantic features fails to reflect the discrimination-related vulnerability. We then design the SFA module to introduce the data distribution prior for more discrimination-related gradient directions for generating adversarial examples. Comprehensive experiments show that SFA module increases the attack success rate by nearly 40$\%$ on average. We conduct this fine-grained adversarial analysis on different annotations, geometric maps, and backbone networks (e.g., Resnet network). These fine-grained adversarial examples can be used for selecting robust backbone networks and auxiliary features. They also can be used for adversarial training, which makes it practical to further improve the accuracy and robustness of the face anti-spoofing models.
<div id='section'>Paperid: <span id='pid'>70, <a href='https://arxiv.org/pdf/2403.19334.pdf' target='_blank'>https://arxiv.org/pdf/2403.19334.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qianyu Zhou, Ke-Yue Zhang, Taiping Yao, Xuequan Lu, Shouhong Ding, Lizhuang Ma
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.19334">Test-Time Domain Generalization for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face Anti-Spoofing (FAS) is pivotal in safeguarding facial recognition systems against presentation attacks. While domain generalization (DG) methods have been developed to enhance FAS performance, they predominantly focus on learning domain-invariant features during training, which may not guarantee generalizability to unseen data that differs largely from the source distributions. Our insight is that testing data can serve as a valuable resource to enhance the generalizability beyond mere evaluation for DG FAS. In this paper, we introduce a novel Test-Time Domain Generalization (TTDG) framework for FAS, which leverages the testing data to boost the model's generalizability. Our method, consisting of Test-Time Style Projection (TTSP) and Diverse Style Shifts Simulation (DSSS), effectively projects the unseen data to the seen domain space. In particular, we first introduce the innovative TTSP to project the styles of the arbitrarily unseen samples of the testing distribution to the known source space of the training distributions. We then design the efficient DSSS to synthesize diverse style shifts via learnable style bases with two specifically designed losses in a hyperspherical feature space. Our method eliminates the need for model updates at the test time and can be seamlessly integrated into not only the CNN but also ViT backbones. Comprehensive experiments on widely used cross-domain FAS benchmarks demonstrate our method's state-of-the-art performance and effectiveness.
<div id='section'>Paperid: <span id='pid'>71, <a href='https://arxiv.org/pdf/2405.10357.pdf' target='_blank'>https://arxiv.org/pdf/2405.10357.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xin Qiao, Matteo Poggi, Pengchao Deng, Hao Wei, Chenyang Ge, Stefano Mattoccia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.10357">RGB Guided ToF Imaging System: A Survey of Deep Learning-based Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Integrating an RGB camera into a ToF imaging system has become a significant technique for perceiving the real world. The RGB guided ToF imaging system is crucial to several applications, including face anti-spoofing, saliency detection, and trajectory prediction. Depending on the distance of the working range, the implementation schemes of the RGB guided ToF imaging systems are different. Specifically, ToF sensors with a uniform field of illumination, which can output dense depth but have low resolution, are typically used for close-range measurements. In contrast, LiDARs, which emit laser pulses and can only capture sparse depth, are usually employed for long-range detection. In the two cases, depth quality improvement for RGB guided ToF imaging corresponds to two sub-tasks: guided depth super-resolution and guided depth completion. In light of the recent significant boost to the field provided by deep learning, this paper comprehensively reviews the works related to RGB guided ToF imaging, including network structures, learning strategies, evaluation metrics, benchmark datasets, and objective functions. Besides, we present quantitative comparisons of state-of-the-art methods on widely used benchmark datasets. Finally, we discuss future trends and the challenges in real applications for further research.
<div id='section'>Paperid: <span id='pid'>72, <a href='https://arxiv.org/pdf/2308.09302.pdf' target='_blank'>https://arxiv.org/pdf/2308.09302.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Penghui Wen, Kun Hu, Wenxi Yue, Sen Zhang, Wanlei Zhou, Zhiyong Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.09302">Robust Audio Anti-Spoofing with Fusion-Reconstruction Learning on Multi-Order Spectrograms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Robust audio anti-spoofing has been increasingly challenging due to the recent advancements on deepfake techniques. While spectrograms have demonstrated their capability for anti-spoofing, complementary information presented in multi-order spectral patterns have not been well explored, which limits their effectiveness for varying spoofing attacks. Therefore, we propose a novel deep learning method with a spectral fusion-reconstruction strategy, namely S2pecNet, to utilise multi-order spectral patterns for robust audio anti-spoofing representations. Specifically, spectral patterns up to second-order are fused in a coarse-to-fine manner and two branches are designed for the fine-level fusion from the spectral and temporal contexts. A reconstruction from the fused representation to the input spectrograms further reduces the potential fused information loss. Our method achieved the state-of-the-art performance with an EER of 0.77% on a widely used dataset: ASVspoof2019 LA Challenge.
<div id='section'>Paperid: <span id='pid'>73, <a href='https://arxiv.org/pdf/2308.02116.pdf' target='_blank'>https://arxiv.org/pdf/2308.02116.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiawei Chen, Xiao Yang, Heng Yin, Mingzhi Ma, Bihui Chen, Jianteng Peng, Yandong Guo, Zhaoxia Yin, Hang Su
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.02116">AdvFAS: A robust face anti-spoofing framework against adversarial examples</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Ensuring the reliability of face recognition systems against presentation attacks necessitates the deployment of face anti-spoofing techniques. Despite considerable advancements in this domain, the ability of even the most state-of-the-art methods to defend against adversarial examples remains elusive. While several adversarial defense strategies have been proposed, they typically suffer from constrained practicability due to inevitable trade-offs between universality, effectiveness, and efficiency. To overcome these challenges, we thoroughly delve into the coupled relationship between adversarial detection and face anti-spoofing. Based on this, we propose a robust face anti-spoofing framework, namely AdvFAS, that leverages two coupled scores to accurately distinguish between correctly detected and wrongly detected face images. Extensive experiments demonstrate the effectiveness of our framework in a variety of settings, including different attacks, datasets, and backbones, meanwhile enjoying high accuracy on clean examples. Moreover, we successfully apply the proposed method to detect real-world adversarial examples.
<div id='section'>Paperid: <span id='pid'>74, <a href='https://arxiv.org/pdf/2412.12032.pdf' target='_blank'>https://arxiv.org/pdf/2412.12032.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Gaojian Wang, Feng Lin, Tong Wu, Zhenguang Liu, Zhongjie Ba, Kui Ren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.12032">FSFM: A Generalizable Face Security Foundation Model via Self-Supervised Facial Representation Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work asks: with abundant, unlabeled real faces, how to learn a robust and transferable facial representation that boosts various face security tasks with respect to generalization performance? We make the first attempt and propose a self-supervised pretraining framework to learn fundamental representations of real face images, FSFM, that leverages the synergy between masked image modeling (MIM) and instance discrimination (ID). We explore various facial masking strategies for MIM and present a simple yet powerful CRFR-P masking, which explicitly forces the model to capture meaningful intra-region consistency and challenging inter-region coherency. Furthermore, we devise the ID network that naturally couples with MIM to establish underlying local-to-global correspondence via tailored self-distillation. These three learning objectives, namely 3C, empower encoding both local features and global semantics of real faces. After pretraining, a vanilla ViT serves as a universal vision foundation model for downstream face security tasks: cross-dataset deepfake detection, cross-domain face anti-spoofing, and unseen diffusion facial forgery detection. Extensive experiments on 10 public datasets demonstrate that our model transfers better than supervised pretraining, visual and facial self-supervised learning arts, and even outperforms task-specialized SOTA methods.
<div id='section'>Paperid: <span id='pid'>75, <a href='https://arxiv.org/pdf/2405.16940.pdf' target='_blank'>https://arxiv.org/pdf/2405.16940.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fengfan Zhou, Qianyu Zhou, Hefei Ling, Xuequan Lu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.16940">Adversarial Attacks on Both Face Recognition and Face Anti-spoofing Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Adversarial attacks on Face Recognition (FR) systems have demonstrated significant effectiveness against standalone FR models. However, their practicality diminishes in complete FR systems that incorporate Face Anti-Spoofing (FAS) models, as these models can detect and mitigate a substantial number of adversarial examples. To address this critical yet under-explored challenge, we introduce a novel attack setting that targets both FR and FAS models simultaneously, thereby enhancing the practicability of adversarial attacks on integrated FR systems. Specifically, we propose a new attack method, termed Reference-free Multi-level Alignment (RMA), designed to improve the capacity of black-box attacks on both FR and FAS models. The RMA framework is built upon three key components. Firstly, we propose an Adaptive Gradient Maintenance module to address the imbalances in gradient contributions between FR and FAS models. Secondly, we develop a Reference-free Intermediate Biasing module to improve the transferability of adversarial examples against FAS models. In addition, we introduce a Multi-level Feature Alignment module to reduce feature discrepancies at various levels of representation. Extensive experiments showcase the superiority of our proposed attack method to state-of-the-art adversarial attacks.
<div id='section'>Paperid: <span id='pid'>76, <a href='https://arxiv.org/pdf/2506.06756.pdf' target='_blank'>https://arxiv.org/pdf/2506.06756.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Bikash Dutta, Rishabh Ranjan, Shyam Sathvik, Mayank Vatsa, Richa Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.06756">Can Quantized Audio Language Models Perform Zero-Shot Spoofing Detection?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Quantization is essential for deploying large audio language models (LALMs) efficiently in resource-constrained environments. However, its impact on complex tasks, such as zero-shot audio spoofing detection, remains underexplored. This study evaluates the zero-shot capabilities of five LALMs, GAMA, LTU-AS, MERaLiON, Qwen-Audio, and SALMONN, across three distinct datasets: ASVspoof2019, In-the-Wild, and WaveFake, and investigates their robustness to quantization (FP32, FP16, INT8). Despite high initial spoof detection accuracy, our analysis demonstrates severe predictive biases toward spoof classification across all models, rendering their practical performance equivalent to random classification. Interestingly, quantization to FP16 precision resulted in negligible performance degradation compared to FP32, effectively halving memory and computational requirements without materially impacting accuracy. However, INT8 quantization intensified model biases, significantly degrading balanced accuracy. These findings highlight critical architectural limitations and emphasize FP16 quantization as an optimal trade-off, providing guidelines for practical deployment and future model refinement.
<div id='section'>Paperid: <span id='pid'>77, <a href='https://arxiv.org/pdf/2406.17246.pdf' target='_blank'>https://arxiv.org/pdf/2406.17246.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hye-jin Shim, Md Sahidullah, Jee-weon Jung, Shinji Watanabe, Tomi Kinnunen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.17246">Beyond Silence: Bias Analysis through Loss and Asymmetric Approach in Audio Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current trends in audio anti-spoofing detection research strive to improve models' ability to generalize across unseen attacks by learning to identify a variety of spoofing artifacts. This emphasis has primarily focused on the spoof class. Recently, several studies have noted that the distribution of silence differs between the two classes, which can serve as a shortcut. In this paper, we extend class-wise interpretations beyond silence. We employ loss analysis and asymmetric methodologies to move away from traditional attack-focused and result-oriented evaluations towards a deeper examination of model behaviors. Our investigations highlight the significant differences in training dynamics between the two classes, emphasizing the need for future research to focus on robust modeling of the bonafide class.
<div id='section'>Paperid: <span id='pid'>78, <a href='https://arxiv.org/pdf/2404.06211.pdf' target='_blank'>https://arxiv.org/pdf/2404.06211.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haocheng Yuan, Ajian Liu, Junze Zheng, Jun Wan, Jiankang Deng, Sergio Escalera, Hugo Jair Escalante, Isabelle Guyon, Zhen Lei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06211">Unified Physical-Digital Attack Detection Challenge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face Anti-Spoofing (FAS) is crucial to safeguard Face Recognition (FR) Systems. In real-world scenarios, FRs are confronted with both physical and digital attacks. However, existing algorithms often address only one type of attack at a time, which poses significant limitations in real-world scenarios where FR systems face hybrid physical-digital threats. To facilitate the research of Unified Attack Detection (UAD) algorithms, a large-scale UniAttackData dataset has been collected. UniAttackData is the largest public dataset for Unified Attack Detection, with a total of 28,706 videos, where each unique identity encompasses all advanced attack types. Based on this dataset, we organized a Unified Physical-Digital Face Attack Detection Challenge to boost the research in Unified Attack Detections. It attracted 136 teams for the development phase, with 13 qualifying for the final round. The results re-verified by the organizing team were used for the final ranking. This paper comprehensively reviews the challenge, detailing the dataset introduction, protocol definition, evaluation criteria, and a summary of published results. Finally, we focus on the detailed analysis of the highest-performing algorithms and offer potential directions for unified physical-digital attack detection inspired by this competition. Challenge Website: https://sites.google.com/view/face-anti-spoofing-challenge/welcome/challengecvpr2024.
<div id='section'>Paperid: <span id='pid'>79, <a href='https://arxiv.org/pdf/2403.14333.pdf' target='_blank'>https://arxiv.org/pdf/2403.14333.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ajian Liu, Shuai Xue, Jianwen Gan, Jun Wan, Yanyan Liang, Jiankang Deng, Sergio Escalera, Zhen Lei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.14333">CFPL-FAS: Class Free Prompt Learning for Generalizable Face Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Domain generalization (DG) based Face Anti-Spoofing (FAS) aims to improve the model's performance on unseen domains. Existing methods either rely on domain labels to align domain-invariant feature spaces, or disentangle generalizable features from the whole sample, which inevitably lead to the distortion of semantic feature structures and achieve limited generalization. In this work, we make use of large-scale VLMs like CLIP and leverage the textual feature to dynamically adjust the classifier's weights for exploring generalizable visual features. Specifically, we propose a novel Class Free Prompt Learning (CFPL) paradigm for DG FAS, which utilizes two lightweight transformers, namely Content Q-Former (CQF) and Style Q-Former (SQF), to learn the different semantic prompts conditioned on content and style features by using a set of learnable query vectors, respectively. Thus, the generalizable prompt can be learned by two improvements: (1) A Prompt-Text Matched (PTM) supervision is introduced to ensure CQF learns visual representation that is most informative of the content description. (2) A Diversified Style Prompt (DSP) technology is proposed to diversify the learning of style prompts by mixing feature statistics between instance-specific styles. Finally, the learned text features modulate visual features to generalization through the designed Prompt Modulation (PM). Extensive experiments show that the CFPL is effective and outperforms the state-of-the-art methods on several cross-domain datasets.
<div id='section'>Paperid: <span id='pid'>80, <a href='https://arxiv.org/pdf/2307.06669.pdf' target='_blank'>https://arxiv.org/pdf/2307.06669.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rishabh Ranjan, Mayank Vatsa, Richa Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.06669">Uncovering the Deceptions: An Analysis on Audio Spoofing Detection and Future Prospects</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Audio has become an increasingly crucial biometric modality due to its ability to provide an intuitive way for humans to interact with machines. It is currently being used for a range of applications, including person authentication to banking to virtual assistants. Research has shown that these systems are also susceptible to spoofing and attacks. Therefore, protecting audio processing systems against fraudulent activities, such as identity theft, financial fraud, and spreading misinformation, is of paramount importance. This paper reviews the current state-of-the-art techniques for detecting audio spoofing and discusses the current challenges along with open research problems. The paper further highlights the importance of considering the ethical and privacy implications of audio spoofing detection systems. Lastly, the work aims to accentuate the need for building more robust and generalizable methods, the integration of automatic speaker verification and countermeasure systems, and better evaluation protocols.
<div id='section'>Paperid: <span id='pid'>81, <a href='https://arxiv.org/pdf/2305.09285.pdf' target='_blank'>https://arxiv.org/pdf/2305.09285.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qinghong Sun, Zhenfei Yin, Yichao Wu, Yuanhan Zhang, Jing Shao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.09285">Latent Distribution Adjusting for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the development of deep learning, the field of face anti-spoofing (FAS) has witnessed great progress. FAS is usually considered a classification problem, where each class is assumed to contain a single cluster optimized by softmax loss. In practical deployment, one class can contain several local clusters, and a single-center is insufficient to capture the inherent structure of the FAS data. However, few approaches consider large distribution discrepancies in the field of FAS. In this work, we propose a unified framework called Latent Distribution Adjusting (LDA) with properties of latent, discriminative, adaptive, generic to improve the robustness of the FAS model by adjusting complex data distribution with multiple prototypes. 1) Latent. LDA attempts to model the data of each class as a Gaussian mixture distribution, and acquire a flexible number of centers for each class in the last fully connected layer implicitly. 2) Discriminative. To enhance the intra-class compactness and inter-class discrepancy, we propose a margin-based loss for providing distribution constrains for prototype learning. 3) Adaptive. To make LDA more efficient and decrease redundant parameters, we propose Adaptive Prototype Selection (APS) by selecting the appropriate number of centers adaptively according to different distributions. 4) Generic. Furthermore, LDA can adapt to unseen distribution by utilizing very few training data without re-training. Extensive experiments demonstrate that our framework can 1) make the final representation space both intra-class compact and inter-class separable, 2) outperform the state-of-the-art methods on multiple standard FAS benchmarks.
<div id='section'>Paperid: <span id='pid'>82, <a href='https://arxiv.org/pdf/2305.03277.pdf' target='_blank'>https://arxiv.org/pdf/2305.03277.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ajian Liu, Zichang Tan, Zitong Yu, Chenxu Zhao, Jun Wan, Yanyan Liang, Zhen Lei, Du Zhang, Stan Z. Li, Guodong Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.03277">FM-ViT: Flexible Modal Vision Transformers for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The availability of handy multi-modal (i.e., RGB-D) sensors has brought about a surge of face anti-spoofing research. However, the current multi-modal face presentation attack detection (PAD) has two defects: (1) The framework based on multi-modal fusion requires providing modalities consistent with the training input, which seriously limits the deployment scenario. (2) The performance of ConvNet-based model on high fidelity datasets is increasingly limited. In this work, we present a pure transformer-based framework, dubbed the Flexible Modal Vision Transformer (FM-ViT), for face anti-spoofing to flexibly target any single-modal (i.e., RGB) attack scenarios with the help of available multi-modal data. Specifically, FM-ViT retains a specific branch for each modality to capture different modal information and introduces the Cross-Modal Transformer Block (CMTB), which consists of two cascaded attentions named Multi-headed Mutual-Attention (MMA) and Fusion-Attention (MFA) to guide each modal branch to mine potential features from informative patch tokens, and to learn modality-agnostic liveness features by enriching the modal information of own CLS token, respectively. Experiments demonstrate that the single model trained based on FM-ViT can not only flexibly evaluate different modal samples, but also outperforms existing single-modal frameworks by a large margin, and approaches the multi-modal frameworks introduced with smaller FLOPs and model parameters.
<div id='section'>Paperid: <span id='pid'>83, <a href='https://arxiv.org/pdf/2304.07580.pdf' target='_blank'>https://arxiv.org/pdf/2304.07580.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Fang, Ajian Liu, Jun Wan, Sergio Escalera, Hugo Jair Escalante, Zhen Lei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.07580">Surveillance Face Presentation Attack Detection Challenge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face Anti-spoofing (FAS) is essential to secure face recognition systems from various physical attacks. However, most of the studies lacked consideration of long-distance scenarios. Specifically, compared with FAS in traditional scenes such as phone unlocking, face payment, and self-service security inspection, FAS in long-distance such as station squares, parks, and self-service supermarkets are equally important, but it has not been sufficiently explored yet. In order to fill this gap in the FAS community, we collect a large-scale Surveillance High-Fidelity Mask (SuHiFiMask). SuHiFiMask contains $10,195$ videos from $101$ subjects of different age groups, which are collected by $7$ mainstream surveillance cameras. Based on this dataset and protocol-$3$ for evaluating the robustness of the algorithm under quality changes, we organized a face presentation attack detection challenge in surveillance scenarios. It attracted 180 teams for the development phase with a total of 37 teams qualifying for the final round. The organization team re-verified and re-ran the submitted code and used the results as the final ranking. In this paper, we present an overview of the challenge, including an introduction to the dataset used, the definition of the protocol, the evaluation metrics, and the announcement of the competition results. Finally, we present the top-ranked algorithms and the research ideas provided by the competition for attack detection in long-range surveillance scenarios.
<div id='section'>Paperid: <span id='pid'>84, <a href='https://arxiv.org/pdf/2304.05753.pdf' target='_blank'>https://arxiv.org/pdf/2304.05753.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dong Wang, Jia Guo, Qiqi Shao, Haochi He, Zhian Chen, Chuanbao Xiao, Ajian Liu, Sergio Escalera, Hugo Jair Escalante, Zhen Lei, Jun Wan, Jiankang Deng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.05753">Wild Face Anti-Spoofing Challenge 2023: Benchmark and Results</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) is an essential mechanism for safeguarding the integrity of automated face recognition systems. Despite substantial advancements, the generalization of existing approaches to real-world applications remains challenging. This limitation can be attributed to the scarcity and lack of diversity in publicly available FAS datasets, which often leads to overfitting during training or saturation during testing. In terms of quantity, the number of spoof subjects is a critical determinant. Most datasets comprise fewer than 2,000 subjects. With regard to diversity, the majority of datasets consist of spoof samples collected in controlled environments using repetitive, mechanical processes. This data collection methodology results in homogenized samples and a dearth of scenario diversity. To address these shortcomings, we introduce the Wild Face Anti-Spoofing (WFAS) dataset, a large-scale, diverse FAS dataset collected in unconstrained settings. Our dataset encompasses 853,729 images of 321,751 spoof subjects and 529,571 images of 148,169 live subjects, representing a substantial increase in quantity. Moreover, our dataset incorporates spoof data obtained from the internet, spanning a wide array of scenarios and various commercial sensors, including 17 presentation attacks (PAs) that encompass both 2D and 3D forms. This novel data collection strategy markedly enhances FAS data diversity. Leveraging the WFAS dataset and Protocol 1 (Known-Type), we host the Wild Face Anti-Spoofing Challenge at the CVPR2023 workshop. Additionally, we meticulously evaluate representative methods using Protocol 1 and Protocol 2 (Unknown-Type). Through an in-depth examination of the challenge outcomes and benchmark baselines, we provide insightful analyses and propose potential avenues for future research. The dataset is released under Insightface.
<div id='section'>Paperid: <span id='pid'>85, <a href='https://arxiv.org/pdf/2301.00975.pdf' target='_blank'>https://arxiv.org/pdf/2301.00975.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hao Fang, Ajian Liu, Jun Wan, Sergio Escalera, Chenxu Zhao, Xu Zhang, Stan Z. Li, Zhen Lei
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.00975">Surveillance Face Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face Anti-spoofing (FAS) is essential to secure face recognition systems from various physical attacks. However, recent research generally focuses on short-distance applications (i.e., phone unlocking) while lacking consideration of long-distance scenes (i.e., surveillance security checks). In order to promote relevant research and fill this gap in the community, we collect a large-scale Surveillance High-Fidelity Mask (SuHiFiMask) dataset captured under 40 surveillance scenes, which has 101 subjects from different age groups with 232 3D attacks (high-fidelity masks), 200 2D attacks (posters, portraits, and screens), and 2 adversarial attacks. In this scene, low image resolution and noise interference are new challenges faced in surveillance FAS. Together with the SuHiFiMask dataset, we propose a Contrastive Quality-Invariance Learning (CQIL) network to alleviate the performance degradation caused by image quality from three aspects: (1) An Image Quality Variable module (IQV) is introduced to recover image information associated with discrimination by combining the super-resolution network. (2) Using generated sample pairs to simulate quality variance distributions to help contrastive learning strategies obtain robust feature representation under quality variation. (3) A Separate Quality Network (SQN) is designed to learn discriminative features independent of image quality. Finally, a large number of experiments verify the quality of the SuHiFiMask dataset and the superiority of the proposed CQIL.
<div id='section'>Paperid: <span id='pid'>86, <a href='https://arxiv.org/pdf/2507.08227.pdf' target='_blank'>https://arxiv.org/pdf/2507.08227.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yang Xiao, Ting Dang, Rohan Kumar Das
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.08227">RawTFNet: A Lightweight CNN Architecture for Speech Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic speaker verification (ASV) systems are often affected by spoofing attacks. Recent transformer-based models have improved anti-spoofing performance by learning strong feature representations. However, these models usually need high computing power. To address this, we introduce RawTFNet, a lightweight CNN model designed for audio signals. The RawTFNet separates feature processing along time and frequency dimensions, which helps to capture the fine-grained details of synthetic speech. We tested RawTFNet on the ASVspoof 2021 LA and DF evaluation datasets. The results show that RawTFNet reaches comparable performance to that of the state-of-the-art models, while also using fewer computing resources. The code and models will be made publicly available.
<div id='section'>Paperid: <span id='pid'>87, <a href='https://arxiv.org/pdf/2505.09484.pdf' target='_blank'>https://arxiv.org/pdf/2505.09484.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yingjie Ma, Xun Lin, Zitong Yu, Xin Liu, Xiaochen Yuan, Weicheng Xie, Linlin Shen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.09484">Denoising and Alignment: Rethinking Domain Generalization for Multimodal Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face Anti-Spoofing (FAS) is essential for the security of facial recognition systems in diverse scenarios such as payment processing and surveillance. Current multimodal FAS methods often struggle with effective generalization, mainly due to modality-specific biases and domain shifts. To address these challenges, we introduce the \textbf{M}ulti\textbf{m}odal \textbf{D}enoising and \textbf{A}lignment (\textbf{MMDA}) framework. By leveraging the zero-shot generalization capability of CLIP, the MMDA framework effectively suppresses noise in multimodal data through denoising and alignment mechanisms, thereby significantly enhancing the generalization performance of cross-modal alignment. The \textbf{M}odality-\textbf{D}omain Joint \textbf{D}ifferential \textbf{A}ttention (\textbf{MD2A}) module in MMDA concurrently mitigates the impacts of domain and modality noise by refining the attention mechanism based on extracted common noise features. Furthermore, the \textbf{R}epresentation \textbf{S}pace \textbf{S}oft (\textbf{RS2}) Alignment strategy utilizes the pre-trained CLIP model to align multi-domain multimodal data into a generalized representation space in a flexible manner, preserving intricate representations and enhancing the model's adaptability to various unseen conditions. We also design a \textbf{U}-shaped \textbf{D}ual \textbf{S}pace \textbf{A}daptation (\textbf{U-DSA}) module to enhance the adaptability of representations while maintaining generalization performance. These improvements not only enhance the framework's generalization capabilities but also boost its ability to represent complex representations. Our experimental results on four benchmark datasets under different evaluation protocols demonstrate that the MMDA framework outperforms existing state-of-the-art methods in terms of cross-domain generalization and multimodal detection accuracy. The code will be released soon.
<div id='section'>Paperid: <span id='pid'>88, <a href='https://arxiv.org/pdf/2509.21676.pdf' target='_blank'>https://arxiv.org/pdf/2509.21676.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aurosweta Mahapatra, Ismail Rasim Ulgen, Berrak Sisman
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21676">HuLA: Prosody-Aware Anti-Spoofing with Multi-Task Learning for Expressive and Emotional Synthetic Speech</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current anti-spoofing systems remain vulnerable to expressive and emotional synthetic speech, since they rarely leverage prosody as a discriminative cue. Prosody is central to human expressiveness and emotion, and humans instinctively use prosodic cues such as F0 patterns and voiced/unvoiced structure to distinguish natural from synthetic speech. In this paper, we propose HuLA, a two-stage prosody-aware multi-task learning framework for spoof detection. In Stage 1, a self-supervised learning (SSL) backbone is trained on real speech with auxiliary tasks of F0 prediction and voiced/unvoiced classification, enhancing its ability to capture natural prosodic variation similar to human perceptual learning. In Stage 2, the model is jointly optimized for spoof detection and prosody tasks on both real and synthetic data, leveraging prosodic awareness to detect mismatches between natural and expressive synthetic speech. Experiments show that HuLA consistently outperforms strong baselines on challenging out-of-domain dataset, including expressive, emotional, and cross-lingual attacks. These results demonstrate that explicit prosodic supervision, combined with SSL embeddings, substantially improves robustness against advanced synthetic speech attacks.
<div id='section'>Paperid: <span id='pid'>89, <a href='https://arxiv.org/pdf/2507.03468.pdf' target='_blank'>https://arxiv.org/pdf/2507.03468.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hieu-Thi Luong, Inbal Rimon, Haim Permuter, Kong Aik Lee, Eng Siong Chng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.03468">Robust Localization of Partially Fake Speech: Metrics and Out-of-Domain Evaluation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Partial audio deepfake localization poses unique challenges and remain underexplored compared to full-utterance spoofing detection. While recent methods report strong in-domain performance, their real-world utility remains unclear. In this analysis, we critically examine the limitations of current evaluation practices, particularly the widespread use of Equal Error Rate (EER), which often obscures generalization and deployment readiness. We propose reframing the localization task as a sequential anomaly detection problem and advocate for the use of threshold-dependent metrics such as accuracy, precision, recall, and F1-score, which better reflect real-world behavior. Specifically, we analyze the performance of the open-source Coarse-to-Fine Proposal Refinement Framework (CFPRF), which achieves a 20-ms EER of 7.61% on the in-domain PartialSpoof evaluation set, but 43.25% and 27.59% on the LlamaPartialSpoof and Half-Truth out-of-domain test sets. Interestingly, our reproduced version of the same model performs worse on in-domain data (9.84%) but better on the out-of-domain sets (41.72% and 14.98%, respectively). This highlights the risks of over-optimizing for in-domain EER, which can lead to models that perform poorly in real-world scenarios. It also suggests that while deep learning models can be effective on in-domain data, they generalize poorly to out-of-domain scenarios, failing to detect novel synthetic samples and misclassifying unfamiliar bona fide audio. Finally, we observe that adding more bona fide or fully synthetic utterances to the training data often degrades performance, whereas adding partially fake utterances improves it.
<div id='section'>Paperid: <span id='pid'>90, <a href='https://arxiv.org/pdf/2412.18191.pdf' target='_blank'>https://arxiv.org/pdf/2412.18191.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuechen Liu, Junichi Yamagishi, Md Sahidullah, Tomi kinnunen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.18191">Explaining Speaker and Spoof Embeddings via Probing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study investigates the explainability of embedding representations, specifically those used in modern audio spoofing detection systems based on deep neural networks, known as spoof embeddings. Building on established work in speaker embedding explainability, we examine how well these spoof embeddings capture speaker-related information. We train simple neural classifiers using either speaker or spoof embeddings as input, with speaker-related attributes as target labels. These attributes are categorized into two groups: metadata-based traits (e.g., gender, age) and acoustic traits (e.g., fundamental frequency, speaking rate). Our experiments on the ASVspoof 2019 LA evaluation set demonstrate that spoof embeddings preserve several key traits, including gender, speaking rate, F0, and duration. Further analysis of gender and speaking rate indicates that the spoofing detector partially preserves these traits, potentially to ensure the decision process remains robust against them.
<div id='section'>Paperid: <span id='pid'>91, <a href='https://arxiv.org/pdf/2409.14712.pdf' target='_blank'>https://arxiv.org/pdf/2409.14712.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hieu-Thi Luong, Duc-Tuan Truong, Kong Aik Lee, Eng Siong Chng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.14712">Room Impulse Responses help attackers to evade Deep Fake Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The ASVspoof 2021 benchmark, a widely-used evaluation framework for anti-spoofing, consists of two subsets: Logical Access (LA) and Deepfake (DF), featuring samples with varied coding characteristics and compression artifacts. Notably, the current state-of-the-art (SOTA) system boasts impressive performance, achieving an Equal Error Rate (EER) of 0.87% on the LA subset and 2.58% on the DF. However, benchmark accuracy is no guarantee of robustness in real-world scenarios. This paper investigates the effectiveness of utilizing room impulse responses (RIRs) to enhance fake speech and increase their likelihood of evading fake speech detection systems. Our findings reveal that this simple approach significantly improves the evasion rate, doubling the SOTA system's EER. To counter this type of attack, We augmented training data with a large-scale synthetic/simulated RIR dataset. The results demonstrate significant improvement on both reverberated fake speech and original samples, reducing DF task EER to 2.13%.
<div id='section'>Paperid: <span id='pid'>92, <a href='https://arxiv.org/pdf/2309.07736.pdf' target='_blank'>https://arxiv.org/pdf/2309.07736.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ning Gao, Shuchen Meng, Cen Li, Shengguo Meng, Wankai Tang, Shi Jin, Michail Matthaiou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.07736">RIS-Assisted Wireless Link Signatures for Specific Emitter Identification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The physical layer authentication (PLA) is a promising technology which can enhance the access security of a massive number of devices in the near future. In this paper, we propose a reconfigurable intelligent surface (RIS)-assisted PLA system, in which the legitimate transmitter can customize the channel fingerprints during PLA by controlling the ON-OFF state of the RIS. Without loss of generality, we use the received signal strength (RSS) based spoofing detection approach to analyze the feasibility of the proposed architecture. Specifically, based on the RSS, we derive the statistical properties of PLA and give some interesting insights, which showcase that the RIS-assisted PLA is theoretically feasible. Then, we derive the optimal detection threshold to maximize the performance in the context of the presented performance metrics. Next, the actual feasibility of the proposed system is verified via proof-of-concept experiments on a RIS-assisted PLA prototype platform. The experiment results show that there are 3.5% and 76% performance improvements when the transmission sources are at different locations and at the same location, respectively.
<div id='section'>Paperid: <span id='pid'>93, <a href='https://arxiv.org/pdf/2409.08346.pdf' target='_blank'>https://arxiv.org/pdf/2409.08346.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianchi Liu, Ivan Kukanov, Zihan Pan, Qiongqiong Wang, Hardik B. Sailor, Kong Aik Lee
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.08346">Towards Quantifying and Reducing Language Mismatch Effects in Cross-Lingual Speech Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The effects of language mismatch impact speech anti-spoofing systems, while investigations and quantification of these effects remain limited. Existing anti-spoofing datasets are mainly in English, and the high cost of acquiring multilingual datasets hinders training language-independent models. We initiate this work by evaluating top-performing speech anti-spoofing systems that are trained on English data but tested on other languages, observing notable performance declines. We propose an innovative approach - Accent-based data expansion via TTS (ACCENT), which introduces diverse linguistic knowledge to monolingual-trained models, improving their cross-lingual capabilities. We conduct experiments on a large-scale dataset consisting of over 3 million samples, including 1.8 million training samples and nearly 1.2 million testing samples across 12 languages. The language mismatch effects are preliminarily quantified and remarkably reduced over 15% by applying the proposed ACCENT. This easily implementable method shows promise for multilingual and low-resource language scenarios.
<div id='section'>Paperid: <span id='pid'>94, <a href='https://arxiv.org/pdf/2401.01102.pdf' target='_blank'>https://arxiv.org/pdf/2401.01102.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhe Kong, Wentian Zhang, Tao Wang, Kaihao Zhang, Yuexiang Li, Xiaoying Tang, Wenhan Luo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.01102">Dual Teacher Knowledge Distillation with Domain Alignment for Face Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition systems have raised concerns due to their vulnerability to different presentation attacks, and system security has become an increasingly critical concern. Although many face anti-spoofing (FAS) methods perform well in intra-dataset scenarios, their generalization remains a challenge. To address this issue, some methods adopt domain adversarial training (DAT) to extract domain-invariant features. However, the competition between the encoder and the domain discriminator can cause the network to be difficult to train and converge. In this paper, we propose a domain adversarial attack (DAA) method to mitigate the training instability problem by adding perturbations to the input images, which makes them indistinguishable across domains and enables domain alignment. Moreover, since models trained on limited data and types of attacks cannot generalize well to unknown attacks, we propose a dual perceptual and generative knowledge distillation framework for face anti-spoofing that utilizes pre-trained face-related models containing rich face priors. Specifically, we adopt two different face-related models as teachers to transfer knowledge to the target student model. The pre-trained teacher models are not from the task of face anti-spoofing but from perceptual and generative tasks, respectively, which implicitly augment the data. By combining both DAA and dual-teacher knowledge distillation, we develop a dual teacher knowledge distillation with domain alignment framework (DTDA) for face anti-spoofing. The advantage of our proposed method has been verified through extensive ablation studies and comparison with state-of-the-art methods on public datasets across multiple protocols.
<div id='section'>Paperid: <span id='pid'>95, <a href='https://arxiv.org/pdf/2306.14313.pdf' target='_blank'>https://arxiv.org/pdf/2306.14313.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chih-Jung Chang, Yaw-Chern Lee, Shih-Hsuan Yao, Min-Hung Chen, Chien-Yi Wang, Shang-Hong Lai, Trista Pei-Chun Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.14313">A Closer Look at Geometric Temporal Dynamics for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) is indispensable for a face recognition system. Many texture-driven countermeasures were developed against presentation attacks (PAs), but the performance against unseen domains or unseen spoofing types is still unsatisfactory. Instead of exhaustively collecting all the spoofing variations and making binary decisions of live/spoof, we offer a new perspective on the FAS task to distinguish between normal and abnormal movements of live and spoof presentations. We propose Geometry-Aware Interaction Network (GAIN), which exploits dense facial landmarks with spatio-temporal graph convolutional network (ST-GCN) to establish a more interpretable and modularized FAS model. Additionally, with our cross-attention feature interaction mechanism, GAIN can be easily integrated with other existing methods to significantly boost performance. Our approach achieves state-of-the-art performance in the standard intra- and cross-dataset evaluations. Moreover, our model outperforms state-of-the-art methods by a large margin in the cross-dataset cross-type protocol on CASIA-SURF 3DMask (+10.26% higher AUC score), exhibiting strong robustness against domain shifts and unseen spoofing types.
<div id='section'>Paperid: <span id='pid'>96, <a href='https://arxiv.org/pdf/2302.05744.pdf' target='_blank'>https://arxiv.org/pdf/2302.05744.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zitong Yu, Rizhao Cai, Yawen Cui, Xin Liu, Yongjian Hu, Alex Kot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.05744">Rethinking Vision Transformer and Masked Autoencoder in Multimodal Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, vision transformer (ViT) based multimodal learning methods have been proposed to improve the robustness of face anti-spoofing (FAS) systems. However, there are still no works to explore the fundamental natures (\textit{e.g.}, modality-aware inputs, suitable multimodal pre-training, and efficient finetuning) in vanilla ViT for multimodal FAS. In this paper, we investigate three key factors (i.e., inputs, pre-training, and finetuning) in ViT for multimodal FAS with RGB, Infrared (IR), and Depth. First, in terms of the ViT inputs, we find that leveraging local feature descriptors benefits the ViT on IR modality but not RGB or Depth modalities. Second, in observation of the inefficiency on direct finetuning the whole or partial ViT, we design an adaptive multimodal adapter (AMA), which can efficiently aggregate local multimodal features while freezing majority of ViT parameters. Finally, in consideration of the task (FAS vs. generic object classification) and modality (multimodal vs. unimodal) gaps, ImageNet pre-trained models might be sub-optimal for the multimodal FAS task. To bridge these gaps, we propose the modality-asymmetric masked autoencoder (M$^{2}$A$^{2}$E) for multimodal FAS self-supervised pre-training without costly annotated labels. Compared with the previous modality-symmetric autoencoder, the proposed M$^{2}$A$^{2}$E is able to learn more intrinsic task-aware representation and compatible with modality-agnostic (e.g., unimodal, bimodal, and trimodal) downstream settings. Extensive experiments with both unimodal (RGB, Depth, IR) and multimodal (RGB+Depth, RGB+IR, Depth+IR, RGB+Depth+IR) settings conducted on multimodal FAS benchmarks demonstrate the superior performance of the proposed methods. We hope these findings and solutions can facilitate the future research for ViT-based multimodal FAS.
<div id='section'>Paperid: <span id='pid'>97, <a href='https://arxiv.org/pdf/2407.08514.pdf' target='_blank'>https://arxiv.org/pdf/2407.08514.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxin Cao, Yumeng Zhu, Derui Wang, Sheng Wen, Minhui Xue, Jin Lu, Hao Ge
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.08514">Rethinking the Threat and Accessibility of Adversarial Attacks against Face Recognition Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition pipelines have been widely deployed in various mission-critical systems in trust, equitable and responsible AI applications. However, the emergence of adversarial attacks has threatened the security of the entire recognition pipeline. Despite the sheer number of attack methods proposed for crafting adversarial examples in both digital and physical forms, it is never an easy task to assess the real threat level of different attacks and obtain useful insight into the key risks confronted by face recognition systems. Traditional attacks view imperceptibility as the most important measurement to keep perturbations stealthy, while we suspect that industry professionals may possess a different opinion. In this paper, we delve into measuring the threat brought about by adversarial attacks from the perspectives of the industry and the applications of face recognition. In contrast to widely studied sophisticated attacks in the field, we propose an effective yet easy-to-launch physical adversarial attack, named AdvColor, against black-box face recognition pipelines in the physical world. AdvColor fools models in the recognition pipeline via directly supplying printed photos of human faces to the system under adversarial illuminations. Experimental results show that physical AdvColor examples can achieve a fooling rate of more than 96% against the anti-spoofing model and an overall attack success rate of 88% against the face recognition pipeline. We also conduct a survey on the threats of prevailing adversarial attacks, including AdvColor, to understand the gap between the machine-measured and human-assessed threat levels of different forms of adversarial attacks. The survey results surprisingly indicate that, compared to deliberately launched imperceptible attacks, perceptible but accessible attacks pose more lethal threats to real-world commercial systems of face recognition.
<div id='section'>Paperid: <span id='pid'>98, <a href='https://arxiv.org/pdf/2406.10283.pdf' target='_blank'>https://arxiv.org/pdf/2406.10283.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zihan Pan, Tianchi Liu, Hardik B. Sailor, Qiongqiong Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.10283">Attentive Merging of Hidden Embeddings from Pre-trained Speech Model for Anti-spoofing Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised learning (SSL) speech representation models, trained on large speech corpora, have demonstrated effectiveness in extracting hierarchical speech embeddings through multiple transformer layers. However, the behavior of these embeddings in specific tasks remains uncertain. This paper investigates the multi-layer behavior of the WavLM model in anti-spoofing and proposes an attentive merging method to leverage the hierarchical hidden embeddings. Results demonstrate the feasibility of fine-tuning WavLM to achieve the best equal error rate (EER) of 0.65%, 3.50%, and 3.19% on the ASVspoof 2019LA, 2021LA, and 2021DF evaluation sets, respectively. Notably, We find that the early hidden transformer layers of the WavLM large model contribute significantly to anti-spoofing task, enabling computational efficiency by utilizing a partial pre-trained model.
<div id='section'>Paperid: <span id='pid'>99, <a href='https://arxiv.org/pdf/2310.16569.pdf' target='_blank'>https://arxiv.org/pdf/2310.16569.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxin Cao, Yian Li, Yumeng Zhu, Derui Wang, Minhui Xue
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.16569">Flow-Attention-based Spatio-Temporal Aggregation Network for 3D Mask Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Anti-spoofing detection has become a necessity for face recognition systems due to the security threat posed by spoofing attacks. Despite great success in traditional attacks, most deep-learning-based methods perform poorly in 3D masks, which can highly simulate real faces in appearance and structure, suffering generalizability insufficiency while focusing only on the spatial domain with single frame input. This has been mitigated by the recent introduction of a biomedical technology called rPPG (remote photoplethysmography). However, rPPG-based methods are sensitive to noisy interference and require at least one second (> 25 frames) of observation time, which induces high computational overhead. To address these challenges, we propose a novel 3D mask detection framework, called FASTEN (Flow-Attention-based Spatio-Temporal aggrEgation Network). We tailor the network for focusing more on fine-grained details in large movements, which can eliminate redundant spatio-temporal feature interference and quickly capture splicing traces of 3D masks in fewer frames. Our proposed network contains three key modules: 1) a facial optical flow network to obtain non-RGB inter-frame flow information; 2) flow attention to assign different significance to each frame; 3) spatio-temporal aggregation to aggregate high-level spatial features and temporal transition features. Through extensive experiments, FASTEN only requires five frames of input and outperforms eight competitors for both intra-dataset and cross-dataset evaluations in terms of multiple detection metrics. Moreover, FASTEN has been deployed in real-world mobile devices for practical 3D mask detection.
<div id='section'>Paperid: <span id='pid'>100, <a href='https://arxiv.org/pdf/2510.05562.pdf' target='_blank'>https://arxiv.org/pdf/2510.05562.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sheng Xiang, Yidong Jiang, Yunting Chen, Dawei Cheng, Guoping Zhao, Changjun Jiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.05562">Generative Dynamic Graph Representation Learning for Conspiracy Spoofing Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spoofing detection in financial trading is crucial, especially for identifying complex behaviors such as conspiracy spoofing. Traditional machine-learning approaches primarily focus on isolated node features, often overlooking the broader context of interconnected nodes. Graph-based techniques, particularly Graph Neural Networks (GNNs), have advanced the field by leveraging relational information effectively. However, in real-world spoofing detection datasets, trading behaviors exhibit dynamic, irregular patterns. Existing spoofing detection methods, though effective in some scenarios, struggle to capture the complexity of dynamic and diverse, evolving inter-node relationships. To address these challenges, we propose a novel framework called the Generative Dynamic Graph Model (GDGM), which models dynamic trading behaviors and the relationships among nodes to learn representations for conspiracy spoofing detection. Specifically, our approach incorporates the generative dynamic latent space to capture the temporal patterns and evolving market conditions. Raw trading data is first converted into time-stamped sequences. Then we model trading behaviors using the neural ordinary differential equations and gated recurrent units, to generate the representation incorporating temporal dynamics of spoofing patterns. Furthermore, pseudo-label generation and heterogeneous aggregation techniques are employed to gather relevant information and enhance the detection performance for conspiratorial spoofing behaviors. Experiments conducted on spoofing detection datasets demonstrate that our approach outperforms state-of-the-art models in detection accuracy. Additionally, our spoofing detection system has been successfully deployed in one of the largest global trading markets, further validating the practical applicability and performance of the proposed method.
<div id='section'>Paperid: <span id='pid'>101, <a href='https://arxiv.org/pdf/2208.05401.pdf' target='_blank'>https://arxiv.org/pdf/2208.05401.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zitong Yu, Rizhao Cai, Zhi Li, Wenhan Yang, Jingang Shi, Alex C. Kot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.05401">Benchmarking Joint Face Spoofing and Forgery Detection with Visual and Physiological Cues</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) and face forgery detection play vital roles in securing face biometric systems from presentation attacks (PAs) and vicious digital manipulation (e.g., deepfakes). Despite promising performance upon large-scale data and powerful deep models, the generalization problem of existing approaches is still an open issue. Most of recent approaches focus on 1) unimodal visual appearance or physiological (i.e., remote photoplethysmography (rPPG)) cues; and 2) separated feature representation for FAS or face forgery detection. On one side, unimodal appearance and rPPG features are respectively vulnerable to high-fidelity face 3D mask and video replay attacks, inspiring us to design reliable multi-modal fusion mechanisms for generalized face attack detection. On the other side, there are rich common features across FAS and face forgery detection tasks (e.g., periodic rPPG rhythms and vanilla appearance for bonafides), providing solid evidence to design a joint FAS and face forgery detection system in a multi-task learning fashion. In this paper, we establish the first joint face spoofing and forgery detection benchmark using both visual appearance and physiological rPPG cues. To enhance the rPPG periodicity discrimination, we design a two-branch physiological network using both facial spatio-temporal rPPG signal map and its continuous wavelet transformed counterpart as inputs. To mitigate the modality bias and improve the fusion efficacy, we conduct a weighted batch and layer normalization for both appearance and rPPG features before multi-modal fusion. We find that the generalization capacities of both unimodal (appearance or rPPG) and multi-modal (appearance+rPPG) models can be obviously improved via joint training on these two tasks. We hope this new benchmark will facilitate the future research of both FAS and deepfake detection communities.
<div id='section'>Paperid: <span id='pid'>102, <a href='https://arxiv.org/pdf/2510.17201.pdf' target='_blank'>https://arxiv.org/pdf/2510.17201.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mika Feng, Pierre Gallin-Martel, Koichi Ito, Takafumi Aoki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.17201">Optimizing DINOv2 with Registers for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition systems are designed to be robust against variations in head pose, illumination, and image blur during capture. However, malicious actors can exploit these systems by presenting a face photo of a registered user, potentially bypassing the authentication process. Such spoofing attacks must be detected prior to face recognition. In this paper, we propose a DINOv2-based spoofing attack detection method to discern minute differences between live and spoofed face images. Specifically, we employ DINOv2 with registers to extract generalizable features and to suppress perturbations in the attention mechanism, which enables focused attention on essential and minute features. We demonstrate the effectiveness of the proposed method through experiments conducted on the dataset provided by ``The 6th Face Anti-Spoofing Workshop: Unified Physical-Digital Attacks Detection@ICCV2025'' and SiW dataset.
<div id='section'>Paperid: <span id='pid'>103, <a href='https://arxiv.org/pdf/2509.03108.pdf' target='_blank'>https://arxiv.org/pdf/2509.03108.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shota Iwamatsu, Koichi Ito, Takafumi Aoki
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03108">Backdoor Poisoning Attack Against Face Spoofing Attack Detection Methods</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition systems are robust against environmental changes and noise, and thus may be vulnerable to illegal authentication attempts using user face photos, such as spoofing attacks. To prevent such spoofing attacks, it is crucial to discriminate whether the input image is a live user image or a spoofed image prior to the face recognition process. Most existing spoofing attack detection methods utilize deep learning, which necessitates a substantial amount of training data. Consequently, if malicious data is injected into a portion of the training dataset, a specific spoofing attack may be erroneously classified as live, leading to false positives. In this paper, we propose a novel backdoor poisoning attack method to demonstrate the latent threat of backdoor poisoning within face anti-spoofing detection. The proposed method enables certain spoofing attacks to bypass detection by embedding features extracted from the spoofing attack's face image into a live face image without inducing any perceptible visual alterations. Through experiments conducted on public datasets, we demonstrate that the proposed method constitutes a realistic threat to existing spoofing attack detection systems.
<div id='section'>Paperid: <span id='pid'>104, <a href='https://arxiv.org/pdf/2306.07655.pdf' target='_blank'>https://arxiv.org/pdf/2306.07655.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Michele Panariello, Wanying Ge, Hemlata Tak, Massimiliano Todisco, Nicholas Evans
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.07655">Malafide: a novel adversarial convolutive noise attack against deepfake and spoofing detection systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present Malafide, a universal adversarial attack against automatic speaker verification (ASV) spoofing countermeasures (CMs). By introducing convolutional noise using an optimised linear time-invariant filter, Malafide attacks can be used to compromise CM reliability while preserving other speech attributes such as quality and the speaker's voice. In contrast to other adversarial attacks proposed recently, Malafide filters are optimised independently of the input utterance and duration, are tuned instead to the underlying spoofing attack, and require the optimisation of only a small number of filter coefficients. Even so, they degrade CM performance estimates by an order of magnitude, even in black-box settings, and can also be configured to overcome integrated CM and ASV subsystems. Integrated solutions that use self-supervised learning CMs, however, are more robust, under both black-box and white-box settings.
<div id='section'>Paperid: <span id='pid'>105, <a href='https://arxiv.org/pdf/2508.19324.pdf' target='_blank'>https://arxiv.org/pdf/2508.19324.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jefferson David Rodriguez Chivata, Davide Ghiani, Simone Maurizio La Cava, Marco Micheletto, Giulia OrrÃ¹, Federico Lama, Gian Luca Marcialis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.19324">Deep Data Hiding for ICAO-Compliant Face Images: A Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>ICAO-compliant facial images, initially designed for secure biometric passports, are increasingly becoming central to identity verification in a wide range of application contexts, including border control, digital travel credentials, and financial services. While their standardization enables global interoperability, it also facilitates practices such as morphing and deepfakes, which can be exploited for harmful purposes like identity theft and illegal sharing of identity documents. Traditional countermeasures like Presentation Attack Detection (PAD) are limited to real-time capture and offer no post-capture protection. This survey paper investigates digital watermarking and steganography as complementary solutions that embed tamper-evident signals directly into the image, enabling persistent verification without compromising ICAO compliance. We provide the first comprehensive analysis of state-of-the-art techniques to evaluate the potential and drawbacks of the underlying approaches concerning the applications involving ICAO-compliant images and their suitability under standard constraints. We highlight key trade-offs, offering guidance for secure deployment in real-world identity systems.
<div id='section'>Paperid: <span id='pid'>106, <a href='https://arxiv.org/pdf/2504.11066.pdf' target='_blank'>https://arxiv.org/pdf/2504.11066.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marco Micheletto, Giulia OrrÃ¹, Luca Ghiani, Gian Luca Marcialis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.11066">Improving fingerprint presentation attack detection by an approach integrated into the personal verification stage</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Presentation Attack Detection (PAD) systems are usually designed independently of the fingerprint verification system. While this can be acceptable for use cases where specific user templates are not predetermined, it represents a missed opportunity to enhance security in scenarios where integrating PAD with the fingerprint verification system could significantly leverage users' templates, which are the real target of a potential presentation attack. This does not mean that a PAD should be specifically designed for such users; that would imply the availability of many enrolled users' PAI and, consequently, complexity, time, and cost increase. On the contrary, we propose to equip a basic PAD, designed according to the state of the art, with an innovative add-on module called the Closeness Binary Code (CC) module. The term "closeness" refers to a peculiar property of the bona fide-related features: in an Euclidean feature space, genuine fingerprints tend to cluster in a specific pattern. First, samples from the same finger are close to each other, then samples from other fingers of the same user and finally, samples from fingers of other users. This property is statistically verified in our previous publication, and further confirmed in this paper. It is independent of the user population and the feature set class, which can be handcrafted or deep network-based (embeddings). Therefore, the add-on can be designed without the need for the targeted user samples; moreover, it exploits her/his samples' "closeness" property during the verification stage. Extensive experiments on benchmark datasets and state-of-the-art PAD methods confirm the benefits of the proposed add-on, which can be easily coupled with the main PAD module integrated into the fingerprint verification system.
<div id='section'>Paperid: <span id='pid'>107, <a href='https://arxiv.org/pdf/2408.09752.pdf' target='_blank'>https://arxiv.org/pdf/2408.09752.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hang Zou, Chenxi Du, Ajian Liu, Yuan Zhang, Jing Liu, Mingchuan Yang, Jun Wan, Hui Zhang, Zhenan Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.09752">A Unified Framework for Iris Anti-Spoofing: Introducing Iris Anti-Spoofing Cross-Domain-Testing Protocol and Masked-MoE Method</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Iris recognition is widely used in high-security scenarios due to its stability and distinctiveness. However, iris images captured by different devices exhibit certain and device-related consistent differences, which has a greater impact on the classification algorithm for anti-spoofing. The iris of various races would also affect the classification, causing the risk of identity theft. So it is necessary to improve the cross-domain capabilities of the iris anti-spoofing (IAS) methods to enable it more robust in facing different races and devices. However, there is no existing protocol that is comprehensively available. To address this gap, we propose an Iris Anti-Spoofing Cross-Domain-Testing (IAS-CDT) Protocol, which involves 10 datasets, belonging to 7 databases, published by 4 institutions, and collected with 6 different devices. It contains three sub-protocols hierarchically, aimed at evaluating average performance, cross-racial generalization, and cross-device generalization of IAS models. Moreover, to address the cross-device generalization challenge brought by the IAS-CDT Protocol, we employ multiple model parameter sets to learn from the multiple sub-datasets. Specifically, we utilize the Mixture of Experts (MoE) to fit complex data distributions using multiple sub-neural networks. To further enhance the generalization capabilities, we propose a novel method Masked-MoE (MMoE), which randomly masks a portion of tokens for some experts and requires their outputs to be similar to the unmasked experts, which can effectively mitigate the overfitting issue of MoE. For the evaluation, we selected ResNet50, VIT-B/16, CLIP, and FLIP as representative models and benchmarked them under the proposed IAS-CDT Protocol.
<div id='section'>Paperid: <span id='pid'>108, <a href='https://arxiv.org/pdf/2309.15578.pdf' target='_blank'>https://arxiv.org/pdf/2309.15578.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Marco Micheletto, Roberto Casula, Giulia OrrÃ¹, Simone Carta, Sara Concas, Simone Maurizio La Cava, Julian Fierrez, Gian Luca Marcialis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.15578">LivDet2023 -- Fingerprint Liveness Detection Competition: Advancing Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The International Fingerprint Liveness Detection Competition (LivDet) is a biennial event that invites academic and industry participants to prove their advancements in Fingerprint Presentation Attack Detection (PAD). This edition, LivDet2023, proposed two challenges, Liveness Detection in Action and Fingerprint Representation, to evaluate the efficacy of PAD embedded in verification systems and the effectiveness and compactness of feature sets. A third, hidden challenge is the inclusion of two subsets in the training set whose sensor information is unknown, testing participants ability to generalize their models. Only bona fide fingerprint samples were provided to participants, and the competition reports and assesses the performance of their algorithms suffering from this limitation in data availability.
<div id='section'>Paperid: <span id='pid'>109, <a href='https://arxiv.org/pdf/2507.20404.pdf' target='_blank'>https://arxiv.org/pdf/2507.20404.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan E. Tapia, Mario Nieto, Juan M. Espin, Alvaro S. Rocamora, Javier Barrachina, Naser Damer, Christoph Busch, Marija Ivanovska, Leon Todorov, Renat Khizbullin, Lazar Lazarevich, Aleksei Grishin, Daniel Schulz, Sebastian Gonzalez, Amir Mohammadi, Ketan Kotwal, Sebastien Marcel, Raghavendra Mudgalgundurao, Kiran Raja, Patrick Schuch, Sushrut Patwardhan, Raghavendra Ramachandra, Pedro Couto Pereira, Joao Ribeiro Pinto, Mariana Xavier, AndrÃ©s Valenzuela, Rodrigo Lara, Borut Batagelj, Marko Peterlin, Peter Peer, Ajnas Muhammed, Diogo Nunes, Nuno GonÃ§alves
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.20404">Second Competition on Presentation Attack Detection on ID Card</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work summarises and reports the results of the second Presentation Attack Detection competition on ID cards. This new version includes new elements compared to the previous one. (1) An automatic evaluation platform was enabled for automatic benchmarking; (2) Two tracks were proposed in order to evaluate algorithms and datasets, respectively; and (3) A new ID card dataset was shared with Track 1 teams to serve as the baseline dataset for the training and optimisation. The Hochschule Darmstadt, Fraunhofer-IGD, and Facephi company jointly organised this challenge. 20 teams were registered, and 74 submitted models were evaluated. For Track 1, the "Dragons" team reached first place with an Average Ranking and Equal Error rate (EER) of AV-Rank of 40.48% and 11.44% EER, respectively. For the more challenging approach in Track 2, the "Incode" team reached the best results with an AV-Rank of 14.76% and 6.36% EER, improving on the results of the first edition of 74.30% and 21.87% EER, respectively. These results suggest that PAD on ID cards is improving, but it is still a challenging problem related to the number of images, especially of bona fide images.
<div id='section'>Paperid: <span id='pid'>110, <a href='https://arxiv.org/pdf/2505.09415.pdf' target='_blank'>https://arxiv.org/pdf/2505.09415.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hongyang Wang, Yichen Shi, Zhuofu Tao, Yuhao Gao, Liepiao Zhang, Xun Lin, Jun Feng, Xiaochen Yuan, Zitong Yu, Xiaochun Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.09415">FaceShield: Explainable Face Anti-Spoofing with Multimodal Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) is crucial for protecting facial recognition systems from presentation attacks. Previous methods approached this task as a classification problem, lacking interpretability and reasoning behind the predicted results. Recently, multimodal large language models (MLLMs) have shown strong capabilities in perception, reasoning, and decision-making in visual tasks. However, there is currently no universal and comprehensive MLLM and dataset specifically designed for FAS task. To address this gap, we propose FaceShield, a MLLM for FAS, along with the corresponding pre-training and supervised fine-tuning (SFT) datasets, FaceShield-pre10K and FaceShield-sft45K. FaceShield is capable of determining the authenticity of faces, identifying types of spoofing attacks, providing reasoning for its judgments, and detecting attack areas. Specifically, we employ spoof-aware vision perception (SAVP) that incorporates both the original image and auxiliary information based on prior knowledge. We then use an prompt-guided vision token masking (PVTM) strategy to random mask vision tokens, thereby improving the model's generalization ability. We conducted extensive experiments on three benchmark datasets, demonstrating that FaceShield significantly outperforms previous deep learning models and general MLLMs on four FAS tasks, i.e., coarse-grained classification, fine-grained classification, reasoning, and attack localization. Our instruction datasets, protocols, and codes will be released soon.
<div id='section'>Paperid: <span id='pid'>111, <a href='https://arxiv.org/pdf/2409.00372.pdf' target='_blank'>https://arxiv.org/pdf/2409.00372.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan E. Tapia, Naser Damer, Christoph Busch, Juan M. Espin, Javier Barrachina, Alvaro S. Rocamora, Kristof Ocvirk, Leon Alessio, Borut Batagelj, Sushrut Patwardhan, Raghavendra Ramachandra, Raghavendra Mudgalgundurao, Kiran Raja, Daniel Schulz, Carlos Aravena
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.00372">First Competition on Presentation Attack Detection on ID Card</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper summarises the Competition on Presentation Attack Detection on ID Cards (PAD-IDCard) held at the 2024 International Joint Conference on Biometrics (IJCB2024). The competition attracted a total of ten registered teams, both from academia and industry. In the end, the participating teams submitted five valid submissions, with eight models to be evaluated by the organisers. The competition presented an independent assessment of current state-of-the-art algorithms. Today, no independent evaluation on cross-dataset is available; therefore, this work determined the state-of-the-art on ID cards. To reach this goal, a sequestered test set and baseline algorithms were used to evaluate and compare all the proposals. The sequestered test dataset contains ID cards from four different countries. In summary, a team that chose to be "Anonymous" reached the best average ranking results of 74.80%, followed very closely by the "IDVC" team with 77.65%.
<div id='section'>Paperid: <span id='pid'>112, <a href='https://arxiv.org/pdf/2309.17399.pdf' target='_blank'>https://arxiv.org/pdf/2309.17399.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jiancheng Huang, Donghao Zhou, Shifeng Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.17399">IFAST: Weakly Supervised Interpretable Face Anti-spoofing from Single-shot Binocular NIR Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Single-shot face anti-spoofing (FAS) is a key technique for securing face recognition systems, and it requires only static images as input. However, single-shot FAS remains a challenging and under-explored problem due to two main reasons: 1) on the data side, learning FAS from RGB images is largely context-dependent, and single-shot images without additional annotations contain limited semantic information. 2) on the model side, existing single-shot FAS models are infeasible to provide proper evidence for their decisions, and FAS methods based on depth estimation require expensive per-pixel annotations. To address these issues, a large binocular NIR image dataset (BNI-FAS) is constructed and published, which contains more than 300,000 real face and plane attack images, and an Interpretable FAS Transformer (IFAST) is proposed that requires only weak supervision to produce interpretable predictions. Our IFAST can produce pixel-wise disparity maps by the proposed disparity estimation Transformer with Dynamic Matching Attention (DMA) block. Besides, a well-designed confidence map generator is adopted to cooperate with the proposed dual-teacher distillation module to obtain the final discriminant results. The comprehensive experiments show that our IFAST can achieve state-of-the-art results on BNI-FAS, proving the effectiveness of the single-shot FAS based on binocular NIR images.
<div id='section'>Paperid: <span id='pid'>113, <a href='https://arxiv.org/pdf/2203.12175.pdf' target='_blank'>https://arxiv.org/pdf/2203.12175.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hsin-Ping Huang, Deqing Sun, Yaojie Liu, Wen-Sheng Chu, Taihong Xiao, Jinwei Yuan, Hartwig Adam, Ming-Hsuan Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.12175">Adaptive Transformers for Robust Few-shot Cross-domain Face Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>While recent face anti-spoofing methods perform well under the intra-domain setups, an effective approach needs to account for much larger appearance variations of images acquired in complex scenes with different sensors for robust performance. In this paper, we present adaptive vision transformers (ViT) for robust cross-domain face antispoofing. Specifically, we adopt ViT as a backbone to exploit its strength to account for long-range dependencies among pixels. We further introduce the ensemble adapters module and feature-wise transformation layers in the ViT to adapt to different domains for robust performance with a few samples. Experiments on several benchmark datasets show that the proposed models achieve both robust and competitive performance against the state-of-the-art methods for cross-domain face anti-spoofing using a few samples.
<div id='section'>Paperid: <span id='pid'>114, <a href='https://arxiv.org/pdf/2310.00659.pdf' target='_blank'>https://arxiv.org/pdf/2310.00659.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sandip Purnapatra, Humaira Rezaie, Bhavin Jawade, Yu Liu, Yue Pan, Luke Brosell, Mst Rumana Sumi, Lambert Igene, Alden Dimarco, Srirangaraj Setlur, Soumyabrata Dey, Stephanie Schuckers, Marco Huber, Jan Niklas Kolf, Meiling Fang, Naser Damer, Banafsheh Adami, Raul Chitic, Karsten Seelert, Vishesh Mistry, Rahul Parthe, Umit Kacar
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.00659">Liveness Detection Competition -- Noncontact-based Fingerprint Algorithms and Systems (LivDet-2023 Noncontact Fingerprint)</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Liveness Detection (LivDet) is an international competition series open to academia and industry with the objec-tive to assess and report state-of-the-art in Presentation Attack Detection (PAD). LivDet-2023 Noncontact Fingerprint is the first edition of the noncontact fingerprint-based PAD competition for algorithms and systems. The competition serves as an important benchmark in noncontact-based fingerprint PAD, offering (a) independent assessment of the state-of-the-art in noncontact-based fingerprint PAD for algorithms and systems, and (b) common evaluation protocol, which includes finger photos of a variety of Presentation Attack Instruments (PAIs) and live fingers to the biometric research community (c) provides standard algorithm and system evaluation protocols, along with the comparative analysis of state-of-the-art algorithms from academia and industry with both old and new android smartphones. The winning algorithm achieved an APCER of 11.35% averaged overall PAIs and a BPCER of 0.62%. The winning system achieved an APCER of 13.0.4%, averaged over all PAIs tested over all the smartphones, and a BPCER of 1.68% over all smartphones tested. Four-finger systems that make individual finger-based PAD decisions were also tested. The dataset used for competition will be available 1 to all researchers as per data share protocol
<div id='section'>Paperid: <span id='pid'>115, <a href='https://arxiv.org/pdf/2309.04038.pdf' target='_blank'>https://arxiv.org/pdf/2309.04038.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rizhao Cai, Zitong Yu, Chenqi Kong, Haoliang Li, Changsheng Chen, Yongjian Hu, Alex Kot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.04038">S-Adapter: Generalizing Vision Transformer for Face Anti-Spoofing with Statistical Tokens</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face Anti-Spoofing (FAS) aims to detect malicious attempts to invade a face recognition system by presenting spoofed faces. State-of-the-art FAS techniques predominantly rely on deep learning models but their cross-domain generalization capabilities are often hindered by the domain shift problem, which arises due to different distributions between training and testing data. In this study, we develop a generalized FAS method under the Efficient Parameter Transfer Learning (EPTL) paradigm, where we adapt the pre-trained Vision Transformer models for the FAS task. During training, the adapter modules are inserted into the pre-trained ViT model, and the adapters are updated while other pre-trained parameters remain fixed. We find the limitations of previous vanilla adapters in that they are based on linear layers, which lack a spoofing-aware inductive bias and thus restrict the cross-domain generalization. To address this limitation and achieve cross-domain generalized FAS, we propose a novel Statistical Adapter (S-Adapter) that gathers local discriminative and statistical information from localized token histograms. To further improve the generalization of the statistical tokens, we propose a novel Token Style Regularization (TSR), which aims to reduce domain style variance by regularizing Gram matrices extracted from tokens across different domains. Our experimental results demonstrate that our proposed S-Adapter and TSR provide significant benefits in both zero-shot and few-shot cross-domain testing, outperforming state-of-the-art methods on several benchmark tests. We will release the source code upon acceptance.
<div id='section'>Paperid: <span id='pid'>116, <a href='https://arxiv.org/pdf/2308.09107.pdf' target='_blank'>https://arxiv.org/pdf/2308.09107.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shuangpeng Han, Rizhao Cai, Yawen Cui, Zitong Yu, Yongjian Hu, Alex Kot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.09107">Hyperbolic Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Learning generalized face anti-spoofing (FAS) models against presentation attacks is essential for the security of face recognition systems. Previous FAS methods usually encourage models to extract discriminative features, of which the distances within the same class (bonafide or attack) are pushed close while those between bonafide and attack are pulled away. However, these methods are designed based on Euclidean distance, which lacks generalization ability for unseen attack detection due to poor hierarchy embedding ability. According to the evidence that different spoofing attacks are intrinsically hierarchical, we propose to learn richer hierarchical and discriminative spoofing cues in hyperbolic space. Specifically, for unimodal FAS learning, the feature embeddings are projected into the PoincarÃ© ball, and then the hyperbolic binary logistic regression layer is cascaded for classification. To further improve generalization, we conduct hyperbolic contrastive learning for the bonafide only while relaxing the constraints on diverse spoofing attacks. To alleviate the vanishing gradient problem in hyperbolic space, a new feature clipping method is proposed to enhance the training stability of hyperbolic models. Besides, we further design a multimodal FAS framework with Euclidean multimodal feature decomposition and hyperbolic multimodal feature fusion & classification. Extensive experiments on three benchmark datasets (i.e., WMCA, PADISI-Face, and SiW-M) with diverse attack types demonstrate that the proposed method can bring significant improvement compared to the Euclidean baselines on unseen attack detection. In addition, the proposed framework is also generalized well on four benchmark datasets (i.e., MSU-MFSD, IDIAP REPLAY-ATTACK, CASIA-FASD, and OULU-NPU) with a limited number of attack types.
<div id='section'>Paperid: <span id='pid'>117, <a href='https://arxiv.org/pdf/2303.09914.pdf' target='_blank'>https://arxiv.org/pdf/2303.09914.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rizhao Cai, Yawen Cui, Zhi Li, Zitong Yu, Haoliang Li, Yongjian Hu, Alex Kot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.09914">Rehearsal-Free Domain Continual Face Anti-Spoofing: Generalize More and Forget Less</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face Anti-Spoofing (FAS) is recently studied under the continual learning setting, where the FAS models are expected to evolve after encountering the data from new domains. However, existing methods need extra replay buffers to store previous data for rehearsal, which becomes infeasible when previous data is unavailable because of privacy issues. In this paper, we propose the first rehearsal-free method for Domain Continual Learning (DCL) of FAS, which deals with catastrophic forgetting and unseen domain generalization problems simultaneously. For better generalization to unseen domains, we design the Dynamic Central Difference Convolutional Adapter (DCDCA) to adapt Vision Transformer (ViT) models during the continual learning sessions. To alleviate the forgetting of previous domains without using previous data, we propose the Proxy Prototype Contrastive Regularization (PPCR) to constrain the continual learning with previous domain knowledge from the proxy prototypes. Simulate practical DCL scenarios, we devise two new protocols which evaluate both generalization and anti-forgetting performance. Extensive experimental results show that our proposed method can improve the generalization performance in unseen domains and alleviate the catastrophic forgetting of the previous knowledge. The codes and protocols will be released soon.
<div id='section'>Paperid: <span id='pid'>118, <a href='https://arxiv.org/pdf/2303.02660.pdf' target='_blank'>https://arxiv.org/pdf/2303.02660.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meiling Fang, Marco Huber, Naser Damer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.02660">SynthASpoof: Developing Face Presentation Attack Detection Based on Privacy-friendly Synthetic Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, significant progress has been made in face presentation attack detection (PAD), which aims to secure face recognition systems against presentation attacks, owing to the availability of several face PAD datasets. However, all available datasets are based on privacy and legally-sensitive authentic biometric data with a limited number of subjects. To target these legal and technical challenges, this work presents the first synthetic-based face PAD dataset, named SynthASpoof, as a large-scale PAD development dataset. The bona fide samples in SynthASpoof are synthetically generated and the attack samples are collected by presenting such synthetic data to capture systems in a real attack scenario. The experimental results demonstrate the feasibility of using SynthASpoof for the development of face PAD. Moreover, we boost the performance of such a solution by incorporating the domain generalization tool MixStyle into the PAD solutions. Additionally, we showed the viability of using synthetic data as a supplement to enrich the diversity of limited authentic training data and consistently enhance PAD performances. The SynthASpoof dataset, containing 25,000 bona fide and 78,800 attack samples, the implementation, and the pre-trained weights are made publicly available.
<div id='section'>Paperid: <span id='pid'>119, <a href='https://arxiv.org/pdf/2509.00186.pdf' target='_blank'>https://arxiv.org/pdf/2509.00186.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arnab Das, Yassine El Kheir, Carlos Franzreb, Tim Herzig, Tim Polzehl, Sebastian MÃ¶ller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.00186">Generalizable Audio Spoofing Detection using Non-Semantic Representations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Rapid advancements in generative modeling have made synthetic audio generation easy, making speech-based services vulnerable to spoofing attacks. Consequently, there is a dire need for robust countermeasures more than ever. Existing solutions for deepfake detection are often criticized for lacking generalizability and fail drastically when applied to real-world data. This study proposes a novel method for generalizable spoofing detection leveraging non-semantic universal audio representations. Extensive experiments have been performed to find suitable non-semantic features using TRILL and TRILLsson models. The results indicate that the proposed method achieves comparable performance on the in-domain test set while significantly outperforming state-of-the-art approaches on out-of-domain test sets. Notably, it demonstrates superior generalization on public-domain data, surpassing methods based on hand-crafted features, semantic embeddings, and end-to-end architectures.
<div id='section'>Paperid: <span id='pid'>120, <a href='https://arxiv.org/pdf/2506.21895.pdf' target='_blank'>https://arxiv.org/pdf/2506.21895.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fangling Jiang, Qi Li, Weining Wang, Gang Wang, Bing Liu, Zhenan Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.21895">Exploring Task-Solving Paradigm for Generalized Cross-Domain Face Anti-Spoofing via Reinforcement Fine-Tuning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently the emergence of novel presentation attacks has drawn increasing attention to face anti-spoofing. However, existing methods tend to memorize data patterns from the training set, resulting in poor generalization to unknown attack types across different scenarios and limited interpretability. To address these challenges, this paper presents a reinforcement fine-tuning-based face anti-spoofing method that stimulates the capabilities of multimodal large language models to think and learn how to solve the anti-spoofing task itself, rather than relying on the memorization of authenticity patterns. We design verifiable class consistent reward and reasoning consistent reward, and employ a GRPO-based optimization strategy to guide the model in exploring reasoning policies from multiple perspectives to maximize expected rewards. As a result, through iterative trial-and-error learning while retaining only high-reward trajectories, the model distills highly generalizable decision-making rules from the extensive solution space to effectively address cross-domain face anti-spoofing tasks. Extensive experimental results demonstrate that our method achieves state-of-the-art cross-domain generalization performance. It generalizes well to diverse unknown attack types in unseen target domains while providing interpretable reasoning for its authenticity decisions without requiring labor-intensive textual annotations for training.
<div id='section'>Paperid: <span id='pid'>121, <a href='https://arxiv.org/pdf/2505.03611.pdf' target='_blank'>https://arxiv.org/pdf/2505.03611.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fangling Jiang, Qi Li, Weining Wang, Wei Shen, Bing Liu, Zhenan Sun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03611">Learning Unknown Spoof Prompts for Generalized Face Anti-Spoofing Using Only Real Face Images</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing is a critical technology for ensuring the security of face recognition systems. However, its ability to generalize across diverse scenarios remains a significant challenge. In this paper, we attribute the limited generalization ability to two key factors: covariate shift, which arises from external data collection variations, and semantic shift, which results from substantial differences in emerging attack types. To address both challenges, we propose a novel approach for learning unknown spoof prompts, relying solely on real face images from a single source domain. Our method generates textual prompts for real faces and potential unknown spoof attacks by leveraging the general knowledge embedded in vision-language models, thereby enhancing the model's ability to generalize to unseen target domains. Specifically, we introduce a diverse spoof prompt optimization framework to learn effective prompts. This framework constrains unknown spoof prompts within a relaxed prior knowledge space while maximizing their distance from real face images. Moreover, it enforces semantic independence among different spoof prompts to capture a broad range of spoof patterns. Experimental results on nine datasets demonstrate that the learned prompts effectively transfer the knowledge of vision-language models, enabling state-of-the-art generalization ability against diverse unknown attack types across unseen target domains without using any spoof face images.
<div id='section'>Paperid: <span id='pid'>122, <a href='https://arxiv.org/pdf/2505.03610.pdf' target='_blank'>https://arxiv.org/pdf/2505.03610.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Fangling Jiang, Qi Li, Bing Liu, Weining Wang, Caifeng Shan, Zhenan Sun, Ming-Hsuan Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.03610">Learning Knowledge-based Prompts for Robust 3D Mask Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>3D mask presentation attack detection is crucial for protecting face recognition systems against the rising threat of 3D mask attacks. While most existing methods utilize multimodal features or remote photoplethysmography (rPPG) signals to distinguish between real faces and 3D masks, they face significant challenges, such as the high costs associated with multimodal sensors and limited generalization ability. Detection-related text descriptions offer concise, universal information and are cost-effective to obtain. However, the potential of vision-language multimodal features for 3D mask presentation attack detection remains unexplored. In this paper, we propose a novel knowledge-based prompt learning framework to explore the strong generalization capability of vision-language models for 3D mask presentation attack detection. Specifically, our approach incorporates entities and triples from knowledge graphs into the prompt learning process, generating fine-grained, task-specific explicit prompts that effectively harness the knowledge embedded in pre-trained vision-language models. Furthermore, considering different input images may emphasize distinct knowledge graph elements, we introduce a visual-specific knowledge filter based on an attention mechanism to refine relevant elements according to the visual context. Additionally, we leverage causal graph theory insights into the prompt learning process to further enhance the generalization ability of our method. During training, a spurious correlation elimination paradigm is employed, which removes category-irrelevant local image patches using guidance from knowledge-based text features, fostering the learning of generalized causal prompts that align with category-relevant local patches. Experimental results demonstrate that the proposed method achieves state-of-the-art intra- and cross-scenario detection performance on benchmark datasets.
<div id='section'>Paperid: <span id='pid'>123, <a href='https://arxiv.org/pdf/2501.08799.pdf' target='_blank'>https://arxiv.org/pdf/2501.08799.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alain Komaty, Hatef Otroshi Shahreza, Anjith George, Sebastien Marcel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.08799">Exploring ChatGPT for Face Presentation Attack Detection in Zero and Few-Shot in-Context Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This study highlights the potential of ChatGPT (specifically GPT-4o) as a competitive alternative for Face Presentation Attack Detection (PAD), outperforming several PAD models, including commercial solutions, in specific scenarios. Our results show that GPT-4o demonstrates high consistency, particularly in few-shot in-context learning, where its performance improves as more examples are provided (reference data). We also observe that detailed prompts enable the model to provide scores reliably, a behavior not observed with concise prompts. Additionally, explanation-seeking prompts slightly enhance the model's performance by improving its interpretability. Remarkably, the model exhibits emergent reasoning capabilities, correctly predicting the attack type (print or replay) with high accuracy in few-shot scenarios, despite not being explicitly instructed to classify attack types. Despite these strengths, GPT-4o faces challenges in zero-shot tasks, where its performance is limited compared to specialized PAD systems. Experiments were conducted on a subset of the SOTERIA dataset, ensuring compliance with data privacy regulations by using only data from consenting individuals. These findings underscore GPT-4o's promise in PAD applications, laying the groundwork for future research to address broader data privacy concerns and improve cross-dataset generalization. Code available here: https://gitlab.idiap.ch/bob/bob.paper.wacv2025_chatgpt_face_pad
<div id='section'>Paperid: <span id='pid'>124, <a href='https://arxiv.org/pdf/2404.12680.pdf' target='_blank'>https://arxiv.org/pdf/2404.12680.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Raghavendra Ramachandra, Narayan Vetrekar, Sushma Venkatesh, Savita Nageshker, Jag Mohan Singh, R. S. Gad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.12680">VoxAtnNet: A 3D Point Clouds Convolutional Neural Network for Generalizable Face Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Facial biometrics are an essential components of smartphones to ensure reliable and trustworthy authentication. However, face biometric systems are vulnerable to Presentation Attacks (PAs), and the availability of more sophisticated presentation attack instruments such as 3D silicone face masks will allow attackers to deceive face recognition systems easily. In this work, we propose a novel Presentation Attack Detection (PAD) algorithm based on 3D point clouds captured using the frontal camera of a smartphone to detect presentation attacks. The proposed PAD algorithm, VoxAtnNet, processes 3D point clouds to obtain voxelization to preserve the spatial structure. Then, the voxelized 3D samples were trained using the novel convolutional attention network to detect PAs on the smartphone. Extensive experiments were carried out on the newly constructed 3D face point cloud dataset comprising bona fide and two different 3D PAIs (3D silicone face mask and wrap photo mask), resulting in 3480 samples. The performance of the proposed method was compared with existing methods to benchmark the detection performance using three different evaluation protocols. The experimental results demonstrate the improved performance of the proposed method in detecting both known and unknown face presentation attacks.
<div id='section'>Paperid: <span id='pid'>125, <a href='https://arxiv.org/pdf/2311.11566.pdf' target='_blank'>https://arxiv.org/pdf/2311.11566.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Narayan Vetrekar, Raghavendra Ramachandra, Sushma Venkatesh, Jyoti D. Pawar, R. S. Gad
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.11566">Does complimentary information from multispectral imaging improve face presentation attack detection?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Presentation Attack Detection (PAD) has been extensively studied, particularly in the visible spectrum. With the advancement of sensing technology beyond the visible range, multispectral imaging has gained significant attention in this direction. We present PAD based on multispectral images constructed for eight different presentation artifacts resulted from three different artifact species. In this work, we introduce Face Presentation Attack Multispectral (FPAMS) database to demonstrate the significance of employing multispectral imaging. The goal of this work is to study complementary information that can be combined in two different ways (image fusion and score fusion) from multispectral imaging to improve the face PAD. The experimental evaluation results present an extensive qualitative analysis of 61650 sample multispectral images collected for bonafide and artifacts. The PAD based on the score fusion and image fusion method presents superior performance, demonstrating the significance of employing multispectral imaging to detect presentation artifacts.
<div id='section'>Paperid: <span id='pid'>126, <a href='https://arxiv.org/pdf/2310.04541.pdf' target='_blank'>https://arxiv.org/pdf/2310.04541.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Patrick Tinsley, Sandip Purnapatra, Mahsa Mitcheff, Aidan Boyd, Colton Crum, Kevin Bowyer, Patrick Flynn, Stephanie Schuckers, Adam Czajka, Meiling Fang, Naser Damer, Xingyu Liu, Caiyong Wang, Xianyun Sun, Zhaohua Chang, Xinyue Li, Guangzhe Zhao, Juan Tapia, Christoph Busch, Carlos Aravena, Daniel Schulz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.04541">Iris Liveness Detection Competition (LivDet-Iris) -- The 2023 Edition</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper describes the results of the 2023 edition of the ''LivDet'' series of iris presentation attack detection (PAD) competitions. New elements in this fifth competition include (1) GAN-generated iris images as a category of presentation attack instruments (PAI), and (2) an evaluation of human accuracy at detecting PAI as a reference benchmark. Clarkson University and the University of Notre Dame contributed image datasets for the competition, composed of samples representing seven different PAI categories, as well as baseline PAD algorithms. Fraunhofer IGD, Beijing University of Civil Engineering and Architecture, and Hochschule Darmstadt contributed results for a total of eight PAD algorithms to the competition. Accuracy results are analyzed by different PAI types, and compared to human accuracy. Overall, the Fraunhofer IGD algorithm, using an attention-based pixel-wise binary supervision network, showed the best-weighted accuracy results (average classification error rate of 37.31%), while the Beijing University of Civil Engineering and Architecture's algorithm won when equal weights for each PAI were given (average classification rate of 22.15%). These results suggest that iris PAD is still a challenging problem.
<div id='section'>Paperid: <span id='pid'>127, <a href='https://arxiv.org/pdf/2309.13704.pdf' target='_blank'>https://arxiv.org/pdf/2309.13704.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Raghavendra Ramachandra, Jag Mohan Singh, Sushma Venkatesh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.13704">Sound-Print: Generalised Face Presentation Attack Detection using Deep Representation of Sound Echoes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Facial biometrics are widely deployed in smartphone-based applications because of their usability and increased verification accuracy in unconstrained scenarios. The evolving applications of smartphone-based facial recognition have also increased Presentation Attacks (PAs), where an attacker can present a Presentation Attack Instrument (PAI) to maliciously gain access to the application. Because the materials used to generate PAI are not deterministic, the detection of unknown presentation attacks is challenging. In this paper, we present an acoustic echo-based face Presentation Attack Detection (PAD) on a smartphone in which the PAs are detected based on the reflection profiles of the transmitted signal. We propose a novel transmission signal based on the wide pulse that allows us to model the background noise before transmitting the signal and increase the Signal-to-Noise Ratio (SNR). The received signal reflections were processed to remove background noise and accurately represent reflection characteristics. The reflection profiles of the bona fide and PAs are different owing to the different reflection characteristics of the human skin and artefact materials. Extensive experiments are presented using the newly collected Acoustic Sound Echo Dataset (ASED) with 4807 samples captured from bona fide and four different types of PAIs, including print (two types), display, and silicone face-mask attacks. The obtained results indicate the robustness of the proposed method for detecting unknown face presentation attacks.
<div id='section'>Paperid: <span id='pid'>128, <a href='https://arxiv.org/pdf/2309.04958.pdf' target='_blank'>https://arxiv.org/pdf/2309.04958.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Usman Muhammad, Mourad Oussalah, Jorma Laaksonen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.04958">Semi-Supervised learning for Face Anti-Spoofing using Apex frame</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conventional feature extraction techniques in the face anti-spoofing domain either analyze the entire video sequence or focus on a specific segment to improve model performance. However, identifying the optimal frames that provide the most valuable input for the face anti-spoofing remains a challenging task. In this paper, we address this challenge by employing Gaussian weighting to create apex frames for videos. Specifically, an apex frame is derived from a video by computing a weighted sum of its frames, where the weights are determined using a Gaussian distribution centered around the video's central frame. Furthermore, we explore various temporal lengths to produce multiple unlabeled apex frames using a Gaussian function, without the need for convolution. By doing so, we leverage the benefits of semi-supervised learning, which considers both labeled and unlabeled apex frames to effectively discriminate between live and spoof classes. Our key contribution emphasizes the apex frame's capacity to represent the most significant moments in the video, while unlabeled apex frames facilitate efficient semi-supervised learning, as they enable the model to learn from videos of varying temporal lengths. Experimental results using four face anti-spoofing databases: CASIA, REPLAY-ATTACK, OULU-NPU, and MSU-MFSD demonstrate the apex frame's efficacy in advancing face anti-spoofing techniques.
<div id='section'>Paperid: <span id='pid'>129, <a href='https://arxiv.org/pdf/2308.14551.pdf' target='_blank'>https://arxiv.org/pdf/2308.14551.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meiling Fang, Naser Damer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.14551">Face Presentation Attack Detection by Excavating Causal Clues and Adapting Embedding Statistics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent face presentation attack detection (PAD) leverages domain adaptation (DA) and domain generalization (DG) techniques to address performance degradation on unknown domains. However, DA-based PAD methods require access to unlabeled target data, while most DG-based PAD solutions rely on a priori, i.e., known domain labels. Moreover, most DA-/DG-based methods are computationally intensive, demanding complex model architectures and/or multi-stage training processes. This paper proposes to model face PAD as a compound DG task from a causal perspective, linking it to model optimization. We excavate the causal factors hidden in the high-level representation via counterfactual intervention. Moreover, we introduce a class-guided MixStyle to enrich feature-level data distribution within classes instead of focusing on domain information. Both class-guided MixStyle and counterfactual intervention components introduce no extra trainable parameters and negligible computational resources. Extensive cross-dataset and analytic experiments demonstrate the effectiveness and efficiency of our method compared to state-of-the-art PADs. The implementation and the trained weights are publicly available.
<div id='section'>Paperid: <span id='pid'>130, <a href='https://arxiv.org/pdf/2308.12364.pdf' target='_blank'>https://arxiv.org/pdf/2308.12364.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Usman Muhammad, Mourad Oussalah, Jorma Laaksonen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.12364">Saliency-based Video Summarization for Face Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the growing availability of databases for face presentation attack detection, researchers are increasingly focusing on video-based face anti-spoofing methods that involve hundreds to thousands of images for training the models. However, there is currently no clear consensus on the optimal number of frames in a video to improve face spoofing detection. Inspired by the visual saliency theory, we present a video summarization method for face anti-spoofing detection that aims to enhance the performance and efficiency of deep learning models by leveraging visual saliency. In particular, saliency information is extracted from the differences between the Laplacian and Wiener filter outputs of the source images, enabling identification of the most visually salient regions within each frame. Subsequently, the source images are decomposed into base and detail images, enhancing the representation of the most important information. Weighting maps are then computed based on the saliency information, indicating the importance of each pixel in the image. By linearly combining the base and detail images using the weighting maps, the method fuses the source images to create a single representative image that summarizes the entire video. The key contribution of the proposed method lies in demonstrating how visual saliency can be used as a data-centric approach to improve the performance and efficiency for face presentation attack detection. By focusing on the most salient images or regions within the images, a more representative and diverse training set can be created, potentially leading to more effective models. To validate the method's effectiveness, a simple CNN-RNN deep learning architecture was used, and the experimental results showcased state-of-the-art performance on five challenging face anti-spoofing datasets
<div id='section'>Paperid: <span id='pid'>131, <a href='https://arxiv.org/pdf/2307.02858.pdf' target='_blank'>https://arxiv.org/pdf/2307.02858.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Usman Muhammad, Md Ziaul Hoque, Mourad Oussalah, Jorma Laaksonen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.02858">Deep Ensemble Learning with Frame Skipping for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face presentation attacks (PA), also known as spoofing attacks, pose a substantial threat to biometric systems that rely on facial recognition systems, such as access control systems, mobile payments, and identity verification systems. To mitigate the spoofing risk, several video-based methods have been presented in the literature that analyze facial motion in successive video frames. However, estimating the motion between adjacent frames is a challenging task and requires high computational cost. In this paper, we rephrase the face anti-spoofing task as a motion prediction problem and introduce a deep ensemble learning model with a frame skipping mechanism. In particular, the proposed frame skipping adopts a uniform sampling approach by dividing the original video into video clips of fixed size. By doing so, every nth frame of the clip is selected to ensure that the temporal patterns can easily be perceived during the training of three different recurrent neural networks (RNNs). Motivated by the performance of individual RNNs, a meta-model is developed to improve the overall detection performance by combining the prediction of individual RNNs. Extensive experiments were performed on four datasets, and state-of-the-art performance is reported on MSU-MFSD (3.12%), Replay-Attack (11.19%), and OULU-NPU (12.23%) databases by using half total error rates (HTERs) in the most challenging cross-dataset testing scenario.
<div id='section'>Paperid: <span id='pid'>132, <a href='https://arxiv.org/pdf/2303.05459.pdf' target='_blank'>https://arxiv.org/pdf/2303.05459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sandip Purnapatra, Conor Miller-Lynch, Stephen Miner, Yu Liu, Keivan Bahmani, Soumyabrata Dey, Stephanie Schuckers
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.05459">Presentation Attack Detection with Advanced CNN Models for Noncontact-based Fingerprint Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Touch-based fingerprint biometrics is one of the most popular biometric modalities with applications in several fields. Problems associated with touch-based techniques such as the presence of latent fingerprints and hygiene issues due to many people touching the same surface motivated the community to look for non-contact-based solutions. For the last few years, contactless fingerprint systems are on the rise and in demand because of the ability to turn any device with a camera into a fingerprint reader. Yet, before we can fully utilize the benefit of noncontact-based methods, the biometric community needs to resolve a few concerns such as the resiliency of the system against presentation attacks. One of the major obstacles is the limited publicly available data sets with inadequate spoof and live data. In this publication, we have developed a Presentation attack detection (PAD) dataset of more than 7500 four-finger images and more than 14,000 manually segmented single-fingertip images, and 10,000 synthetic fingertips (deepfakes). The PAD dataset was collected from six different Presentation Attack Instruments (PAI) of three different difficulty levels according to FIDO protocols, with five different types of PAI materials, and different smartphone cameras with manual focusing. We have utilized DenseNet-121 and NasNetMobile models and our proposed dataset to develop PAD algorithms and achieved PAD accuracy of Attack presentation classification error rate (APCER) 0.14\% and Bonafide presentation classification error rate (BPCER) 0.18\%. We have also reported the test results of the models against unseen spoof types to replicate uncertain real-world testing scenarios.
<div id='section'>Paperid: <span id='pid'>133, <a href='https://arxiv.org/pdf/2301.02145.pdf' target='_blank'>https://arxiv.org/pdf/2301.02145.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Usman Muhammad, Jorma Laaksonen, Djamila Romaissa Beddiar, Mourad Oussalah
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.02145">Domain Generalization via Ensemble Stacking for Face Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face Presentation Attack Detection (PAD) plays a pivotal role in securing face recognition systems against spoofing attacks. Although great progress has been made in designing face PAD methods, developing a model that can generalize well to unseen test domains remains a significant challenge. Moreover, due to different types of spoofing attacks, creating a dataset with a sufficient number of samples for training deep neural networks is a laborious task. This work proposes a comprehensive solution that combines synthetic data generation and deep ensemble learning to enhance the generalization capabilities of face PAD. Specifically, synthetic data is generated by blending a static image with spatiotemporal encoded images using alpha composition and video distillation. This way, we simulate motion blur with varying alpha values, thereby generating diverse subsets of synthetic data that contribute to a more enriched training set. Furthermore, multiple base models are trained on each subset of synthetic data using stacked ensemble learning. This allows the models to learn complementary features and representations from different synthetic subsets. The meta-features generated by the base models are used as input to a new model called the meta-model. The latter combines the predictions from the base models, leveraging their complementary information to better handle unseen target domains and enhance the overall performance. Experimental results on four datasets demonstrate low half total error rates (HTERs) on three benchmark datasets: CASIA-MFSD (8.92%), MSU-MFSD (4.81%), and OULU-NPU (6.70%). The approach shows potential for advancing presentation attack detection by utilizing large-scale synthetic data and the meta-model.
<div id='section'>Paperid: <span id='pid'>134, <a href='https://arxiv.org/pdf/2209.09035.pdf' target='_blank'>https://arxiv.org/pdf/2209.09035.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Meiling Fang, Wufei Yang, Arjan Kuijper, Vitomir Struc, Naser Damer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2209.09035">Fairness in Face Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition (FR) algorithms have been proven to exhibit discriminatory behaviors against certain demographic and non-demographic groups, raising ethical and legal concerns regarding their deployment in real-world scenarios. Despite the growing number of fairness studies in FR, the fairness of face presentation attack detection (PAD) has been overlooked, mainly due to the lack of appropriately annotated data. To avoid and mitigate the potential negative impact of such behavior, it is essential to assess the fairness in face PAD and develop fair PAD models. To enable fairness analysis in face PAD, we present a Combined Attribute Annotated PAD Dataset (CAAD-PAD), offering seven human-annotated attribute labels. Then, we comprehensively analyze the fairness of PAD and its relation to the nature of the training data and the Operational Decision Threshold Assignment (ODTA) through a set of face PAD solutions. Additionally, we propose a novel metric, the Accuracy Balanced Fairness (ABF), that jointly represents both the PAD fairness and the absolute PAD performance. The experimental results pointed out that female and faces with occluding features (e.g. eyeglasses, beard, etc.) are relatively less protected than male and non-occlusion groups by all PAD solutions. To alleviate this observed unfairness, we propose a plug-and-play data augmentation method, FairSWAP, to disrupt the identity/semantic information and encourage models to mine the attack clues. The extensive experimental results indicate that FairSWAP leads to better-performing and fairer face PADs in 10 out of 12 investigated cases.
<div id='section'>Paperid: <span id='pid'>135, <a href='https://arxiv.org/pdf/2508.16858.pdf' target='_blank'>https://arxiv.org/pdf/2508.16858.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yihan Wu, Jee-weon Jung, Hye-jin Shim, Xin Cheng, Xin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.16858">WildSpoof Challenge Evaluation Plan</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The WildSpoof Challenge aims to advance the use of in-the-wild data in two intertwined speech processing tasks. It consists of two parallel tracks: (1) Text-to-Speech (TTS) synthesis for generating spoofed speech, and (2) Spoofing-robust Automatic Speaker Verification (SASV) for detecting spoofed speech. While the organizers coordinate both tracks and define the data protocols, participants treat them as separate and independent tasks. The primary objectives of the challenge are: (i) to promote the use of in-the-wild data for both TTS and SASV, moving beyond conventional clean and controlled datasets and considering real-world scenarios; and (ii) to encourage interdisciplinary collaboration between the spoofing generation (TTS) and spoofing detection (SASV) communities, thereby fostering the development of more integrated, robust, and realistic systems.
<div id='section'>Paperid: <span id='pid'>136, <a href='https://arxiv.org/pdf/2508.13078.pdf' target='_blank'>https://arxiv.org/pdf/2508.13078.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qingwen Zeng, Juan E. Tapia, Izan Garcia, Juan M. Espin, Christoph Busch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.13078">ID-Card Synthetic Generation: Toward a Simulated Bona fide Dataset</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nowadays, the development of a Presentation Attack Detection (PAD) system for ID cards presents a challenge due to the lack of images available to train a robust PAD system and the increase in diversity of possible attack instrument species. Today, most algorithms focus on generating attack samples and do not take into account the limited number of bona fide images. This work is one of the first to propose a method for mimicking bona fide images by generating synthetic versions of them using Stable Diffusion, which may help improve the generalisation capabilities of the detector. Furthermore, the new images generated are evaluated in a system trained from scratch and in a commercial solution. The PAD system yields an interesting result, as it identifies our images as bona fide, which has a positive impact on detection performance and data restrictions.
<div id='section'>Paperid: <span id='pid'>137, <a href='https://arxiv.org/pdf/2507.16393.pdf' target='_blank'>https://arxiv.org/pdf/2507.16393.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lazaro Janier Gonzalez-Sole, Juan E. Tapia, Christoph Busch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.16393">Are Foundation Models All You Need for Zero-shot Face Presentation Attack Detection?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although face recognition systems have undergone an impressive evolution in the last decade, these technologies are vulnerable to attack presentations (AP). These attacks are mostly easy to create and, by executing them against the system's capture device, the malicious actor can impersonate an authorised subject and thus gain access to the latter's information (e.g., financial transactions). To protect facial recognition schemes against presentation attacks, state-of-the-art deep learning presentation attack detection (PAD) approaches require a large amount of data to produce reliable detection performances and even then, they decrease their performance for unknown presentation attack instruments (PAI) or database (information not seen during training), i.e. they lack generalisability. To mitigate the above problems, this paper focuses on zero-shot PAD. To do so, we first assess the effectiveness and generalisability of foundation models in established and challenging experimental scenarios and then propose a simple but effective framework for zero-shot PAD. Experimental results show that these models are able to achieve performance in difficult scenarios with minimal effort of the more advanced PAD mechanisms, whose weights were optimised mainly with training sets that included APs and bona fide presentations. The top-performing foundation model outperforms by a margin the best from the state of the art observed with the leaving-one-out protocol on the SiW-Mv2 database, which contains challenging unknown 2D and 3D attacks
<div id='section'>Paperid: <span id='pid'>138, <a href='https://arxiv.org/pdf/2506.05263.pdf' target='_blank'>https://arxiv.org/pdf/2506.05263.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan E. Tapia, Christoph Busch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.05263">Can Foundation Models Generalise the Presentation Attack Detection Capabilities on ID Cards?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nowadays, one of the main challenges in presentation attack detection (PAD) on ID cards is obtaining generalisation capabilities for a diversity of countries that are issuing ID cards. Most PAD systems are trained on one, two, or three ID documents because of privacy protection concerns. As a result, they do not obtain competitive results for commercial purposes when tested in an unknown new ID card country. In this scenario, Foundation Models (FM) trained on huge datasets can help to improve generalisation capabilities. This work intends to improve and benchmark the capabilities of FM and how to use them to adapt the generalisation on PAD of ID Documents. Different test protocols were used, considering zero-shot and fine-tuning and two different ID card datasets. One private dataset based on Chilean IDs and one open-set based on three ID countries: Finland, Spain, and Slovakia. Our findings indicate that bona fide images are the key to generalisation.
<div id='section'>Paperid: <span id='pid'>139, <a href='https://arxiv.org/pdf/2505.07540.pdf' target='_blank'>https://arxiv.org/pdf/2505.07540.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan E. Tapia, Fabian Stockhardt, LÃ¡zaro Janier GonzÃ¡lez-Soler, Christoph Busch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.07540">SynID: Passport Synthetic Dataset for Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The demand for Presentation Attack Detection (PAD) to identify fraudulent ID documents in remote verification systems has significantly risen in recent years. This increase is driven by several factors, including the rise of remote work, online purchasing, migration, and advancements in synthetic images. Additionally, we have noticed a surge in the number of attacks aimed at the enrolment process. Training a PAD to detect fake ID documents is very challenging because of the limited number of ID documents available due to privacy concerns. This work proposes a new passport dataset generated from a hybrid method that combines synthetic data and open-access information using the ICAO requirement to obtain realistic training and testing images.
<div id='section'>Paperid: <span id='pid'>140, <a href='https://arxiv.org/pdf/2503.00643.pdf' target='_blank'>https://arxiv.org/pdf/2503.00643.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yante Li, Hanwen Qi, Haoyu Chen, Xinlian Liang, Guoying Zhao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.00643">Deep Change Monitoring: A Hyperbolic Representative Learning Framework and a Dataset for Long-term Fine-grained Tree Change Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In environmental protection, tree monitoring plays an essential role in maintaining and improving ecosystem health. However, precise monitoring is challenging because existing datasets fail to capture continuous fine-grained changes in trees due to low-resolution images and high acquisition costs. In this paper, we introduce UAVTC, a large-scale, long-term, high-resolution dataset collected using UAVs equipped with cameras, specifically designed to detect individual Tree Changes (TCs). UAVTC includes rich annotations and statistics based on biological knowledge, offering a fine-grained view for tree monitoring. To address environmental influences and effectively model the hierarchical diversity of physiological TCs, we propose a novel Hyperbolic Siamese Network (HSN) for TC detection, enabling compact and hierarchical representations of dynamic tree changes.
  Extensive experiments show that HSN can effectively capture complex hierarchical changes and provide a robust solution for fine-grained TC detection. In addition, HSN generalizes well to cross-domain face anti-spoofing task, highlighting its broader significance in AI. We believe our work, combining ecological insights and interdisciplinary expertise, will benefit the community by offering a new benchmark and innovative AI technologies.
<div id='section'>Paperid: <span id='pid'>141, <a href='https://arxiv.org/pdf/2501.06312.pdf' target='_blank'>https://arxiv.org/pdf/2501.06312.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Juan E. Tapia, LÃ¡zaro Janier GonzÃ¡lez-Soler, Christoph Busch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.06312">Towards Iris Presentation Attack Detection with Foundation Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Foundation models are becoming increasingly popular due to their strong generalization capabilities resulting from being trained on huge datasets. These generalization capabilities are attractive in areas such as NIR Iris Presentation Attack Detection (PAD), in which databases are limited in the number of subjects and diversity of attack instruments, and there is no correspondence between the bona fide and attack images because, most of the time, they do not belong to the same subjects. This work explores an iris PAD approach based on two foundation models, DinoV2 and VisualOpenClip. The results show that fine-tuning prediction with a small neural network as head overpasses the state-of-the-art performance based on deep learning approaches. However, systems trained from scratch have still reached better results if bona fide and attack images are available.
<div id='section'>Paperid: <span id='pid'>142, <a href='https://arxiv.org/pdf/2412.16008.pdf' target='_blank'>https://arxiv.org/pdf/2412.16008.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jos Wigchert, Savio Sciancalepore, Gabriele Oligeri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2412.16008">Detection of Aerial Spoofing Attacks to LEO Satellite Systems via Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting spoofing attacks to Low-Earth-Orbit (LEO) satellite systems is a cornerstone to assessing the authenticity of the received information and guaranteeing robust service delivery in several application domains. The solutions available today for spoofing detection either rely on additional communication systems, receivers, and antennas, or require mobile deployments. Detection systems working at the Physical (PHY) layer of the satellite communication link also require time-consuming and energy-hungry training processes on all satellites of the constellation, and rely on the availability of spoofed data, which are often challenging to collect. Moreover, none of such contributions investigate the feasibility of aerial spoofing attacks launched via drones operating at various altitudes. In this paper, we propose a new spoofing detection technique for LEO satellite constellation systems, applying anomaly detection on the received PHY signal via autoencoders. We validate our solution through an extensive measurement campaign involving the deployment of an actual spoofer (Software-Defined Radio) installed on a drone and injecting rogue IRIDIUM messages while flying at different altitudes with various movement patterns. Our results demonstrate that the proposed technique can reliably detect LEO spoofing attacks launched at different altitudes, while state-of-the-art competing approaches simply fail. We also release the collected data as open source, fostering further research on satellite security.
<div id='section'>Paperid: <span id='pid'>143, <a href='https://arxiv.org/pdf/2411.19841.pdf' target='_blank'>https://arxiv.org/pdf/2411.19841.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Awais Khan, Ijaz Ul Haq, Khalid Mahmood Malik
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.19841">Parallel Stacked Aggregated Network for Voice Authentication in IoT-Enabled Smart Devices</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Voice authentication on IoT-enabled smart devices has gained prominence in recent years due to increasing concerns over user privacy and security. The current authentication systems are vulnerable to different voice-spoofing attacks (e.g., replay, voice cloning, and audio deepfakes) that mimic legitimate voices to deceive authentication systems and enable fraudulent activities (e.g., impersonation, unauthorized access, financial fraud, etc.). Existing solutions are often designed to tackle a single type of attack, leading to compromised performance against unseen attacks. On the other hand, existing unified voice anti-spoofing solutions, not designed specifically for IoT, possess complex architectures and thus cannot be deployed on IoT-enabled smart devices. Additionally, most of these unified solutions exhibit significant performance issues, including higher equal error rates or lower accuracy for specific attacks. To overcome these issues, we present the parallel stacked aggregation network (PSA-Net), a lightweight framework designed as an anti-spoofing defense system for voice-controlled smart IoT devices. The PSA-Net processes raw audios directly and eliminates the need for dataset-dependent handcrafted features or pre-computed spectrograms. Furthermore, PSA-Net employs a split-transform-aggregate approach, which involves the segmentation of utterances, the extraction of intrinsic differentiable embeddings through convolutions, and the aggregation of them to distinguish legitimate from spoofed audios. In contrast to existing deep Resnet-oriented solutions, we incorporate cardinality as an additional dimension in our network, which enhances the PSA-Net ability to generalize across diverse attacks. The results show that the PSA-Net achieves more consistent performance for different attacks that exist in current anti-spoofing solutions.
<div id='section'>Paperid: <span id='pid'>144, <a href='https://arxiv.org/pdf/2402.04178.pdf' target='_blank'>https://arxiv.org/pdf/2402.04178.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yichen Shi, Yuhao Gao, Yingxin Lai, Hongyang Wang, Jun Feng, Lei He, Jun Wan, Changsheng Chen, Zitong Yu, Xiaochun Cao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.04178">SHIELD : An Evaluation Benchmark for Face Spoofing and Forgery Detection with Multimodal Large Language Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multimodal large language models (MLLMs) have demonstrated strong capabilities in vision-related tasks, capitalizing on their visual semantic comprehension and reasoning capabilities. However, their ability to detect subtle visual spoofing and forgery clues in face attack detection tasks remains underexplored. In this paper, we introduce a benchmark, SHIELD, to evaluate MLLMs for face spoofing and forgery detection. Specifically, we design true/false and multiple-choice questions to assess MLLM performance on multimodal face data across two tasks. For the face anti-spoofing task, we evaluate three modalities (i.e., RGB, infrared, and depth) under six attack types. For the face forgery detection task, we evaluate GAN-based and diffusion-based data, incorporating visual and acoustic modalities. We conduct zero-shot and few-shot evaluations in standard and chain of thought (COT) settings. Additionally, we propose a novel multi-attribute chain of thought (MA-COT) paradigm for describing and judging various task-specific and task-irrelevant attributes of face images. The findings of this study demonstrate that MLLMs exhibit strong potential for addressing the challenges associated with the security of facial recognition technology applications.
<div id='section'>Paperid: <span id='pid'>145, <a href='https://arxiv.org/pdf/2309.10560.pdf' target='_blank'>https://arxiv.org/pdf/2309.10560.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Awais Khan, Khalid Mahmood Malik
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.10560">Bridging the Spoof Gap: A Unified Parallel Aggregation Network for Voice Presentation Attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic Speaker Verification (ASV) systems are increasingly used in voice bio-metrics for user authentication but are susceptible to logical and physical spoofing attacks, posing security risks. Existing research mainly tackles logical or physical attacks separately, leading to a gap in unified spoofing detection. Moreover, when existing systems attempt to handle both types of attacks, they often exhibit significant disparities in the Equal Error Rate (EER). To bridge this gap, we present a Parallel Stacked Aggregation Network that processes raw audio. Our approach employs a split-transform-aggregation technique, dividing utterances into convolved representations, applying transformations, and aggregating the results to identify logical (LA) and physical (PA) spoofing attacks. Evaluation of the ASVspoof-2019 and VSDC datasets shows the effectiveness of the proposed system. It outperforms state-of-the-art solutions, displaying reduced EER disparities and superior performance in detecting spoofing attacks. This highlights the proposed method's generalizability and superiority. In a world increasingly reliant on voice-based security, our unified spoofing detection system provides a robust defense against a spectrum of voice spoofing attacks, safeguarding ASVs and user data effectively.
<div id='section'>Paperid: <span id='pid'>146, <a href='https://arxiv.org/pdf/2309.09837.pdf' target='_blank'>https://arxiv.org/pdf/2309.09837.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Awais Khan, Khalid Mahmood Malik, Shah Nawaz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.09837">Frame-to-Utterance Convergence: A Spectra-Temporal Approach for Unified Spoofing Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Voice spoofing attacks pose a significant threat to automated speaker verification systems. Existing anti-spoofing methods often simulate specific attack types, such as synthetic or replay attacks. However, in real-world scenarios, the countermeasures are unaware of the generation schema of the attack, necessitating a unified solution. Current unified solutions struggle to detect spoofing artifacts, especially with recent spoofing mechanisms. For instance, the spoofing algorithms inject spectral or temporal anomalies, which are challenging to identify. To this end, we present a spectra-temporal fusion leveraging frame-level and utterance-level coefficients. We introduce a novel local spectral deviation coefficient (SDC) for frame-level inconsistencies and employ a bi-LSTM-based network for sequential temporal coefficients (STC), which capture utterance-level artifacts. Our spectra-temporal fusion strategy combines these coefficients, and an auto-encoder generates spectra-temporal deviated coefficients (STDC) to enhance robustness. Our proposed approach addresses multiple spoofing categories, including synthetic, replay, and partial deepfake attacks. Extensive evaluation on diverse datasets (ASVspoof2019, ASVspoof2021, VSDC, partial spoofs, and in-the-wild deepfakes) demonstrated its robustness for a wide range of voice applications.
<div id='section'>Paperid: <span id='pid'>147, <a href='https://arxiv.org/pdf/2309.08279.pdf' target='_blank'>https://arxiv.org/pdf/2309.08279.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxiang Zhang, Jingze Lu, Zengqiang Shang, Wenchao Wang, Pengyuan Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.08279">Improving Short Utterance Anti-Spoofing with AASIST2</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The wav2vec 2.0 and integrated spectro-temporal graph attention network (AASIST) based countermeasure achieves great performance in speech anti-spoofing. However, current spoof speech detection systems have fixed training and evaluation durations, while the performance degrades significantly during short utterance evaluation. To solve this problem, AASIST can be improved to AASIST2 by modifying the residual blocks to Res2Net blocks. The modified Res2Net blocks can extract multi-scale features and improve the detection performance for speech of different durations, thus improving the short utterance evaluation performance. On the other hand, adaptive large margin fine-tuning (ALMFT) has achieved performance improvement in short utterance speaker verification. Therefore, we apply Dynamic Chunk Size (DCS) and ALMFT training strategies in speech anti-spoofing to further improve the performance of short utterance evaluation. Experiments demonstrate that the proposed AASIST2 improves the performance of short utterance evaluation while maintaining the performance of regular evaluation on different datasets.
<div id='section'>Paperid: <span id='pid'>148, <a href='https://arxiv.org/pdf/2307.13958.pdf' target='_blank'>https://arxiv.org/pdf/2307.13958.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zitong Yu, Rizhao Cai, Yawen Cui, Ajian Liu, Changsheng Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.13958">Visual Prompt Flexible-Modal Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently, vision transformer based multimodal learning methods have been proposed to improve the robustness of face anti-spoofing (FAS) systems. However, multimodal face data collected from the real world is often imperfect due to missing modalities from various imaging sensors. Recently, flexible-modal FAS~\cite{yu2023flexible} has attracted more attention, which aims to develop a unified multimodal FAS model using complete multimodal face data but is insensitive to test-time missing modalities. In this paper, we tackle one main challenge in flexible-modal FAS, i.e., when missing modality occurs either during training or testing in real-world situations. Inspired by the recent success of the prompt learning in language models, we propose \textbf{V}isual \textbf{P}rompt flexible-modal \textbf{FAS} (VP-FAS), which learns the modal-relevant prompts to adapt the frozen pre-trained foundation model to downstream flexible-modal FAS task. Specifically, both vanilla visual prompts and residual contextual prompts are plugged into multimodal transformers to handle general missing-modality cases, while only requiring less than 4\% learnable parameters compared to training the entire model. Furthermore, missing-modality regularization is proposed to force models to learn consistent multimodal feature embeddings when missing partial modalities. Extensive experiments conducted on two multimodal FAS benchmark datasets demonstrate the effectiveness of our VP-FAS framework that improves the performance under various missing-modality cases while alleviating the requirement of heavy model re-training.
<div id='section'>Paperid: <span id='pid'>149, <a href='https://arxiv.org/pdf/2305.15940.pdf' target='_blank'>https://arxiv.org/pdf/2305.15940.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Chenglin Yao, Jianfeng Ren, Ruibin Bai, Heshan Du, Jiang Liu, Xudong Jiang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.15940">Mask Attack Detection Using Vascular-weighted Motion-robust rPPG Signals</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Detecting 3D mask attacks to a face recognition system is challenging. Although genuine faces and 3D face masks show significantly different remote photoplethysmography (rPPG) signals, rPPG-based face anti-spoofing methods often suffer from performance degradation due to unstable face alignment in the video sequence and weak rPPG signals. To enhance the rPPG signal in a motion-robust way, a landmark-anchored face stitching method is proposed to align the faces robustly and precisely at the pixel-wise level by using both SIFT keypoints and facial landmarks. To better encode the rPPG signal, a weighted spatial-temporal representation is proposed, which emphasizes the face regions with rich blood vessels. In addition, characteristics of rPPG signals in different color spaces are jointly utilized. To improve the generalization capability, a lightweight EfficientNet with a Gated Recurrent Unit (GRU) is designed to extract both spatial and temporal features from the rPPG spatial-temporal representation for classification. The proposed method is compared with the state-of-the-art methods on five benchmark datasets under both intra-dataset and cross-dataset evaluations. The proposed method shows a significant and consistent improvement in performance over other state-of-the-art rPPG-based methods for face spoofing detection.
<div id='section'>Paperid: <span id='pid'>150, <a href='https://arxiv.org/pdf/2303.01126.pdf' target='_blank'>https://arxiv.org/pdf/2303.01126.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xuechen Liu, Md Sahidullah, Kong Aik Lee, Tomi Kinnunen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.01126">Speaker-Aware Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We address speaker-aware anti-spoofing, where prior knowledge of the target speaker is incorporated into a voice spoofing countermeasure (CM). In contrast to the frequently used speaker-independent solutions, we train the CM in a speaker-conditioned way. As a proof of concept, we consider speaker-aware extension to the state-of-the-art AASIST (audio anti-spoofing using integrated spectro-temporal graph attention networks) model. To this end, we consider two alternative strategies to incorporate target speaker information at the frame and utterance levels, respectively. The experimental results on a custom protocol based on ASVspoof 2019 dataset indicates the efficiency of the speaker information via enrollment: we obtain maximum relative improvements of 25.1% and 11.6% in equal error rate (EER) and minimum tandem detection cost function (t-DCF) over a speaker-independent baseline, respectively.
<div id='section'>Paperid: <span id='pid'>151, <a href='https://arxiv.org/pdf/2208.11148.pdf' target='_blank'>https://arxiv.org/pdf/2208.11148.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiao Guo, Yaojie Liu, Anil Jain, Xiaoming Liu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2208.11148">Multi-domain Learning for Updating Face Anti-spoofing Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this work, we study multi-domain learning for face anti-spoofing(MD-FAS), where a pre-trained FAS model needs to be updated to perform equally well on both source and target domains while only using target domain data for updating. We present a new model for MD-FAS, which addresses the forgetting issue when learning new domain data, while possessing a high level of adaptability. First, we devise a simple yet effective module, called spoof region estimator(SRE), to identify spoof traces in the spoof image. Such spoof traces reflect the source pre-trained model's responses that help upgraded models combat catastrophic forgetting during updating. Unlike prior works that estimate spoof traces which generate multiple outputs or a low-resolution binary mask, SRE produces one single, detailed pixel-wise estimate in an unsupervised manner. Secondly, we propose a novel framework, named FAS-wrapper, which transfers knowledge from the pre-trained models and seamlessly integrates with different FAS models. Lastly, to help the community further advance MD-FAS, we construct a new benchmark based on SIW, SIW-Mv2 and Oulu-NPU, and introduce four distinct protocols for evaluation, where source and target domains are different in terms of spoof type, age, ethnicity, and illumination. Our proposed method achieves superior performance on the MD-FAS benchmark than previous methods. Our code and newly curated SIW-Mv2 are publicly available.
<div id='section'>Paperid: <span id='pid'>152, <a href='https://arxiv.org/pdf/2509.23475.pdf' target='_blank'>https://arxiv.org/pdf/2509.23475.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ming-Tsung Hsu, Fang-Yu Hsu, Yi-Ting Lin, Kai-Heng Chien, Jun-Ren Chen, Cheng-Hsiang Su, Yi-Chen Ou, Chiou-Ting Hsu, Pei-Kai Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.23475">Robust Multi-Modal Face Anti-Spoofing with Domain Adaptation: Tackling Missing Modalities, Noisy Pseudo-Labels, and Model Degradation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent multi-modal face anti-spoofing (FAS) methods have investigated the potential of leveraging multiple modalities to distinguish live and spoof faces. However, pre-adapted multi-modal FAS models often fail to detect unseen attacks from new target domains. Although a more realistic domain adaptation (DA) scenario has been proposed for single-modal FAS to learn specific spoof attacks during inference, DA remains unexplored in multi-modal FAS methods. In this paper, we propose a novel framework, MFAS-DANet, to address three major challenges in multi-modal FAS under the DA scenario: missing modalities, noisy pseudo labels, and model degradation. First, to tackle the issue of missing modalities, we propose extracting complementary features from other modalities to substitute missing modality features or enhance existing ones. Next, to reduce the impact of noisy pseudo labels during model adaptation, we propose deriving reliable pseudo labels by leveraging prediction uncertainty across different modalities. Finally, to prevent model degradation, we design an adaptive mechanism that decreases the loss weight during unstable adaptations and increasing it during stable ones. Extensive experiments demonstrate the effectiveness and state-of-the-art performance of our proposed MFAS-DANet.
<div id='section'>Paperid: <span id='pid'>153, <a href='https://arxiv.org/pdf/2507.05575.pdf' target='_blank'>https://arxiv.org/pdf/2507.05575.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jun-Xiong Chong, Fang-Yu Hsu, Ming-Tsung Hsu, Yi-Ting Lin, Kai-Heng Chien, Chiou-Ting Hsu, Pei-Kai Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.05575">Multi-Modal Face Anti-Spoofing via Cross-Modal Feature Transitions</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Multi-modal face anti-spoofing (FAS) aims to detect genuine human presence by extracting discriminative liveness cues from multiple modalities, such as RGB, infrared (IR), and depth images, to enhance the robustness of biometric authentication systems. However, because data from different modalities are typically captured by various camera sensors and under diverse environmental conditions, multi-modal FAS often exhibits significantly greater distribution discrepancies across training and testing domains compared to single-modal FAS. Furthermore, during the inference stage, multi-modal FAS confronts even greater challenges when one or more modalities are unavailable or inaccessible. In this paper, we propose a novel Cross-modal Transition-guided Network (CTNet) to tackle the challenges in the multi-modal FAS task. Our motivation stems from that, within a single modality, the visual differences between live faces are typically much smaller than those of spoof faces. Additionally, feature transitions across modalities are more consistent for the live class compared to those between live and spoof classes. Upon this insight, we first propose learning consistent cross-modal feature transitions among live samples to construct a generalized feature space. Next, we introduce learning the inconsistent cross-modal feature transitions between live and spoof samples to effectively detect out-of-distribution (OOD) attacks during inference. To further address the issue of missing modalities, we propose learning complementary infrared (IR) and depth features from the RGB modality as auxiliary modalities. Extensive experiments demonstrate that the proposed CTNet outperforms previous two-class multi-modal FAS methods across most protocols.
<div id='section'>Paperid: <span id='pid'>154, <a href='https://arxiv.org/pdf/2504.04818.pdf' target='_blank'>https://arxiv.org/pdf/2504.04818.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zuying Xie, Changtao Miao, Ajian Liu, Jiabao Guo, Feng Li, Dan Guo, Yunfeng Diao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.04818">SUEDE:Shared Unified Experts for Physical-Digital Face Attack Detection Enhancement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition systems are vulnerable to physical attacks (e.g., printed photos) and digital threats (e.g., DeepFake), which are currently being studied as independent visual tasks, such as Face Anti-Spoofing and Forgery Detection. The inherent differences among various attack types present significant challenges in identifying a common feature space, making it difficult to develop a unified framework for detecting data from both attack modalities simultaneously. Inspired by the efficacy of Mixture-of-Experts (MoE) in learning across diverse domains, we explore utilizing multiple experts to learn the distinct features of various attack types. However, the feature distributions of physical and digital attacks overlap and differ. This suggests that relying solely on distinct experts to learn the unique features of each attack type may overlook shared knowledge between them. To address these issues, we propose SUEDE, the Shared Unified Experts for Physical-Digital Face Attack Detection Enhancement. SUEDE combines a shared expert (always activated) to capture common features for both attack types and multiple routed experts (selectively activated) for specific attack types. Further, we integrate CLIP as the base network to ensure the shared expert benefits from prior visual knowledge and align visual-text representations in a unified space. Extensive results demonstrate SUEDE achieves superior performance compared to state-of-the-art unified detection methods.
<div id='section'>Paperid: <span id='pid'>155, <a href='https://arxiv.org/pdf/2503.22929.pdf' target='_blank'>https://arxiv.org/pdf/2503.22929.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pei-Kai Huang, Jun-Xiong Chong, Ming-Tsung Hsu, Fang-Yu Hsu, Yi-Ting Lin, Kai-Heng Chien, Hao-Chiang Shao, Chiou-Ting Hsu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22929">Unsupervised Feature Disentanglement and Augmentation Network for One-class Face Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) techniques aim to enhance the security of facial identity authentication by distinguishing authentic live faces from deceptive attempts. While two-class FAS methods risk overfitting to training attacks to achieve better performance, one-class FAS approaches handle unseen attacks well but are less robust to domain information entangled within the liveness features. To address this, we propose an Unsupervised Feature Disentanglement and Augmentation Network (\textbf{UFDANet}), a one-class FAS technique that enhances generalizability by augmenting face images via disentangled features. The \textbf{UFDANet} employs a novel unsupervised feature disentangling method to separate the liveness and domain features, facilitating discriminative feature learning. It integrates an out-of-distribution liveness feature augmentation scheme to synthesize new liveness features of unseen spoof classes, which deviate from the live class, thus enhancing the representability and discriminability of liveness features. Additionally, \textbf{UFDANet} incorporates a domain feature augmentation routine to synthesize unseen domain features, thereby achieving better generalizability. Extensive experiments demonstrate that the proposed \textbf{UFDANet} outperforms previous one-class FAS methods and achieves comparable performance to state-of-the-art two-class FAS methods.
<div id='section'>Paperid: <span id='pid'>156, <a href='https://arxiv.org/pdf/2503.19982.pdf' target='_blank'>https://arxiv.org/pdf/2503.19982.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pei-Kai Huang, Jun-Xiong Chong, Cheng-Hsuan Chiang, Tzu-Hsien Chen, Tyng-Luh Liu, Chiou-Ting Hsu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.19982">SLIP: Spoof-Aware One-Class Face Anti-Spoofing with Language Image Pretraining</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) plays a pivotal role in ensuring the security and reliability of face recognition systems. With advancements in vision-language pretrained (VLP) models, recent two-class FAS techniques have leveraged the advantages of using VLP guidance, while this potential remains unexplored in one-class FAS methods. The one-class FAS focuses on learning intrinsic liveness features solely from live training images to differentiate between live and spoof faces. However, the lack of spoof training data can lead one-class FAS models to inadvertently incorporate domain information irrelevant to the live/spoof distinction (e.g., facial content), causing performance degradation when tested with a new application domain. To address this issue, we propose a novel framework called Spoof-aware one-class face anti-spoofing with Language Image Pretraining (SLIP). Given that live faces should ideally not be obscured by any spoof-attack-related objects (e.g., paper, or masks) and are assumed to yield zero spoof cue maps, we first propose an effective language-guided spoof cue map estimation to enhance one-class FAS models by simulating whether the underlying faces are covered by attack-related objects and generating corresponding nonzero spoof cue maps. Next, we introduce a novel prompt-driven liveness feature disentanglement to alleviate live/spoof-irrelative domain variations by disentangling live/spoof-relevant and domain-dependent information. Finally, we design an effective augmentation strategy by fusing latent features from live images and spoof prompts to generate spoof-like image features and thus diversify latent spoof features to facilitate the learning of one-class FAS. Our extensive experiments and ablation studies support that SLIP consistently outperforms previous one-class FAS methods.
<div id='section'>Paperid: <span id='pid'>157, <a href='https://arxiv.org/pdf/2410.09866.pdf' target='_blank'>https://arxiv.org/pdf/2410.09866.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Asish Bera, Debotosh Bhattacharjee, Hubert P H Shum
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.09866">Two-Stage Human Verification using HandCAPTCHA and Anti-Spoofed Finger Biometrics with Feature Selection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a human verification scheme in two independent stages to overcome the vulnerabilities of attacks and to enhance security. At the first stage, a hand image-based CAPTCHA (HandCAPTCHA) is tested to avert automated bot-attacks on the subsequent biometric stage. In the next stage, finger biometric verification of a legitimate user is performed with presentation attack detection (PAD) using the real hand images of the person who has passed a random HandCAPTCHA challenge. The electronic screen-based PAD is tested using image quality metrics. After this spoofing detection, geometric features are extracted from the four fingers (excluding the thumb) of real users. A modified forward-backward (M-FoBa) algorithm is devised to select relevant features for biometric authentication. The experiments are performed on the Bogazici University (BU) and the IIT-Delhi (IITD) hand databases using the k-nearest neighbor and random forest classifiers. The average accuracy of the correct HandCAPTCHA solution is 98.5%, and the false accept rate of a bot is 1.23%. The PAD is tested on 255 subjects of BU, and the best average error is 0%. The finger biometric identification accuracy of 98% and an equal error rate (EER) of 6.5% have been achieved for 500 subjects of the BU. For 200 subjects of the IITD, 99.5% identification accuracy, and 5.18% EER are obtained.
<div id='section'>Paperid: <span id='pid'>158, <a href='https://arxiv.org/pdf/2403.01355.pdf' target='_blank'>https://arxiv.org/pdf/2403.01355.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hye-jin Shim, Jee-weon Jung, Tomi Kinnunen, Nicholas Evans, Jean-Francois Bonastre, Itshak Lapidot
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.01355">a-DCF: an architecture agnostic metric with application to spoofing-robust speaker verification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spoofing detection is today a mainstream research topic. Standard metrics can be applied to evaluate the performance of isolated spoofing detection solutions and others have been proposed to support their evaluation when they are combined with speaker detection. These either have well-known deficiencies or restrict the architectural approach to combine speaker and spoof detectors. In this paper, we propose an architecture-agnostic detection cost function (a-DCF). A generalisation of the original DCF used widely for the assessment of automatic speaker verification (ASV), the a-DCF is designed for the evaluation of spoofing-robust ASV. Like the DCF, the a-DCF reflects the cost of decisions in a Bayes risk sense, with explicitly defined class priors and detection cost model. We demonstrate the merit of the a-DCF through the benchmarking evaluation of architecturally-heterogeneous spoofing-robust ASV solutions.
<div id='section'>Paperid: <span id='pid'>159, <a href='https://arxiv.org/pdf/2401.09512.pdf' target='_blank'>https://arxiv.org/pdf/2401.09512.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicolas M. MÃ¼ller, Piotr Kawa, Wei Herng Choong, Edresson Casanova, Eren GÃ¶lge, Thorsten MÃ¼ller, Piotr Syga, Philip Sperl, Konstantin BÃ¶ttinger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.09512">MLAAD: The Multi-Language Audio Anti-Spoofing Dataset</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Text-to-Speech (TTS) technology offers notable benefits, such as providing a voice for individuals with speech impairments, but it also facilitates the creation of audio deepfakes and spoofing attacks. AI-based detection methods can help mitigate these risks; however, the performance of such models is inherently dependent on the quality and diversity of their training data. Presently, the available datasets are heavily skewed towards English and Chinese audio, which limits the global applicability of these anti-spoofing systems.
  To address this limitation, this paper presents the Multi-Language Audio Anti-Spoofing Dataset (MLAAD), version 7, created using 101 TTS models, comprising 52 different architectures, to generate 485.3 hours of synthetic voice in 40 different languages. We train and evaluate three state-of-the-art deepfake detection models with MLAAD and observe that it demonstrates superior performance over comparable datasets like InTheWild and Fake-Or-Real when used as a training resource. Moreover, compared to the renowned ASVspoof 2019 dataset, MLAAD proves to be a complementary resource. In tests across eight datasets, MLAAD and ASVspoof 2019 alternately outperformed each other, each excelling on four datasets. By publishing MLAAD and making a trained model accessible via an interactive webserver, we aim to democratize anti-spoofing technology, making it accessible beyond the realm of specialists, and contributing to global efforts against audio spoofing and deepfakes.
<div id='section'>Paperid: <span id='pid'>160, <a href='https://arxiv.org/pdf/2309.11827.pdf' target='_blank'>https://arxiv.org/pdf/2309.11827.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxiang Zhang, Zhuo Li, Jingze Lu, Hua Hua, Wenchao Wang, Pengyuan Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.11827">The Impact of Silence on Speech Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The current speech anti-spoofing countermeasures (CMs) show excellent performance on specific datasets. However, removing the silence of test speech through Voice Activity Detection (VAD) can severely degrade performance. In this paper, the impact of silence on speech anti-spoofing is analyzed. First, the reasons for the impact are explored, including the proportion of silence duration and the content of silence. The proportion of silence duration in spoof speech generated by text-to-speech (TTS) algorithms is lower than that in bonafide speech. And the content of silence generated by different waveform generators varies compared to bonafide speech. Then the impact of silence on model prediction is explored. Even after retraining, the spoof speech generated by neural network based end-to-end TTS algorithms suffers a significant rise in error rates when the silence is removed. To demonstrate the reasons for the impact of silence on CMs, the attention distribution of a CM is visualized through class activation mapping (CAM). Furthermore, the implementation and analysis of the experiments masking silence or non-silence demonstrates the significance of the proportion of silence duration for detecting TTS and the importance of silence content for detecting voice conversion (VC). Based on the experimental results, improving the robustness of CMs against unknown spoofing attacks by masking silence is also proposed. Finally, the attacks on anti-spoofing CMs through concatenating silence, and the mitigation of VAD and silence attack through low-pass filtering are introduced.
<div id='section'>Paperid: <span id='pid'>161, <a href='https://arxiv.org/pdf/2308.11800.pdf' target='_blank'>https://arxiv.org/pdf/2308.11800.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicolas M. MÃ¼ller, Philip Sperl, Konstantin BÃ¶ttinger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.11800">Complex-valued neural networks for voice anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current anti-spoofing and audio deepfake detection systems use either magnitude spectrogram-based features (such as CQT or Melspectrograms) or raw audio processed through convolution or sinc-layers. Both methods have drawbacks: magnitude spectrograms discard phase information, which affects audio naturalness, and raw-feature-based models cannot use traditional explainable AI methods. This paper proposes a new approach that combines the benefits of both methods by using complex-valued neural networks to process the complex-valued, CQT frequency-domain representation of the input audio. This method retains phase information and allows for explainable AI methods. Results show that this approach outperforms previous methods on the "In-the-Wild" anti-spoofing dataset and enables interpretation of the results through explainable AI. Ablation studies confirm that the model has learned to use phase information to detect voice spoofing.
<div id='section'>Paperid: <span id='pid'>162, <a href='https://arxiv.org/pdf/2306.10701.pdf' target='_blank'>https://arxiv.org/pdf/2306.10701.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kaiyu Cui, Shijie Rao, Sheng Xu, Yidong Huang, Xusheng Cai, Zhilei Huang, Yu Wang, Xue Feng, Fang Liu, Wei Zhang, Yali Li, Shengjin Wang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.10701">Spectral Convolutional Neural Network Chip for In-sensor Edge Computing of Incoherent Natural Light</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Convolutional neural networks (CNNs) are representative models of artificial neural networks (ANNs). However, the considerable power consumption and limited computing speed of electrical computing platforms restrict further CNN development on edge devices. Optical neural networks are considered next-generation physical implementations of ANNs, but their capabilities are limited by on-chip integration scale and requirement for coherent light sources. This study proposes a spectral convolutional neural network (SCNN) of incoherent natural light by an optical convolutional layer (OCL) and a reconfigurable electrical backend. The OCL is implemented by integrating very large-scale, pixel-aligned spectral filters on a CMOS image sensor on a 12-inch wafer, facilitating highly parallel spectral vector-inner products of incident light. It accepts broadband incoherent natural light containing two spatial and one spectral dimension directly as input with the function of matter meta-imaging. This unique optoelectronic framework empowers in-sensor optical analog computing at extremely high energy efficiency because the OCL is driven by the energy of the information carrier, i. e. natural light. To the best of our knowledge, this is the first integrated optical computing utilizing natural light. We employ the same SCNN chip for completely different real-world complex tasks,and achieve accuracies of over 96% for pathological diagnosis and almost 100% for face anti-spoofing at video rates. The SCNN framework has an unprecedented new function of substance identification, provides a feasible optoelectronic and integrated optical CNN implementation for edge devices or cellphones, providing them with practical and powerful edge computing abilities and facilitating diverse applications, such as intelligent robotics, industrial automation, medical diagnosis, and remote sensing.
<div id='section'>Paperid: <span id='pid'>163, <a href='https://arxiv.org/pdf/2305.19953.pdf' target='_blank'>https://arxiv.org/pdf/2305.19953.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hye-jin Shim, Jee-weon Jung, Tomi Kinnunen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.19953">Multi-Dataset Co-Training with Sharpness-Aware Optimization for Audio Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Audio anti-spoofing for automatic speaker verification aims to safeguard users' identities from spoofing attacks. Although state-of-the-art spoofing countermeasure(CM) models perform well on specific datasets, they lack generalization when evaluated with different datasets. To address this limitation, previous studies have explored large pre-trained models, which require significant resources and time. We aim to develop a compact but well-generalizing CM model that can compete with large pre-trained models. Our approach involves multi-dataset co-training and sharpness-aware minimization, which has not been investigated in this domain. Extensive experiments reveal that proposed method yield competitive results across various datasets while utilizing 4,000 times less parameters than the large pre-trained models.
<div id='section'>Paperid: <span id='pid'>164, <a href='https://arxiv.org/pdf/2303.13662.pdf' target='_blank'>https://arxiv.org/pdf/2303.13662.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yiyou Sun, Yaojie Liu, Xiaoming Liu, Yixuan Li, Wen-Sheng Chu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.13662">Rethinking Domain Generalization for Face Anti-spoofing: Separability and Alignment</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This work studies the generalization issue of face anti-spoofing (FAS) models on domain gaps, such as image resolution, blurriness and sensor variations. Most prior works regard domain-specific signals as a negative impact, and apply metric learning or adversarial losses to remove them from feature representation. Though learning a domain-invariant feature space is viable for the training data, we show that the feature shift still exists in an unseen test domain, which backfires on the generalizability of the classifier. In this work, instead of constructing a domain-invariant feature space, we encourage domain separability while aligning the live-to-spoof transition (i.e., the trajectory from live to spoof) to be the same for all domains. We formulate this FAS strategy of separability and alignment (SA-FAS) as a problem of invariant risk minimization (IRM), and learn domain-variant feature representation but domain-invariant classifier. We demonstrate the effectiveness of SA-FAS on challenging cross-domain FAS datasets and establish state-of-the-art performance.
<div id='section'>Paperid: <span id='pid'>165, <a href='https://arxiv.org/pdf/2510.19414.pdf' target='_blank'>https://arxiv.org/pdf/2510.19414.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tong Zhang, Yihuan Huang, Yanzhen Ren
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.19414">EchoFake: A Replay-Aware Dataset for Practical Speech Deepfake Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The growing prevalence of speech deepfakes has raised serious concerns, particularly in real-world scenarios such as telephone fraud and identity theft. While many anti-spoofing systems have demonstrated promising performance on lab-generated synthetic speech, they often fail when confronted with physical replay attacks-a common and low-cost form of attack used in practical settings. Our experiments show that models trained on existing datasets exhibit severe performance degradation, with average accuracy dropping to 59.6% when evaluated on replayed audio. To bridge this gap, we present EchoFake, a comprehensive dataset comprising more than 120 hours of audio from over 13,000 speakers, featuring both cutting-edge zero-shot text-to-speech (TTS) speech and physical replay recordings collected under varied devices and real-world environmental settings. Additionally, we evaluate three baseline detection models and show that models trained on EchoFake achieve lower average EERs across datasets, indicating better generalization. By introducing more practical challenges relevant to real-world deployment, EchoFake offers a more realistic foundation for advancing spoofing detection methods.
<div id='section'>Paperid: <span id='pid'>166, <a href='https://arxiv.org/pdf/2509.07677.pdf' target='_blank'>https://arxiv.org/pdf/2509.07677.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kamel Kamel, Hridoy Sankar Dutta, Keshav Sood, Sunil Aryal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.07677">Spectral Masking and Interpolation Attack (SMIA): A Black-box Adversarial Attack against Voice Authentication and Anti-Spoofing Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Voice Authentication Systems (VAS) use unique vocal characteristics for verification. They are increasingly integrated into high-security sectors such as banking and healthcare. Despite their improvements using deep learning, they face severe vulnerabilities from sophisticated threats like deepfakes and adversarial attacks. The emergence of realistic voice cloning complicates detection, as systems struggle to distinguish authentic from synthetic audio. While anti-spoofing countermeasures (CMs) exist to mitigate these risks, many rely on static detection models that can be bypassed by novel adversarial methods, leaving a critical security gap. To demonstrate this vulnerability, we propose the Spectral Masking and Interpolation Attack (SMIA), a novel method that strategically manipulates inaudible frequency regions of AI-generated audio. By altering the voice in imperceptible zones to the human ear, SMIA creates adversarial samples that sound authentic while deceiving CMs. We conducted a comprehensive evaluation of our attack against state-of-the-art (SOTA) models across multiple tasks, under simulated real-world conditions. SMIA achieved a strong attack success rate (ASR) of at least 82% against combined VAS/CM systems, at least 97.5% against standalone speaker verification systems, and 100% against countermeasures. These findings conclusively demonstrate that current security postures are insufficient against adaptive adversarial attacks. This work highlights the urgent need for a paradigm shift toward next-generation defenses that employ dynamic, context-aware frameworks capable of evolving with the threat landscape.
<div id='section'>Paperid: <span id='pid'>167, <a href='https://arxiv.org/pdf/2509.03409.pdf' target='_blank'>https://arxiv.org/pdf/2509.03409.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hoan My Tran, Damien Lolive, Aghilas Sini, Arnaud Delhay, Pierre-FranÃ§ois Marteau, David Guennec
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.03409">Multi-level SSL Feature Gating for Audio Deepfake Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advancements in generative AI, particularly in speech synthesis, have enabled the generation of highly natural-sounding synthetic speech that closely mimics human voices. While these innovations hold promise for applications like assistive technologies, they also pose significant risks, including misuse for fraudulent activities, identity theft, and security threats. Current research on spoofing detection countermeasures remains limited by generalization to unseen deepfake attacks and languages. To address this, we propose a gating mechanism extracting relevant feature from the speech foundation XLS-R model as a front-end feature extractor. For downstream back-end classifier, we employ Multi-kernel gated Convolution (MultiConv) to capture both local and global speech artifacts. Additionally, we introduce Centered Kernel Alignment (CKA) as a similarity metric to enforce diversity in learned features across different MultiConv layers. By integrating CKA with our gating mechanism, we hypothesize that each component helps improving the learning of distinct synthetic speech patterns. Experimental results demonstrate that our approach achieves state-of-the-art performance on in-domain benchmarks while generalizing robustly to out-of-domain datasets, including multilingual speech samples. This underscores its potential as a versatile solution for detecting evolving speech deepfake threats.
<div id='section'>Paperid: <span id='pid'>168, <a href='https://arxiv.org/pdf/2508.16843.pdf' target='_blank'>https://arxiv.org/pdf/2508.16843.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Kamel Kamel, Keshav Sood, Hridoy Sankar Dutta, Sunil Aryal
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.16843">A Survey of Threats Against Voice Authentication and Anti-Spoofing Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Voice authentication has undergone significant changes from traditional systems that relied on handcrafted acoustic features to deep learning models that can extract robust speaker embeddings. This advancement has expanded its applications across finance, smart devices, law enforcement, and beyond. However, as adoption has grown, so have the threats. This survey presents a comprehensive review of the modern threat landscape targeting Voice Authentication Systems (VAS) and Anti-Spoofing Countermeasures (CMs), including data poisoning, adversarial, deepfake, and adversarial spoofing attacks. We chronologically trace the development of voice authentication and examine how vulnerabilities have evolved in tandem with technological advancements. For each category of attack, we summarize methodologies, highlight commonly used datasets, compare performance and limitations, and organize existing literature using widely accepted taxonomies. By highlighting emerging risks and open challenges, this survey aims to support the development of more secure and resilient voice authentication systems.
<div id='section'>Paperid: <span id='pid'>169, <a href='https://arxiv.org/pdf/2508.09094.pdf' target='_blank'>https://arxiv.org/pdf/2508.09094.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Oleksandr Kuznetsov, Emanuele Frontoni, Luca Romeo, Riccardo Rosati, Andrea Maranesi, Alessandro Muscatello
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.09094">Deep Learning Models for Robust Facial Liveness Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the rapidly evolving landscape of digital security, biometric authentication systems, particularly facial recognition, have emerged as integral components of various security protocols. However, the reliability of these systems is compromised by sophisticated spoofing attacks, where imposters gain unauthorized access by falsifying biometric traits. Current literature reveals a concerning gap: existing liveness detection methodologies - designed to counteract these breaches - fall short against advanced spoofing tactics employing deepfakes and other artificial intelligence-driven manipulations. This study introduces a robust solution through novel deep learning models addressing the deficiencies in contemporary anti-spoofing techniques. By innovatively integrating texture analysis and reflective properties associated with genuine human traits, our models distinguish authentic presence from replicas with remarkable precision. Extensive evaluations were conducted across five diverse datasets, encompassing a wide range of attack vectors and environmental conditions. Results demonstrate substantial advancement over existing systems, with our best model (AttackNet V2.2) achieving 99.9% average accuracy when trained on combined data. Moreover, our research unveils critical insights into the behavioral patterns of impostor attacks, contributing to a more nuanced understanding of their evolving nature. The implications are profound: our models do not merely fortify the authentication processes but also instill confidence in biometric systems across various sectors reliant on secure access.
<div id='section'>Paperid: <span id='pid'>170, <a href='https://arxiv.org/pdf/2503.22984.pdf' target='_blank'>https://arxiv.org/pdf/2503.22984.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhuowei Li, Tianchen Zhao, Xiang Xu, Zheng Zhang, Zhihua Li, Xuanbai Chen, Qin Zhang, Alessandro Bergamo, Anil K. Jain, Yifan Xing
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22984">Optimal Transport-Guided Source-Free Adaptation for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Developing a face anti-spoofing model that meets the security requirements of clients worldwide is challenging due to the domain gap between training datasets and diverse end-user test data. Moreover, for security and privacy reasons, it is undesirable for clients to share a large amount of their face data with service providers. In this work, we introduce a novel method in which the face anti-spoofing model can be adapted by the client itself to a target domain at test time using only a small sample of data while keeping model parameters and training data inaccessible to the client. Specifically, we develop a prototype-based base model and an optimal transport-guided adaptor that enables adaptation in either a lightweight training or training-free fashion, without updating base model's parameters. Furthermore, we propose geodesic mixup, an optimal transport-based synthesis method that generates augmented training data along the geodesic path between source prototypes and target data distribution. This allows training a lightweight classifier to effectively adapt to target-specific characteristics while retaining essential knowledge learned from the source domain. In cross-domain and cross-attack settings, compared with recent methods, our method achieves average relative improvements of 19.17% in HTER and 8.58% in AUC, respectively.
<div id='section'>Paperid: <span id='pid'>171, <a href='https://arxiv.org/pdf/2406.03684.pdf' target='_blank'>https://arxiv.org/pdf/2406.03684.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Xiang Xu, Tianchen Zhao, Zheng Zhang, Zhihua Li, Jon Wu, Alessandro Achille, Mani Srivastava
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.03684">Principles of Designing Robust Remote Face Anti-Spoofing Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Protecting digital identities of human face from various attack vectors is paramount, and face anti-spoofing plays a crucial role in this endeavor. Current approaches primarily focus on detecting spoofing attempts within individual frames to detect presentation attacks. However, the emergence of hyper-realistic generative models capable of real-time operation has heightened the risk of digitally generated attacks. In light of these evolving threats, this paper aims to address two key aspects. First, it sheds light on the vulnerabilities of state-of-the-art face anti-spoofing methods against digital attacks. Second, it presents a comprehensive taxonomy of common threats encountered in face anti-spoofing systems. Through a series of experiments, we demonstrate the limitations of current face anti-spoofing detection techniques and their failure to generalize to novel digital attack scenarios. Notably, the existing models struggle with digital injection attacks including adversarial noise, realistic deepfake attacks, and digital replay attacks. To aid in the design and implementation of robust face anti-spoofing systems resilient to these emerging vulnerabilities, the paper proposes key design principles from model accuracy and robustness to pipeline robustness and even platform robustness. Especially, we suggest to implement the proactive face anti-spoofing system using active sensors to significant reduce the risks for unseen attack vectors and improve the user experience.
<div id='section'>Paperid: <span id='pid'>172, <a href='https://arxiv.org/pdf/2311.18420.pdf' target='_blank'>https://arxiv.org/pdf/2311.18420.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lianrui Mu, Jianhong Bai, Xiaoxuan He, Jiangnan Ye, Xiaoyu Liang, Yuchen Yang, Jiedong Zhuang, Haoji Hu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.18420">TeG-DG: Textually Guided Domain Generalization for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Enhancing the domain generalization performance of Face Anti-Spoofing (FAS) techniques has emerged as a research focus. Existing methods are dedicated to extracting domain-invariant features from various training domains. Despite the promising performance, the extracted features inevitably contain residual style feature bias (e.g., illumination, capture device), resulting in inferior generalization performance. In this paper, we propose an alternative and effective solution, the Textually Guided Domain Generalization (TeG-DG) framework, which can effectively leverage text information for cross-domain alignment. Our core insight is that text, as a more abstract and universal form of expression, can capture the commonalities and essential characteristics across various attacks, bridging the gap between different image domains. Contrary to existing vision-language models, the proposed framework is elaborately designed to enhance the domain generalization ability of the FAS task. Concretely, we first design a Hierarchical Attention Fusion (HAF) module to enable adaptive aggregation of visual features at different levels; Then, a Textual-Enhanced Visual Discriminator (TEVD) is proposed for not only better alignment between the two modalities but also to regularize the classifier with unbiased text features. TeG-DG significantly outperforms previous approaches, especially in situations with extremely limited source domain data (~14% and ~12% improvements on HTER and AUC respectively), showcasing impressive few-shot performance.
<div id='section'>Paperid: <span id='pid'>173, <a href='https://arxiv.org/pdf/2305.12800.pdf' target='_blank'>https://arxiv.org/pdf/2305.12800.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yachun Li, Jingjing Wang, Yuhui Chen, Di Xie, Shiliang Pu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.12800">Single Domain Dynamic Generalization for Iris Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Iris presentation attack detection (PAD) has achieved great success under intra-domain settings but easily degrades on unseen domains. Conventional domain generalization methods mitigate the gap by learning domain-invariant features. However, they ignore the discriminative information in the domain-specific features. Moreover, we usually face a more realistic scenario with only one single domain available for training. To tackle the above issues, we propose a Single Domain Dynamic Generalization (SDDG) framework, which simultaneously exploits domain-invariant and domain-specific features on a per-sample basis and learns to generalize to various unseen domains with numerous natural images. Specifically, a dynamic block is designed to adaptively adjust the network with a dynamic adaptor. And an information maximization loss is further combined to increase diversity. The whole network is integrated into the meta-learning paradigm. We generate amplitude perturbed images and cover diverse domains with natural images. Therefore, the network can learn to generalize to the perturbed domains in the meta-test phase. Extensive experiments show the proposed method is effective and outperforms the state-of-the-art on LivDet-Iris 2017 dataset.
<div id='section'>Paperid: <span id='pid'>174, <a href='https://arxiv.org/pdf/2304.13015.pdf' target='_blank'>https://arxiv.org/pdf/2304.13015.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Diego Pasmino, Carlos Aravena, Juan Tapia, Christoph Busch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.13015">Flickr-PAD: New Face High-Resolution Presentation Attack Detection Database</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Nowadays, Presentation Attack Detection is a very active research area. Several databases are constituted in the state-of-the-art using images extracted from videos. One of the main problems identified is that many databases present a low-quality, small image size and do not represent an operational scenario in a real remote biometric system. Currently, these images are captured from smartphones with high-quality and bigger resolutions. In order to increase the diversity of image quality, this work presents a new PAD database based on open-access Flickr images called: "Flickr-PAD". Our new hand-made database shows high-quality printed and screen scenarios. This will help researchers to compare new approaches to existing algorithms on a wider database. This database will be available for other researchers. A leave-one-out protocol was used to train and evaluate three PAD models based on MobileNet-V3 (small and large) and EfficientNet-B0. The best result was reached with MobileNet-V3 large with BPCER10 of 7.08% and BPCER20 of 11.15%.
<div id='section'>Paperid: <span id='pid'>175, <a href='https://arxiv.org/pdf/2303.06452.pdf' target='_blank'>https://arxiv.org/pdf/2303.06452.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jeremy Speth, Nathan Vance, Benjamin Sporrer, Lu Niu, Patrick Flynn, Adam Czajka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.06452">Hallucinated Heartbeats: Anomaly-Aware Remote Pulse Estimation</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Camera-based physiological monitoring, especially remote photoplethysmography (rPPG), is a promising tool for health diagnostics, and state-of-the-art pulse estimators have shown impressive performance on benchmark datasets. We argue that evaluations of modern solutions may be incomplete, as we uncover failure cases for videos without a live person, or in the presence of severe noise. We demonstrate that spatiotemporal deep learning models trained only with live samples "hallucinate" a genuine-shaped pulse on anomalous and noisy videos, which may have negative consequences when rPPG models are used by medical personnel. To address this, we offer: (a) An anomaly detection model, built on top of the predicted waveforms. We compare models trained in open-set (unknown abnormal predictions) and closed-set (abnormal predictions known when training) settings; (b) An anomaly-aware training regime that penalizes the model for predicting periodic signals from anomalous videos. Extensive experimentation with eight research datasets (rPPG-specific: DDPM, CDDPM, PURE, UBFC, ARPM; deep fakes: DFDC; face presentation attack detection: HKBU-MARs; rPPG outlier: KITTI) show better accuracy of anomaly detection for deep learning models incorporating the proposed training (75.8%), compared to models trained regularly (73.7%) and to hand-crafted rPPG methods (52-62%).
<div id='section'>Paperid: <span id='pid'>176, <a href='https://arxiv.org/pdf/2203.16263.pdf' target='_blank'>https://arxiv.org/pdf/2203.16263.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicolas M. MÃ¼ller, Pavel Czempin, Franziska Dieckmann, Adam Froghyar, Konstantin BÃ¶ttinger
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.16263">Does Audio Deepfake Detection Generalize?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current text-to-speech algorithms produce realistic fakes of human voices, making deepfake detection a much-needed area of research. While researchers have presented various techniques for detecting audio spoofs, it is often unclear exactly why these architectures are successful: Preprocessing steps, hyperparameter settings, and the degree of fine-tuning are not consistent across related work. Which factors contribute to success, and which are accidental? In this work, we address this problem: We systematize audio spoofing detection by re-implementing and uniformly evaluating architectures from related work. We identify overarching features for successful audio deepfake detection, such as using cqtspec or logspec features instead of melspec features, which improves performance by 37% EER on average, all other factors constant. Additionally, we evaluate generalization capabilities: We collect and publish a new dataset consisting of 37.9 hours of found audio recordings of celebrities and politicians, of which 17.2 hours are deepfakes. We find that related work performs poorly on such real-world data (performance degradation of up to one thousand percent). This may suggest that the community has tailored its solutions too closely to the prevailing ASVSpoof benchmark and that deepfakes are much harder to detect outside the lab than previously thought.
<div id='section'>Paperid: <span id='pid'>177, <a href='https://arxiv.org/pdf/2506.01783.pdf' target='_blank'>https://arxiv.org/pdf/2506.01783.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Honglu Zhang, Zhiqin Fang, Ningning Zhao, Saihui Hou, Long Ma, Renwang Pei, Zhaofeng He
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.01783">FaceCoT: A Benchmark Dataset for Face Anti-Spoofing with Chain-of-Thought Reasoning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face Anti-Spoofing (FAS) typically depends on a single visual modality when defending against presentation attacks such as print attacks, screen replays, and 3D masks, resulting in limited generalization across devices, environments, and attack types. Meanwhile, Multimodal Large Language Models (MLLMs) have recently achieved breakthroughs in image-text understanding and semantic reasoning, suggesting that integrating visual and linguistic co-inference into FAS can substantially improve both robustness and interpretability. However, the lack of a high-quality vision-language multimodal dataset has been a critical bottleneck. To address this, we introduce FaceCoT (Face Chain-of-Thought), the first large-scale Visual Question Answering (VQA) dataset tailored for FAS. FaceCoT covers 14 spoofing attack types and enriches model learning with high-quality CoT VQA annotations. Meanwhile, we develop a caption model refined via reinforcement learning to expand the dataset and enhance annotation quality. Furthermore, we introduce a CoT-Enhanced Progressive Learning (CEPL) strategy to better leverage the CoT data and boost model performance on FAS tasks. Extensive experiments demonstrate that models trained with FaceCoT and CEPL outperform state-of-the-art methods on multiple benchmark datasets.
<div id='section'>Paperid: <span id='pid'>178, <a href='https://arxiv.org/pdf/2503.22936.pdf' target='_blank'>https://arxiv.org/pdf/2503.22936.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pei-Kai Huanga, Jun-Xiong Chong, Ming-Tsung Hsu, Fang-Yu Hsu, Chiou-Ting Hsu
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.22936">Enhancing Learnable Descriptive Convolutional Vision Transformer for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing (FAS) heavily relies on identifying live/spoof discriminative features to counter face presentation attacks. Recently, we proposed LDCformer to successfully incorporate the Learnable Descriptive Convolution (LDC) into ViT, to model long-range dependency of locally descriptive features for FAS. In this paper, we propose three novel training strategies to effectively enhance the training of LDCformer to largely boost its feature characterization capability. The first strategy, dual-attention supervision, is developed to learn fine-grained liveness features guided by regional live/spoof attentions. The second strategy, self-challenging supervision, is designed to enhance the discriminability of the features by generating challenging training data. In addition, we propose a third training strategy, transitional triplet mining strategy, through narrowing the cross-domain gap while maintaining the transitional relationship between live and spoof features, to enlarge the domain-generalization capability of LDCformer. Extensive experiments show that LDCformer under joint supervision of the three novel training strategies outperforms previous methods.
<div id='section'>Paperid: <span id='pid'>179, <a href='https://arxiv.org/pdf/2502.03870.pdf' target='_blank'>https://arxiv.org/pdf/2502.03870.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tore Johansson, Marco Spanghero, Panos Papadimitratos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.03870">Consumer INS Coupled with Carrier Phase Measurements for GNSS Spoofing Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Global Navigation Satellite Systems enable precise localization and timing even for highly mobile devices, but legacy implementations provide only limited support for the new generation of security-enhanced signals. Inertial Measurement Units have proved successful in augmenting the accuracy and robustness of the GNSS-provided navigation solution, but effective navigation based on inertial techniques in denied contexts requires high-end sensors. However, commercially available mobile devices usually embed a much lower-grade inertial system. To counteract an attacker transmitting all the adversarial signals from a single antenna, we exploit carrier phase-based observations coupled with a low-end inertial sensor to identify spoofing and meaconing. By short-time integration with an inertial platform, which tracks the displacement of the GNSS antenna, the high-frequency movement at the receiver is correlated with the variation in the carrier phase. In this way, we identify legitimate transmitters, based on their geometrical diversity with respect to the antenna system movement. We introduce a platform designed to effectively compare different tiers of commercial INS platforms with a GNSS receiver. By characterizing different inertial sensors, we show that simple MEMS INS perform as well as high-end industrial-grade sensors. Sensors traditionally considered unsuited for navigation purposes offer great performance at the short integration times used to evaluate the carrier phase information consistency against the high-frequency movement. Results from laboratory evaluation and through field tests at Jammertest 2024 show that the detector is up to 90% accurate in correctly identifying spoofing (or the lack of it), without any modification to the receiver structure, and with mass-production grade INS typical for mobile phones.
<div id='section'>Paperid: <span id='pid'>180, <a href='https://arxiv.org/pdf/2409.15234.pdf' target='_blank'>https://arxiv.org/pdf/2409.15234.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Junyi Peng, Ladislav MoÅ¡ner, Lin Zhang, OldÅich Plchot, Themos Stafylakis, LukÃ¡Å¡ Burget, Jan ÄernockÃ½
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.15234">CA-MHFA: A Context-Aware Multi-Head Factorized Attentive Pooling for SSL-Based Speaker Verification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Self-supervised learning (SSL) models for speaker verification (SV) have gained significant attention in recent years. However, existing SSL-based SV systems often struggle to capture local temporal dependencies and generalize across different tasks. In this paper, we propose context-aware multi-head factorized attentive pooling (CA-MHFA), a lightweight framework that incorporates contextual information from surrounding frames. CA-MHFA leverages grouped, learnable queries to effectively model contextual dependencies while maintaining efficiency by sharing keys and values across groups. Experimental results on the VoxCeleb dataset show that CA-MHFA achieves EERs of 0.42\%, 0.48\%, and 0.96\% on Vox1-O, Vox1-E, and Vox1-H, respectively, outperforming complex models like WavLM-TDNN with fewer parameters and faster convergence. Additionally, CA-MHFA demonstrates strong generalization across multiple SSL models and tasks, including emotion recognition and anti-spoofing, highlighting its robustness and versatility.
<div id='section'>Paperid: <span id='pid'>181, <a href='https://arxiv.org/pdf/2309.16954.pdf' target='_blank'>https://arxiv.org/pdf/2309.16954.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxiang Zhang, Zhuo Li, Jingze Lu, Wenchao Wang, Pengyuan Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.16954">Synthetic Speech Detection Based on Temporal Consistency and Distribution of Speaker Features</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current synthetic speech detection (SSD) methods perform well on certain datasets but still face issues of robustness and interpretability. A possible reason is that these methods do not analyze the deficiencies of synthetic speech. In this paper, the flaws of the speaker features inherent in the text-to-speech (TTS) process are analyzed. Differences in the temporal consistency of intra-utterance speaker features arise due to the lack of fine-grained control over speaker features in TTS. Since the speaker representations in TTS are based on speaker embeddings extracted by encoders, the distribution of inter-utterance speaker features differs between synthetic and bonafide speech. Based on these analyzes, an SSD method based on temporal consistency and distribution of speaker features is proposed. On one hand, modeling the temporal consistency of intra-utterance speaker features can aid speech anti-spoofing. On the other hand, distribution differences in inter-utterance speaker features can be utilized for SSD. The proposed method offers low computational complexity and performs well in both cross-dataset and silence trimming scenarios.
<div id='section'>Paperid: <span id='pid'>182, <a href='https://arxiv.org/pdf/2301.12766.pdf' target='_blank'>https://arxiv.org/pdf/2301.12766.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pavlo Mykytyn, Marcin Brzozowski, Zoya Dyka, Peter Langendoerfer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.12766">GPS-Spoofing Attack Detection Mechanism for UAV Swarms</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recently autonomous and semi-autonomous Unmanned Aerial Vehicle (UAV) swarms started to receive a lot of research interest and demand from various civil application fields. However, for successful mission execution, UAV swarms require Global navigation satellite system signals and in particular, Global Positioning System (GPS) signals for navigation. Unfortunately, civil GPS signals are unencrypted and unauthenticated, which facilitates the execution of GPS spoofing attacks. During these attacks, adversaries mimic the authentic GPS signal and broadcast it to the targeted UAV in order to change its course, and force it to land or crash. In this study, we propose a GPS spoofing detection mechanism capable of detecting single-transmitter and multi-transmitter GPS spoofing attacks to prevent the outcomes mentioned above. Our detection mechanism is based on comparing the distance between each two swarm members calculated from their GPS coordinates to the distance acquired from Impulse Radio Ultra-Wideband ranging between the same swarm members. If the difference in distances is larger than a chosen threshold the GPS spoofing attack is declared detected.
<div id='section'>Paperid: <span id='pid'>183, <a href='https://arxiv.org/pdf/2506.12580.pdf' target='_blank'>https://arxiv.org/pdf/2506.12580.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenjie Liu, Panos Papadimitratos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.12580">GNSS Spoofing Detection Based on Opportunistic Position Information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The limited or no protection for civilian Global Navigation Satellite System (GNSS) signals makes spoofing attacks relatively easy. With modern mobile devices often featuring network interfaces, state-of-the-art signals of opportunity (SOP) schemes can provide accurate network positions in replacement of GNSS. The use of onboard inertial sensors can also assist in the absence of GNSS, possibly in the presence of jammers. The combination of SOP and inertial sensors has received limited attention, yet it shows strong results on fully custom-built platforms. We do not seek to improve such special-purpose schemes. Rather, we focus on countering GNSS attacks, notably detecting them, with emphasis on deployment with consumer-grade platforms, notably smartphones, that provide off-the-shelf opportunistic information (i.e., network position and inertial sensor data). Our Position-based Attack Detection Scheme (PADS) is a probabilistic framework that uses regression and uncertainty analysis for positions. The regression optimization problem is a weighted mean square error of polynomial fitting, with constraints that the fitted positions satisfy the device velocity and acceleration. Then, uncertainty is modeled by a Gaussian process, which provides more flexibility to analyze how sure or unsure we are about position estimations. In the detection process, we combine all uncertainty information with the position estimations into a fused test statistic, which is the input utilized by an anomaly detector based on outlier ensembles. The evaluation shows that the PADS outperforms a set of baseline methods that rely on SOP or inertial sensor-based or statistical tests, achieving up to 3 times the true positive rate at a low false positive rate.
<div id='section'>Paperid: <span id='pid'>184, <a href='https://arxiv.org/pdf/2505.24214.pdf' target='_blank'>https://arxiv.org/pdf/2505.24214.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Redwan Sony, Parisa Farmanifard, Hamzeh Alzwairy, Nitish Shukla, Arun Ross
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.24214">Benchmarking Foundation Models for Zero-Shot Biometric Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The advent of foundation models, particularly Vision-Language Models (VLMs) and Multi-modal Large Language Models (MLLMs), has redefined the frontiers of artificial intelligence, enabling remarkable generalization across diverse tasks with minimal or no supervision. Yet, their potential in biometric recognition and analysis remains relatively underexplored. In this work, we introduce a comprehensive benchmark that evaluates the zero-shot and few-shot performance of state-of-the-art publicly available VLMs and MLLMs across six biometric tasks spanning the face and iris modalities: face verification, soft biometric attribute prediction (gender and race), iris recognition, presentation attack detection (PAD), and face manipulation detection (morphs and deepfakes). A total of 41 VLMs were used in this evaluation. Experiments show that embeddings from these foundation models can be used for diverse biometric tasks with varying degrees of success. For example, in the case of face verification, a True Match Rate (TMR) of 96.77 percent was obtained at a False Match Rate (FMR) of 1 percent on the Labeled Face in the Wild (LFW) dataset, without any fine-tuning. In the case of iris recognition, the TMR at 1 percent FMR on the IITD-R-Full dataset was 97.55 percent without any fine-tuning. Further, we show that applying a simple classifier head to these embeddings can help perform DeepFake detection for faces, Presentation Attack Detection (PAD) for irides, and extract soft biometric attributes like gender and ethnicity from faces with reasonably high accuracy. This work reiterates the potential of pretrained models in achieving the long-term vision of Artificial General Intelligence.
<div id='section'>Paperid: <span id='pid'>185, <a href='https://arxiv.org/pdf/2505.06171.pdf' target='_blank'>https://arxiv.org/pdf/2505.06171.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenjie Liu, Panos Papadimitratos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.06171">Self-Supervised Federated GNSS Spoofing Detection with Opportunistic Data</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Global navigation satellite systems (GNSS) are vulnerable to spoofing attacks, with adversarial signals manipulating the location or time information of receivers, potentially causing severe disruptions. The task of discerning the spoofing signals from benign ones is naturally relevant for machine learning, thus recent interest in applying it for detection. While deep learning-based methods are promising, they require extensive labeled datasets, consume significant computational resources, and raise privacy concerns due to the sensitive nature of position data. This is why this paper proposes a self-supervised federated learning framework for GNSS spoofing detection. It consists of a cloud server and local mobile platforms. Each mobile platform employs a self-supervised anomaly detector using long short-term memory (LSTM) networks. Labels for training are generated locally through a spoofing-deviation prediction algorithm, ensuring privacy. Local models are trained independently, and only their parameters are uploaded to the cloud server, which aggregates them into a global model using FedAvg. The updated global model is then distributed back to the mobile platforms and trained iteratively. The evaluation shows that our self-supervised federated learning framework outperforms position-based and deep learning-based methods in detecting spoofing attacks while preserving data privacy.
<div id='section'>Paperid: <span id='pid'>186, <a href='https://arxiv.org/pdf/2505.02176.pdf' target='_blank'>https://arxiv.org/pdf/2505.02176.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Samuel Webster, Adam Czajka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.02176">Saliency-Guided Training for Fingerprint Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Saliency-guided training, which directs model learning to important regions of images, has demonstrated generalization improvements across various biometric presentation attack detection (PAD) tasks. This paper presents its first application to fingerprint PAD. We conducted a 50-participant study to create a dataset of 800 human-annotated fingerprint perceptually-important maps, explored alongside algorithmically-generated "pseudosaliency," including minutiae-based, image quality-based, and autoencoder-based saliency maps. Evaluating on the 2021 Fingerprint Liveness Detection Competition testing set, we explore various configurations within five distinct training scenarios to assess the impact of saliency-guided training on accuracy and generalization. Our findings demonstrate the effectiveness of saliency-guided training for fingerprint PAD in both limited and large data contexts, and we present a configuration capable of earning the first place on the LivDet-2021 benchmark. Our results highlight saliency-guided training's promise for increased model generalization capabilities, its effectiveness when data is limited, and its potential to scale to larger datasets in fingerprint PAD. All collected saliency data and trained models are released with the paper to support reproducible research.
<div id='section'>Paperid: <span id='pid'>187, <a href='https://arxiv.org/pdf/2409.06842.pdf' target='_blank'>https://arxiv.org/pdf/2409.06842.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Alvaro S. Rocamora, Juan M. Espin, Juan E. Tapia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.06842">Few-Shot Learning: Expanding ID Cards Presentation Attack Detection to Unknown ID Countries</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a Few-shot Learning (FSL) approach for detecting Presentation Attacks on ID Cards deployed in a remote verification system and its extension to new countries. Our research analyses the performance of Prototypical Networks across documents from Spain and Chile as a baseline and measures the extension of generalisation capabilities of new ID Card countries such as Argentina and Costa Rica. Specifically targeting the challenge of screen display presentation attacks. By leveraging convolutional architectures and meta-learning principles embodied in Prototypical Networks, we have crafted a model that demonstrates high efficacy with Few-shot examples. This research reveals that competitive performance can be achieved with as Few-shots as five unique identities and with under 100 images per new country added. This opens a new insight for novel generalised Presentation Attack Detection on ID cards to unknown attacks.
<div id='section'>Paperid: <span id='pid'>188, <a href='https://arxiv.org/pdf/2405.00650.pdf' target='_blank'>https://arxiv.org/pdf/2405.00650.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Colton R. Crum, Samuel Webster, Adam Czajka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2405.00650">Grains of Saliency: Optimizing Saliency-based Training of Biometric Attack Detection Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Incorporating human-perceptual intelligence into model training has shown to increase the generalization capability of models in several difficult biometric tasks, such as presentation attack detection (PAD) and detection of synthetic samples. After the initial collection phase, human visual saliency (e.g., eye-tracking data, or handwritten annotations) can be integrated into model training through attention mechanisms, augmented training samples, or through human perception-related components of loss functions. Despite their successes, a vital, but seemingly neglected, aspect of any saliency-based training is the level of salience granularity (e.g., bounding boxes, single saliency maps, or saliency aggregated from multiple subjects) necessary to find a balance between reaping the full benefits of human saliency and the cost of its collection. In this paper, we explore several different levels of salience granularity and demonstrate that increased generalization capabilities of PAD and synthetic face detection can be achieved by using simple yet effective saliency post-processing techniques across several different CNNs.
<div id='section'>Paperid: <span id='pid'>189, <a href='https://arxiv.org/pdf/2402.03449.pdf' target='_blank'>https://arxiv.org/pdf/2402.03449.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenjie Liu, Panos Papadimitratos
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.03449">Extending RAIM with a Gaussian Mixture of Opportunistic Information</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>GNSS are indispensable for various applications, but they are vulnerable to spoofing attacks. The original receiver autonomous integrity monitoring (RAIM) was not designed for securing GNSS. In this context, RAIM was extended with wireless signals, termed signals of opportunity (SOPs), or onboard sensors, typically assumed benign. However, attackers might also manipulate wireless networks, raising the need for a solution that considers untrustworthy SOPs. To address this, we extend RAIM by incorporating all opportunistic information, i.e., measurements from terrestrial infrastructures and onboard sensors, culminating in one function for robust GNSS spoofing detection. The objective is to assess the likelihood of GNSS spoofing by analyzing locations derived from extended RAIM solutions, which include location solutions from GNSS pseudorange subsets and wireless signal subsets of untrusted networks. Our method comprises two pivotal components: subset generation and location fusion. Subsets of ranging information are created and processed through positioning algorithms, producing temporary locations. Onboard sensors provide speed, acceleration, and attitude data, aiding in location filtering based on motion constraints. The filtered locations, modeled with uncertainty, are fused into a composite likelihood function normalized for GNSS spoofing detection. Theoretical assessments of GNSS-only and multi-infrastructure scenarios under uncoordinated and coordinated attacks are conducted. The detection of these attacks is feasible when the number of benign subsets exceeds a specific threshold. A real-world dataset from the Kista area is used for experimental validation. Comparative analysis against baseline methods shows a significant improvement in detection accuracy achieved by our Gaussian Mixture RAIM approach. Moreover, we discuss leveraging RAIM results for plausible location recovery.
<div id='section'>Paperid: <span id='pid'>190, <a href='https://arxiv.org/pdf/2312.13993.pdf' target='_blank'>https://arxiv.org/pdf/2312.13993.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Reuben Markham, Juan M. Espin, Mario Nieto-Hidalgo, Juan E. Tapia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.13993">Open-Set: ID Card Presentation Attack Detection using Neural Transfer Style</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The accurate detection of ID card Presentation Attacks (PA) is becoming increasingly important due to the rising number of online/remote services that require the presentation of digital photographs of ID cards for digital onboarding or authentication. Furthermore, cybercriminals are continuously searching for innovative ways to fool authentication systems to gain unauthorized access to these services. Although advances in neural network design and training have pushed image classification to the state of the art, one of the main challenges faced by the development of fraud detection systems is the curation of representative datasets for training and evaluation. The handcrafted creation of representative presentation attack samples often requires expertise and is very time-consuming, thus an automatic process of obtaining high-quality data is highly desirable. This work explores ID card Presentation Attack Instruments (PAI) in order to improve the generation of samples with four Generative Adversarial Networks (GANs) based image translation models and analyses the effectiveness of the generated data for training fraud detection systems. Using open-source data, we show that synthetic attack presentations are an adequate complement for additional real attack presentations, where we obtain an EER performance increase of 0.63% points for print attacks and a loss of 0.29% for screen capture attacks.
<div id='section'>Paperid: <span id='pid'>191, <a href='https://arxiv.org/pdf/2305.07602.pdf' target='_blank'>https://arxiv.org/pdf/2305.07602.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Steven A. Grosz, Kanishka P. Wijewardena, Anil K. Jain
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.07602">ViT Unified: Joint Fingerprint Recognition and Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A secure fingerprint recognition system must contain both a presentation attack (i.e., spoof) detection and recognition module in order to protect users against unwanted access by malicious users. Traditionally, these tasks would be carried out by two independent systems; however, recent studies have demonstrated the potential to have one unified system architecture in order to reduce the computational burdens on the system, while maintaining high accuracy. In this work, we leverage a vision transformer architecture for joint spoof detection and matching and report competitive results with state-of-the-art (SOTA) models for both a sequential system (two ViT models operating independently) and a unified architecture (a single ViT model for both tasks). ViT models are particularly well suited for this task as the ViT's global embedding encodes features useful for recognition, whereas the individual, local embeddings are useful for spoof detection. We demonstrate the capability of our unified model to achieve an average integrated matching (IM) accuracy of 98.87% across LivDet 2013 and 2015 CrossMatch sensors. This is comparable to IM accuracy of 98.95% of our sequential dual-ViT system, but with ~50% of the parameters and ~58% of the latency.
<div id='section'>Paperid: <span id='pid'>192, <a href='https://arxiv.org/pdf/2304.07549.pdf' target='_blank'>https://arxiv.org/pdf/2304.07549.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ajian Liu, Yanyan Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.07549">MA-ViT: Modality-Agnostic Vision Transformers for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The existing multi-modal face anti-spoofing (FAS) frameworks are designed based on two strategies: halfway and late fusion. However, the former requires test modalities consistent with the training input, which seriously limits its deployment scenarios. And the latter is built on multiple branches to process different modalities independently, which limits their use in applications with low memory or fast execution requirements. In this work, we present a single branch based Transformer framework, namely Modality-Agnostic Vision Transformer (MA-ViT), which aims to improve the performance of arbitrary modal attacks with the help of multi-modal data. Specifically, MA-ViT adopts the early fusion to aggregate all the available training modalities data and enables flexible testing of any given modal samples. Further, we develop the Modality-Agnostic Transformer Block (MATB) in MA-ViT, which consists of two stacked attentions named Modal-Disentangle Attention (MDA) and Cross-Modal Attention (CMA), to eliminate modality-related information for each modal sequences and supplement modality-agnostic liveness features from another modal sequences, respectively. Experiments demonstrate that the single model trained based on MA-ViT can not only flexibly evaluate different modal samples, but also outperforms existing single-modal frameworks by a large margin, and approaches the multi-modal frameworks introduced with smaller FLOPs and model parameters.
<div id='section'>Paperid: <span id='pid'>193, <a href='https://arxiv.org/pdf/2303.11034.pdf' target='_blank'>https://arxiv.org/pdf/2303.11034.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Haohao Sun, Yilong Zhang, Peng Chen, Haixia Wang, Ronghua Liang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.11034">Internal Structure Attention Network for Fingerprint Presentation Attack Detection from Optical Coherence Tomography</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As a non-invasive optical imaging technique, optical coherence tomography (OCT) has proven promising for automatic fingerprint recognition system (AFRS) applications. Diverse approaches have been proposed for OCT-based fingerprint presentation attack detection (PAD). However, considering the complexity and variety of PA samples, it is extremely challenging to increase the generalization ability with the limited PA dataset. To solve the challenge, this paper presents a novel supervised learning-based PAD method, denoted as ISAPAD, which applies prior knowledge to guide network training and enhance the generalization ability. The proposed dual-branch architecture can not only learns global features from the OCT image, but also concentrate on layered structure feature which comes from the internal structure attention module (ISAM). The simple yet effective ISAM enables the proposed network to obtain layered segmentation features belonging only to Bonafide from noisy OCT volume data directly. Combined with effective training strategies and PAD score generation rules, ISAPAD obtains optimal PAD performance in limited training data. Domain generalization experiments and visualization analysis validate the effectiveness of the proposed method for OCT PAD.
<div id='section'>Paperid: <span id='pid'>194, <a href='https://arxiv.org/pdf/2507.17000.pdf' target='_blank'>https://arxiv.org/pdf/2507.17000.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jacob Piland, Chris Sweet, Adam Czajka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.17000">Divisive Decisions: Improving Salience-Based Training for Generalization in Binary Classification Tasks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Existing saliency-guided training approaches improve model generalization by incorporating a loss term that compares the model's class activation map (CAM) for a sample's true-class ({\it i.e.}, correct-label class) against a human reference saliency map. However, prior work has ignored the false-class CAM(s), that is the model's saliency obtained for incorrect-label class. We hypothesize that in binary tasks the true and false CAMs should diverge on the important classification features identified by humans (and reflected in human saliency maps). We use this hypothesis to motivate three new saliency-guided training methods incorporating both true- and false-class model's CAM into the training strategy and a novel post-hoc tool for identifying important features. We evaluate all introduced methods on several diverse binary close-set and open-set classification tasks, including synthetic face detection, biometric presentation attack detection, and classification of anomalies in chest X-ray scans, and find that the proposed methods improve generalization capabilities of deep learning models over traditional (true-class CAM only) saliency-guided training approaches. We offer source codes and model weights\footnote{GitHub repository link removed to preserve anonymity} to support reproducible research.
<div id='section'>Paperid: <span id='pid'>195, <a href='https://arxiv.org/pdf/2504.01213.pdf' target='_blank'>https://arxiv.org/pdf/2504.01213.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Banafsheh Adami, Nima Karimian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.01213">GRU-AUNet: A Domain Adaptation Framework for Contactless Fingerprint Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although contactless fingerprints offer user comfort, they are more vulnerable to spoofing. The current solution for anti-spoofing in the area of contactless fingerprints relies on domain adaptation learning, limiting their generalization and scalability. To address these limitations, we introduce GRU-AUNet, a domain adaptation approach that integrates a Swin Transformer-based UNet architecture with GRU-enhanced attention mechanisms, a Dynamic Filter Network in the bottleneck, and a combined Focal and Contrastive Loss function. Trained in both genuine and spoof fingerprint images, GRU-AUNet demonstrates robust resilience against presentation attacks, achieving an average BPCER of 0.09\% and APCER of 1.2\% in the CLARKSON, COLFISPOOF, and IIITD datasets, outperforming state-of-the-art domain adaptation methods.
<div id='section'>Paperid: <span id='pid'>196, <a href='https://arxiv.org/pdf/2409.11027.pdf' target='_blank'>https://arxiv.org/pdf/2409.11027.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Manasi Chhibber, Jagabandhu Mishra, Hyejin Shim, Tomi H. Kinnunen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.11027">An Explainable Probabilistic Attribute Embedding Approach for Spoofed Speech Characterization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We propose a novel approach for spoofed speech characterization through explainable probabilistic attribute embeddings. In contrast to high-dimensional raw embeddings extracted from a spoofing countermeasure (CM) whose dimensions are not easy to interpret, the probabilistic attributes are designed to gauge the presence or absence of sub-components that make up a specific spoofing attack. These attributes are then applied to two downstream tasks: spoofing detection and attack attribution. To enforce interpretability also to the back-end, we adopt a decision tree classifier. Our experiments on the ASVspoof2019 dataset with spoof CM embeddings extracted from three models (AASIST, Rawboost-AASIST, SSL-AASIST) suggest that the performance of the attribute embeddings are on par with the original raw spoof CM embeddings for both tasks. The best performance achieved with the proposed approach for spoofing detection and attack attribution, in terms of accuracy, is 99.7% and 99.2%, respectively, compared to 99.7% and 94.7% using the raw CM embeddings. To analyze the relative contribution of each attribute, we estimate their Shapley values. Attributes related to acoustic feature prediction, waveform generation (vocoder), and speaker modeling are found important for spoofing detection; while duration modeling, vocoder, and input type play a role in spoofing attack attribution.
<div id='section'>Paperid: <span id='pid'>197, <a href='https://arxiv.org/pdf/2408.02750.pdf' target='_blank'>https://arxiv.org/pdf/2408.02750.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahsa Mitcheff, Patrick Tinsley, Adam Czajka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.02750">Privacy-Safe Iris Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper proposes a framework for a privacy-safe iris presentation attack detection (PAD) method, designed solely with synthetically-generated, identity-leakage-free iris images. Once trained, the method is evaluated in a classical way using state-of-the-art iris PAD benchmarks. We designed two generative models for the synthesis of ISO/IEC 19794-6-compliant iris images. The first model synthesizes bona fide-looking samples. To avoid ``identity leakage,'' the generated samples that accidentally matched those used in the model's training were excluded. The second model synthesizes images of irises with textured contact lenses and is conditioned by a given contact lens brand to have better control over textured contact lens appearance when forming the training set. Our experiments demonstrate that models trained solely on synthetic data achieve a lower but still reasonable performance when compared to solutions trained with iris images collected from human subjects. This is the first-of-its-kind attempt to use solely synthetic data to train a fully-functional iris PAD solution, and despite the performance gap between regular and the proposed methods, this study demonstrates that with the increasing fidelity of generative models, creating such privacy-safe iris PAD methods may be possible. The source codes and generative models trained for this work are offered along with the paper.
<div id='section'>Paperid: <span id='pid'>198, <a href='https://arxiv.org/pdf/2407.08016.pdf' target='_blank'>https://arxiv.org/pdf/2407.08016.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Nicholas Klein, Tianxiang Chen, Hemlata Tak, Ricardo Casal, Elie Khoury
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.08016">Source Tracing of Audio Deepfake Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent progress in generative AI technology has made audio deepfakes remarkably more realistic. While current research on anti-spoofing systems primarily focuses on assessing whether a given audio sample is fake or genuine, there has been limited attention on discerning the specific techniques to create the audio deepfakes. Algorithms commonly used in audio deepfake generation, like text-to-speech (TTS) and voice conversion (VC), undergo distinct stages including input processing, acoustic modeling, and waveform generation. In this work, we introduce a system designed to classify various spoofing attributes, capturing the distinctive features of individual modules throughout the entire generation pipeline. We evaluate our system on two datasets: the ASVspoof 2019 Logical Access and the Multi-Language Audio Anti-Spoofing Dataset (MLAAD). Results from both experiments demonstrate the robustness of the system to identify the different spoofing attributes of deepfake generation systems.
<div id='section'>Paperid: <span id='pid'>199, <a href='https://arxiv.org/pdf/2311.04148.pdf' target='_blank'>https://arxiv.org/pdf/2311.04148.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Banafsheh Adami, Nima Karimian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.04148">Contactless Fingerprint Biometric Anti-Spoofing: An Unsupervised Deep Learning Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Contactless fingerprint recognition offers a higher level of user comfort and addresses hygiene concerns more effectively. However, it is also more vulnerable to presentation attacks such as photo paper, paper-printout, and various display attacks, which makes it more challenging to implement in biometric systems compared to contact-based modalities. Limited research has been conducted on presentation attacks in contactless fingerprint systems, and these studies have encountered challenges in terms of generalization and scalability since both bonafide samples and presentation attacks are utilized during training model. Although this approach appears promising, it lacks the ability to handle unseen attacks, which is a crucial factor for developing PAD methods that can generalize effectively. We introduced an innovative anti-spoofing approach that combines an unsupervised autoencoder with a convolutional block attention module to address the limitations of existing methods. Our model is exclusively trained on bonafide images without exposure to any spoofed samples during the training phase. It is then evaluated against various types of presentation attack images in the testing phase. The scheme we proposed has achieved an average BPCER of 0.96\% with an APCER of 1.6\% for presentation attacks involving various types of spoofed samples.
<div id='section'>Paperid: <span id='pid'>200, <a href='https://arxiv.org/pdf/2310.15044.pdf' target='_blank'>https://arxiv.org/pdf/2310.15044.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Banafsheh Adami, Sara Tehranipoor, Nasser Nasrabadi, Nima Karimian
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.15044">A Universal Anti-Spoofing Approach for Contactless Fingerprint Biometric Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>With the increasing integration of smartphones into our daily lives, fingerphotos are becoming a potential contactless authentication method. While it offers convenience, it is also more vulnerable to spoofing using various presentation attack instruments (PAI). The contactless fingerprint is an emerging biometric authentication but has not yet been heavily investigated for anti-spoofing. While existing anti-spoofing approaches demonstrated fair results, they have encountered challenges in terms of universality and scalability to detect any unseen/unknown spoofed samples. To address this issue, we propose a universal presentation attack detection method for contactless fingerprints, despite having limited knowledge of presentation attack samples. We generated synthetic contactless fingerprints using StyleGAN from live finger photos and integrating them to train a semi-supervised ResNet-18 model. A novel joint loss function, combining the Arcface and Center loss, is introduced with a regularization to balance between the two loss functions and minimize the variations within the live samples while enhancing the inter-class variations between the deepfake and live samples. We also conducted a comprehensive comparison of different regularizations' impact on the joint loss function for presentation attack detection (PAD) and explored the performance of a modified ResNet-18 architecture with different activation functions (i.e., leaky ReLU and RelU) in conjunction with Arcface and center loss. Finally, we evaluate the performance of the model using unseen types of spoof attacks and live data. Our proposed method achieves a Bona Fide Classification Error Rate (BPCER) of 0.12\%, an Attack Presentation Classification Error Rate (APCER) of 0.63\%, and an Average Classification Error Rate (ACER) of 0.37\%.
<div id='section'>Paperid: <span id='pid'>201, <a href='https://arxiv.org/pdf/2304.06723.pdf' target='_blank'>https://arxiv.org/pdf/2304.06723.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Javier Galbally, Julian Fierrez, Raffaele Cappelli, Gian Luca Marcialis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.06723">Introduction to Presentation Attack Detection in Fingerprint Biometrics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This chapter provides an introduction to Presentation Attack Detection (PAD) in fingerprint biometrics, also coined anti-spoofing, describes early developments in this field, and briefly summarizes recent trends and open issues.
<div id='section'>Paperid: <span id='pid'>202, <a href='https://arxiv.org/pdf/2302.07287.pdf' target='_blank'>https://arxiv.org/pdf/2302.07287.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Enze Liu, Gautam Akiwate, Mattijs Jonker, Ariana Mirian, Grant Ho, Geoffrey M. Voelker, Stefan Savage
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.07287">Forward Pass: On the Security Implications of Email Forwarding Mechanism and Policy</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The critical role played by email has led to a range of extension protocols (e.g., SPF, DKIM, DMARC) designed to protect against the spoofing of email sender domains. These protocols are complex as is, but are further complicated by automated email forwarding -- used by individual users to manage multiple accounts and by mailing lists to redistribute messages. In this paper, we explore how such email forwarding and its implementations can break the implicit assumptions in widely deployed anti-spoofing protocols. Using large-scale empirical measurements of 20 email forwarding services (16 leading email providers and four popular mailing list services), we identify a range of security issues rooted in forwarding behavior and show how they can be combined to reliably evade existing anti-spoofing controls. We further show how these issues allow attackers to not only deliver spoofed email messages to prominent email providers (e.g., Gmail, Microsoft Outlook, and Zoho), but also reliably spoof email on behalf of tens of thousands of popular domains including sensitive domains used by organizations in government (e.g., state.gov), finance (e.g., transunion.com), law (e.g., perkinscoie.com) and news (e.g., washingtonpost.com) among others.
<div id='section'>Paperid: <span id='pid'>203, <a href='https://arxiv.org/pdf/1910.09642.pdf' target='_blank'>https://arxiv.org/pdf/1910.09642.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rafael Henrique Vareto, Araceli Marcia Sandanha, William Robson Schwartz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/1910.09642">The SWAX Benchmark: Attacking Biometric Systems with Wax Figures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>A face spoofing attack occurs when an intruder attempts to impersonate someone who carries a gainful authentication clearance. It is a trending topic due to the increasing demand for biometric authentication on mobile devices, high-security areas, among others. This work introduces a new database named Sense Wax Attack dataset (SWAX), comprised of real human and wax figure images and videos that endorse the problem of face spoofing detection. The dataset consists of more than 1800 face images and 110 videos of 55 people/waxworks, arranged in training, validation and test sets with a large range in expression, illumination and pose variations. Experiments performed with baseline methods show that despite the progress in recent years, advanced spoofing methods are still vulnerable to high-quality violation attempts.
<div id='section'>Paperid: <span id='pid'>204, <a href='https://arxiv.org/pdf/2510.19695.pdf' target='_blank'>https://arxiv.org/pdf/2510.19695.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rashik Shadman, M G Sarwar Murshed, Faraz Hussain
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.19695">Explainable Face Presentation Attack Detection via Ensemble-CAM</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Presentation attacks represent a critical security threat where adversaries use fake biometric data, such as face, fingerprint, or iris images, to gain unauthorized access to protected systems. Various presentation attack detection (PAD) systems have been designed leveraging deep learning (DL) models to mitigate this type of threat. Despite their effectiveness, most of the DL models function as black boxes - their decisions are opaque to their users. The purpose of explainability techniques is to provide detailed information about the reason behind the behavior or decision of DL models. In particular, visual explanation is necessary to better understand the decisions or predictions of DL-based PAD systems and determine the key regions due to which a biometric image is considered real or fake by the system. In this work, a novel technique, Ensemble-CAM, is proposed for providing visual explanations for the decisions made by deep learning-based face PAD systems. Our goal is to improve DL-based face PAD systems by providing a better understanding of their behavior. Our provided visual explanations will enhance the transparency and trustworthiness of DL-based face PAD systems.
<div id='section'>Paperid: <span id='pid'>205, <a href='https://arxiv.org/pdf/2510.14314.pdf' target='_blank'>https://arxiv.org/pdf/2510.14314.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Shivangi Yadav, Arun Ross
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.14314">A Multi-domain Image Translative Diffusion StyleGAN for Iris Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An iris biometric system can be compromised by presentation attacks (PAs) where artifacts such as artificial eyes, printed eye images, or cosmetic contact lenses are presented to the system. To counteract this, several presentation attack detection (PAD) methods have been developed. However, there is a scarcity of datasets for training and evaluating iris PAD techniques due to the implicit difficulties in constructing and imaging PAs. To address this, we introduce the Multi-domain Image Translative Diffusion StyleGAN (MID-StyleGAN), a new framework for generating synthetic ocular images that captures the PA and bonafide characteristics in multiple domains such as bonafide, printed eyes and cosmetic contact lens. MID-StyleGAN combines the strengths of diffusion models and generative adversarial networks (GANs) to produce realistic and diverse synthetic data. Our approach utilizes a multi-domain architecture that enables the translation between bonafide ocular images and different PA domains. The model employs an adaptive loss function tailored for ocular data to maintain domain consistency. Extensive experiments demonstrate that MID-StyleGAN outperforms existing methods in generating high-quality synthetic ocular images. The generated data was used to significantly enhance the performance of PAD systems, providing a scalable solution to the data scarcity problem in iris and ocular biometrics. For example, on the LivDet2020 dataset, the true detect rate at 1% false detect rate improved from 93.41% to 98.72%, showcasing the impact of the proposed method.
<div id='section'>Paperid: <span id='pid'>206, <a href='https://arxiv.org/pdf/2509.14959.pdf' target='_blank'>https://arxiv.org/pdf/2509.14959.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anton Selitskiy, Akib Shahriyar, Jishnuraj Prakasan
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.14959">Discrete optimal transport is a strong audio adversarial attack</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we show that discrete optimal transport (DOT) is an effective black-box adversarial attack against modern audio anti-spoofing countermeasures (CMs). Our attack operates as a post-processing, distribution-alignment step: frame-level WavLM embeddings of generated speech are aligned to an unpaired bona fide pool via entropic OT and a top-$k$ barycentric projection, then decoded with a neural vocoder. Evaluated on ASVspoof2019 and ASVspoof5 with AASIST baselines, DOT yields consistently high equal error rate (EER) across datasets and remains competitive after CM fine-tuning, outperforming several conventional attacks in cross-dataset transfer. Ablation analysis highlights the practical impact of vocoder overlap. Results indicate that distribution-level alignment is a powerful and stable attack surface for deployed CMs.
<div id='section'>Paperid: <span id='pid'>207, <a href='https://arxiv.org/pdf/2507.21087.pdf' target='_blank'>https://arxiv.org/pdf/2507.21087.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anas Ali, Mubashar Husain, Peter Hans
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.21087">Intelligent ARP Spoofing Detection using Multi-layered Machine Learning (ML) Techniques for IoT Networks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Address Resolution Protocol (ARP) spoofing remains a critical threat to IoT networks, enabling attackers to intercept, modify, or disrupt data transmission by exploiting ARP's lack of authentication. The decentralized and resource-constrained nature of IoT environments amplifies this vulnerability, making conventional detection mechanisms ineffective at scale. This paper introduces an intelligent, multi-layered machine learning framework designed to detect ARP spoofing in real-time IoT deployments. Our approach combines feature engineering based on ARP header behavior, traffic flow analysis, and temporal packet anomalies with a hybrid detection pipeline incorporating decision trees, ensemble models, and deep learning classifiers. We propose a hierarchical architecture to prioritize lightweight models at edge gateways and deeper models at centralized nodes to balance detection accuracy and computational efficiency. The system is validated on both simulated IoT traffic and the CICIDS2017 dataset, achieving over 97% detection accuracy with low false positive rates. Comparative evaluations with signature-based and rule-based systems demonstrate the robustness and generalizability of our approach. Our results show that intelligent machine learning integration enables proactive ARP spoofing detection tailored for IoT scenarios, laying the groundwork for scalable and autonomous network security solutions.
<div id='section'>Paperid: <span id='pid'>208, <a href='https://arxiv.org/pdf/2507.11173.pdf' target='_blank'>https://arxiv.org/pdf/2507.11173.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Deepak Kumar Panda, Weisi Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2507.11173">Real-Time Bayesian Detection of Drift-Evasive GNSS Spoofing in Reinforcement Learning Based UAV Deconfliction</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Autonomous unmanned aerial vehicles (UAVs) rely on global navigation satellite system (GNSS) pseudorange measurements for accurate real-time localization and navigation. However, this dependence exposes them to sophisticated spoofing threats, where adversaries manipulate pseudoranges to deceive UAV receivers. Among these, drift-evasive spoofing attacks subtly perturb measurements, gradually diverting the UAVs trajectory without triggering conventional signal-level anti-spoofing mechanisms. Traditional distributional shift detection techniques often require accumulating a threshold number of samples, causing delays that impede rapid detection and timely response. Consequently, robust temporal-scale detection methods are essential to identify attack onset and enable contingency planning with alternative sensing modalities, improving resilience against stealthy adversarial manipulations. This study explores a Bayesian online change point detection (BOCPD) approach that monitors temporal shifts in value estimates from a reinforcement learning (RL) critic network to detect subtle behavioural deviations in UAV navigation. Experimental results show that this temporal value-based framework outperforms conventional GNSS spoofing detectors, temporal semi-supervised learning frameworks, and the Page-Hinkley test, achieving higher detection accuracy and lower false-positive and false-negative rates for drift-evasive spoofing attacks.
<div id='section'>Paperid: <span id='pid'>209, <a href='https://arxiv.org/pdf/2506.11542.pdf' target='_blank'>https://arxiv.org/pdf/2506.11542.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Thanapat Trachu, Thanathai Lertpetchpun, Ekapol Chuangsuwanich
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.11542">Amplifying Artifacts with Speech Enhancement in Voice Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Spoofed utterances always contain artifacts introduced by generative models. While several countermeasures have been proposed to detect spoofed utterances, most primarily focus on architectural improvements. In this work, we investigate how artifacts remain hidden in spoofed speech and how to enhance their presence. We propose a model-agnostic pipeline that amplifies artifacts using speech enhancement and various types of noise. Our approach consists of three key steps: noise addition, noise extraction, and noise amplification. First, we introduce noise into the raw speech. Then, we apply speech enhancement to extract the entangled noise and artifacts. Finally, we amplify these extracted features. Moreover, our pipeline is compatible with different speech enhancement models and countermeasure architectures. Our method improves spoof detection performance by up to 44.44\% on ASVspoof2019 and 26.34\% on ASVspoof2021.
<div id='section'>Paperid: <span id='pid'>210, <a href='https://arxiv.org/pdf/2504.16362.pdf' target='_blank'>https://arxiv.org/pdf/2504.16362.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Colton R. Crum, Adam Czajka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2504.16362">Almost Right: Making First-layer Kernels Nearly Orthogonal Improves Model Generalization</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>An ongoing research challenge within several domains in computer vision is how to increase model generalization capabilities. Several attempts to improve model generalization performance are heavily inspired by human perceptual intelligence, which is remarkable in both its performance and efficiency to generalize to unknown samples. Many of these methods attempt to force portions of the network to be orthogonal, following some observation within neuroscience related to early vision processes. In this paper, we propose a loss component that regularizes the filtering kernels in the first convolutional layer of a network to make them nearly orthogonal. Deviating from previous works, we give the network flexibility in which pairs of kernels it makes orthogonal, allowing the network to navigate to a better solution space, imposing harsh penalties. Without architectural modifications, we report substantial gains in generalization performance using the proposed loss against previous works (including orthogonalization- and saliency-based regularization methods) across three different architectures (ResNet-50, DenseNet-121, ViT-b-16) and two difficult open-set recognition tasks: presentation attack detection in iris biometrics, and anomaly detection in chest X-ray images.
<div id='section'>Paperid: <span id='pid'>211, <a href='https://arxiv.org/pdf/2409.18636.pdf' target='_blank'>https://arxiv.org/pdf/2409.18636.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hailin Li, Raghavendra Ramachandra, Mohamed Ragab, Soumik Mondal, Yong Kiam Tan, Khin Mi Mi Aung
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2409.18636">Unsupervised Fingerphoto Presentation Attack Detection With Diffusion Models</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Smartphone-based contactless fingerphoto authentication has become a reliable alternative to traditional contact-based fingerprint biometric systems owing to rapid advances in smartphone camera technology. Despite its convenience, fingerprint authentication through fingerphotos is more vulnerable to presentation attacks, which has motivated recent research efforts towards developing fingerphoto Presentation Attack Detection (PAD) techniques. However, prior PAD approaches utilized supervised learning methods that require labeled training data for both bona fide and attack samples. This can suffer from two key issues, namely (i) generalization:the detection of novel presentation attack instruments (PAIs) unseen in the training data, and (ii) scalability:the collection of a large dataset of attack samples using different PAIs. To address these challenges, we propose a novel unsupervised approach based on a state-of-the-art deep-learning-based diffusion model, the Denoising Diffusion Probabilistic Model (DDPM), which is trained solely on bona fide samples. The proposed approach detects Presentation Attacks (PA) by calculating the reconstruction similarity between the input and output pairs of the DDPM. We present extensive experiments across three PAI datasets to test the accuracy and generalization capability of our approach. The results show that the proposed DDPM-based PAD method achieves significantly better detection error rates on several PAI classes compared to other baseline unsupervised approaches.
<div id='section'>Paperid: <span id='pid'>212, <a href='https://arxiv.org/pdf/2408.07675.pdf' target='_blank'>https://arxiv.org/pdf/2408.07675.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingyi Yang, Zitong Yu, Xiuming Ni, Jia He, Hui Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.07675">G$^2$V$^2$former: Graph Guided Video Vision Transformer for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In videos containing spoofed faces, we may uncover the spoofing evidence based on either photometric or dynamic abnormality, even a combination of both. Prevailing face anti-spoofing (FAS) approaches generally concentrate on the single-frame scenario, however, purely photometric-driven methods overlook the dynamic spoofing clues that may be exposed over time. This may lead FAS systems to conclude incorrect judgments, especially in cases where it is easily distinguishable in terms of dynamics but challenging to discern in terms of photometrics. To this end, we propose the Graph Guided Video Vision Transformer (G$^2$V$^2$former), which combines faces with facial landmarks for photometric and dynamic feature fusion. We factorize the attention into space and time, and fuse them via a spatiotemporal block. Specifically, we design a novel temporal attention called Kronecker temporal attention, which has a wider receptive field, and is beneficial for capturing dynamic information. Moreover, we leverage the low-semantic motion of facial landmarks to guide the high-semantic change of facial expressions based on the motivation that regions containing landmarks may reveal more dynamic clues. Extensive experiments on nine benchmark datasets demonstrate that our method achieves superior performance under various scenarios. The codes will be released soon.
<div id='section'>Paperid: <span id='pid'>213, <a href='https://arxiv.org/pdf/2407.08243.pdf' target='_blank'>https://arxiv.org/pdf/2407.08243.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jingyi Yang, Zitong Yu, Xiuming Ni, Jia He, Hui Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.08243">Generalized Face Anti-spoofing via Finer Domain Partition and Disentangling Liveness-irrelevant Factors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing techniques based on domain generalization have recently been studied widely. Adversarial learning and meta-learning techniques have been adopted to learn domain-invariant representations. However, prior approaches often consider the dataset gap as the primary factor behind domain shifts. This perspective is not fine-grained enough to reflect the intrinsic gap among the data accurately. In our work, we redefine domains based on identities rather than datasets, aiming to disentangle liveness and identity attributes. We emphasize ignoring the adverse effect of identity shift, focusing on learning identity-invariant liveness representations through orthogonalizing liveness and identity features. To cope with style shifts, we propose Style Cross module to expand the stylistic diversity and Channel-wise Style Attention module to weaken the sensitivity to style shifts, aiming to learn robust liveness representations. Furthermore, acknowledging the asymmetry between live and spoof samples, we introduce a novel contrastive loss, Asymmetric Augmented Instance Contrast. Extensive experiments on four public datasets demonstrate that our method achieves state-of-the-art performance under cross-dataset and limited source dataset scenarios. Additionally, our method has good scalability when expanding diversity of identities. The codes will be released soon.
<div id='section'>Paperid: <span id='pid'>214, <a href='https://arxiv.org/pdf/2404.06663.pdf' target='_blank'>https://arxiv.org/pdf/2404.06663.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Changsheng Chen, Yongyi Deng, Liangwei Lin, Zitong Yu, Zhimao Lai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.06663">Multi-modal Document Presentation Attack Detection With Forensics Trace Disentanglement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Document Presentation Attack Detection (DPAD) is an important measure in protecting the authenticity of a document image. However, recent DPAD methods demand additional resources, such as manual effort in collecting additional data or knowing the parameters of acquisition devices. This work proposes a DPAD method based on multi-modal disentangled traces (MMDT) without the above drawbacks. We first disentangle the recaptured traces by a self-supervised disentanglement and synthesis network to enhance the generalization capacity in document images with different contents and layouts. Then, unlike the existing DPAD approaches that rely only on data in the RGB domain, we propose to explicitly employ the disentangled recaptured traces as new modalities in the transformer backbone through adaptive multi-modal adapters to fuse RGB/trace features efficiently. Visualization of the disentangled traces confirms the effectiveness of the proposed method in different document contents. Extensive experiments on three benchmark datasets demonstrate the superiority of our MMDT method on representing forensic traces of recapturing distortion.
<div id='section'>Paperid: <span id='pid'>215, <a href='https://arxiv.org/pdf/2312.00041.pdf' target='_blank'>https://arxiv.org/pdf/2312.00041.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Justin Spencer, Deborah Lawrence, Prosenjit Chatterjee, Kaushik Roy, Albert Esterline, Jung-Hee Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.00041">Presentation Attack Detection using Convolutional Neural Networks and Local Binary Patterns</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The use of biometrics to authenticate users and control access to secure areas has become extremely popular in recent years, and biometric access control systems are frequently used by both governments and private corporations. However, these systems may represent risks to security when deployed without considering the possibility of biometric presentation attacks (also known as spoofing). Presentation attacks are a serious threat because they do not require significant time, expense, or skill to carry out while remaining effective against many biometric systems in use today. This research compares three different software-based methods for facial and iris presentation attack detection in images. The first method uses Inception-v3, a pre-trained deep Convolutional Neural Network (CNN) made by Google for the ImageNet challenge, which is retrained for this problem. The second uses a shallow CNN based on a modified Spoofnet architecture, which is trained normally. The third is a texture-based method using Local Binary Patterns (LBP). The datasets used are the ATVS-FIr dataset, which contains real and fake iris images, and the CASIA Face Anti-Spoofing Dataset, which contains real images as well as warped photos, cut photos, and video replay presentation attacks. We also present a third set of results, based on cropped versions of the CASIA images.
<div id='section'>Paperid: <span id='pid'>216, <a href='https://arxiv.org/pdf/2312.00040.pdf' target='_blank'>https://arxiv.org/pdf/2312.00040.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Prosenjit Chatterjee, Alex Yalchin, Joseph Shelton, Kaushik Roy, Xiaohong Yuan, Kossi D. Edoh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2312.00040">Presentation Attack detection using Wavelet Transform and Deep Residual Neural Net</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Biometric authentication is becoming more prevalent for secured authentication systems. However, the biometric substances can be deceived by the imposters in several ways. Among other imposter attacks, print attacks, mask attacks, and replay attacks fall under the presentation attack category. The bio-metric images, especially the iris and face, are vulnerable to different presentation attacks. This research applies deep learning approaches to mitigate presentation attacks in a biometric access control system. Our contribution in this paper is two-fold: First, we applied the wavelet transform to extract the features from the biometric images. Second, we modified the deep residual neural net and applied it to the spoof datasets in an attempt to detect the presentation attacks. This research applied the proposed approach to biometric spoof datasets, namely ATVS, CASIA two class, and CASIA cropped image sets. The datasets used in this research contain images that are captured in both a controlled and uncontrolled environment along with different resolutions and sizes. We obtained the best accuracy of 93% on the ATVS Iris datasets. For CASIA two class and CASIA cropped datasets, we achieved test accuracies of 91% and 82%, respectively.
<div id='section'>Paperid: <span id='pid'>217, <a href='https://arxiv.org/pdf/2308.10015.pdf' target='_blank'>https://arxiv.org/pdf/2308.10015.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anuj Rai, Parsheel Kumar Tiwari, Jyotishna Baishya, Ram Prakash Sharma, Somnath Dey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.10015">DyFFPAD: Dynamic Fusion of Convolutional and Handcrafted Features for Fingerprint Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic fingerprint recognition systems suffer from the threat of presentation attacks due to their wide range of deployment in areas including national borders and commercial applications. A presentation attack can be performed by creating a spoof of a user's fingerprint with or without their consent. This paper presents a dynamic ensemble of deep CNN and handcrafted features to detect presentation attacks in known-material and unknown-material protocols of the liveness detection competition. The proposed presentation attack detection model, in this way, utilizes the capabilities of both deep CNN and handcrafted features techniques and exhibits better performance than their individual performances. We have validated our proposed method on benchmark databases from the Liveness Detection Competition in 2015, 2017, and 2019, yielding overall accuracy of 96.10%, 96.49%, and 94.99% on them, respectively. The proposed method outperforms state-of-the-art methods in terms of classification accuracy.
<div id='section'>Paperid: <span id='pid'>218, <a href='https://arxiv.org/pdf/2307.01845.pdf' target='_blank'>https://arxiv.org/pdf/2307.01845.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hailin Li, Raghavendra Ramachandra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.01845">Deep Features for Contactless Fingerprint Presentation Attack Detection: Can They Be Generalized?</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rapid evolution of high-end smartphones with advanced high-resolution cameras has resulted in contactless capture of fingerprint biometrics that are more reliable and suitable for verification. Similar to other biometric systems, contactless fingerprint-verification systems are vulnerable to presentation attacks. In this paper, we present a comparative study on the generalizability of seven different pre-trained Convolutional Neural Networks (CNN) and a Vision Transformer (ViT) to reliably detect presentation attacks. Extensive experiments were carried out on publicly available smartphone-based presentation attack datasets using four different Presentation Attack Instruments (PAI). The detection performance of the eighth deep feature technique was evaluated using the leave-one-out protocol to benchmark the generalization performance for unseen PAI. The obtained results indicated the best generalization performance with the ResNet50 CNN.
<div id='section'>Paperid: <span id='pid'>219, <a href='https://arxiv.org/pdf/2306.03577.pdf' target='_blank'>https://arxiv.org/pdf/2306.03577.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anuj Rai, Ashutosh Anshul, Ashwini Jha, Prayag Jain, Ramprakash Sharma, Somnath Dey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2306.03577">An Open Patch Generator based Fingerprint Presentation Attack Detection using Generative Adversarial Network</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The low-cost, user-friendly, and convenient nature of Automatic Fingerprint Recognition Systems (AFRS) makes them suitable for a wide range of applications. This spreading use of AFRS also makes them vulnerable to various security threats. Presentation Attack (PA) or spoofing is one of the threats which is caused by presenting a spoof of a genuine fingerprint to the sensor of AFRS. Fingerprint Presentation Attack Detection (FPAD) is a countermeasure intended to protect AFRS against fake or spoof fingerprints created using various fabrication materials. In this paper, we have proposed a Convolutional Neural Network (CNN) based technique that uses a Generative Adversarial Network (GAN) to augment the dataset with spoof samples generated from the proposed Open Patch Generator (OPG). This OPG is capable of generating realistic fingerprint samples which have no resemblance to the existing spoof fingerprint samples generated with other materials. The augmented dataset is fed to the DenseNet classifier which helps in increasing the performance of the Presentation Attack Detection (PAD) module for the various real-world attacks possible with unknown spoof materials. Experimental evaluations of the proposed approach are carried out on the Liveness Detection (LivDet) 2015, 2017, and 2019 competition databases. An overall accuracy of 96.20\%, 94.97\%, and 92.90\% has been achieved on the LivDet 2015, 2017, and 2019 databases, respectively under the LivDet protocol scenarios. The performance of the proposed PAD model is also validated in the cross-material and cross-sensor attack paradigm which further exhibits its capability to be used under real-world attack scenarios.
<div id='section'>Paperid: <span id='pid'>220, <a href='https://arxiv.org/pdf/2305.17522.pdf' target='_blank'>https://arxiv.org/pdf/2305.17522.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hailin Li, Raghavendra Ramachandra
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.17522">Deep Learning based Fingerprint Presentation Attack Detection: A Comprehensive Survey</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The vulnerabilities of fingerprint authentication systems have raised security concerns when adapting them to highly secure access-control applications. Therefore, Fingerprint Presentation Attack Detection (FPAD) methods are essential for ensuring reliable fingerprint authentication. Owing to the lack of generation capacity of traditional handcrafted based approaches, deep learning-based FPAD has become mainstream and has achieved remarkable performance in the past decade. Existing reviews have focused more on hand-cratfed rather than deep learning-based methods, which are outdated. To stimulate future research, we will concentrate only on recent deep-learning-based FPAD methods. In this paper, we first briefly introduce the most common Presentation Attack Instruments (PAIs) and publicly available fingerprint Presentation Attack (PA) datasets. We then describe the existing deep-learning FPAD by categorizing them into contact, contactless, and smartphone-based approaches. Finally, we conclude the paper by discussing the open challenges at the current stage and emphasizing the potential future perspective.
<div id='section'>Paperid: <span id='pid'>221, <a href='https://arxiv.org/pdf/2305.09397.pdf' target='_blank'>https://arxiv.org/pdf/2305.09397.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anuj Rai, Somnath Dey
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.09397">EXPRESSNET: An Explainable Residual Slim Network for Fingerprint Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Presentation attack is a challenging issue that persists in the security of automatic fingerprint recognition systems. This paper proposes a novel explainable residual slim network that detects the presentation attack by representing the visual features in the input fingerprint sample. The encoder-decoder of this network along with the channel attention block converts the input sample into its heatmap representation while the modified residual convolutional neural network classifier discriminates between live and spoof fingerprints. The entire architecture of the heatmap generator block and modified ResNet classifier works together in an end-to-end manner. The performance of the proposed model is validated on benchmark liveness detection competition databases i.e. Livdet 2011, 2013, 2015, 2017, and 2019 and the classification accuracy of 96.86\%, 99.84\%, 96.45\%, 96.07\%, 96.27\% are achieved on them, respectively. The performance of the proposed model is compared with the state-of-the-art techniques, and the proposed method outperforms state-of-the-art methods in benchmark protocols of presentation attack detection in terms of classification accuracy.
<div id='section'>Paperid: <span id='pid'>222, <a href='https://arxiv.org/pdf/2303.16053.pdf' target='_blank'>https://arxiv.org/pdf/2303.16053.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Wenzheng Zeng, Yang Xiao, Sicheng Wei, Jinfang Gan, Xintao Zhang, Zhiguo Cao, Zhiwen Fang, Joey Tianyi Zhou
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.16053">Real-time Multi-person Eyeblink Detection in the Wild for Untrimmed Video</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Real-time eyeblink detection in the wild can widely serve for fatigue detection, face anti-spoofing, emotion analysis, etc. The existing research efforts generally focus on single-person cases towards trimmed video. However, multi-person scenario within untrimmed videos is also important for practical applications, which has not been well concerned yet. To address this, we shed light on this research field for the first time with essential contributions on dataset, theory, and practices. In particular, a large-scale dataset termed MPEblink that involves 686 untrimmed videos with 8748 eyeblink events is proposed under multi-person conditions. The samples are captured from unconstrained films to reveal "in the wild" characteristics. Meanwhile, a real-time multi-person eyeblink detection method is also proposed. Being different from the existing counterparts, our proposition runs in a one-stage spatio-temporal way with end-to-end learning capacity. Specifically, it simultaneously addresses the sub-tasks of face detection, face tracking, and human instance-level eyeblink detection. This paradigm holds 2 main advantages: (1) eyeblink features can be facilitated via the face's global context (e.g., head pose and illumination condition) with joint optimization and interaction, and (2) addressing these sub-tasks in parallel instead of sequential manner can save time remarkably to meet the real-time running requirement. Experiments on MPEblink verify the essential challenges of real-time multi-person eyeblink detection in the wild for untrimmed video. Our method also outperforms existing approaches by large margins and with a high inference speed.
<div id='section'>Paperid: <span id='pid'>223, <a href='https://arxiv.org/pdf/2303.01465.pdf' target='_blank'>https://arxiv.org/pdf/2303.01465.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anuj Rai, Somnath Dey, Pradeep Patidar, Prakhar Rai
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.01465">MoSFPAD: An end-to-end Ensemble of MobileNet and Support Vector Classifier for Fingerprint Presentation Attack Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Automatic fingerprint recognition systems are the most extensively used systems for person authentication although they are vulnerable to Presentation attacks. Artificial artifacts created with the help of various materials are used to deceive these systems causing a threat to the security of fingerprint-based applications. This paper proposes a novel end-to-end model to detect fingerprint Presentation attacks. The proposed model incorporates MobileNet as a feature extractor and a Support Vector Classifier as a classifier to detect presentation attacks in cross-material and cross-sensor paradigms. The feature extractor's parameters are learned with the loss generated by the support vector classifier. The proposed model eliminates the need for intermediary data preparation procedures, unlike other static hybrid architectures. The performance of the proposed model has been validated on benchmark LivDet 2011, 2013, 2015, 2017, and 2019 databases, and overall accuracy of 98.64%, 99.50%, 97.23%, 95.06%, and 95.20% is achieved on these databases, respectively. The performance of the proposed model is compared with state-of-the-art methods and the proposed method outperforms in cross-material and cross-sensor paradigms in terms of average classification error.
<div id='section'>Paperid: <span id='pid'>224, <a href='https://arxiv.org/pdf/2510.16229.pdf' target='_blank'>https://arxiv.org/pdf/2510.16229.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vienna Li, Justin Villa, Dan Diessner, Jayson Clifford, Laxima Niure Kandel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.16229">C/N0 Analysis-Based GPS Spoofing Detection with Variable Antenna Orientations</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>GPS spoofing poses a growing threat to aviation by falsifying satellite signals and misleading aircraft navigation systems. This paper demonstrates a proof-of-concept spoofing detection strategy based on analyzing satellite Carrier-to-Noise Density Ratio (C/N$_0$) variation during controlled static antenna orientations. Using a u-blox EVK-M8U receiver and a GPSG-1000 satellite simulator, C/N$_0$ data is collected under three antenna orientations flat, banked right, and banked left) in both real-sky (non-spoofed) and spoofed environments. Our findings reveal that under non-spoofed signals, C/N$_0$ values fluctuate naturally with orientation, reflecting true geometric dependencies. However, spoofed signals demonstrate a distinct pattern: the flat orientation, which directly faces the spoofing antenna, consistently yielded the highest C/N$_0$ values, while both banked orientations showed reduced C/N$_0$ due to misalignment with the spoofing source. These findings suggest that simple maneuvers such as brief banking to induce C/N$_0$ variations can provide early cues of GPS spoofing for general aviation and UAV systems.
<div id='section'>Paperid: <span id='pid'>225, <a href='https://arxiv.org/pdf/2501.02352.pdf' target='_blank'>https://arxiv.org/pdf/2501.02352.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ali Ghanbarzade, Hossein Soleimani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2501.02352">GNSS/GPS Spoofing and Jamming Identification Using Machine Learning and Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The increasing reliance on Global Navigation Satellite Systems (GNSS), particularly the Global Positioning System (GPS), underscores the urgent need to safeguard these technologies against malicious threats such as spoofing and jamming. As the backbone for positioning, navigation, and timing (PNT) across various applications including transportation, telecommunications, and emergency services GNSS is vulnerable to deliberate interference that poses significant risks. Spoofing attacks, which involve transmitting counterfeit GNSS signals to mislead receivers into calculating incorrect positions, can result in serious consequences, from navigational errors in civilian aviation to security breaches in military operations. Furthermore, the lack of inherent security measures within GNSS systems makes them attractive targets for adversaries. While GNSS/GPS jamming and spoofing systems consist of numerous components, the ability to distinguish authentic signals from malicious ones is essential for maintaining system integrity. Recent advancements in machine learning and deep learning provide promising avenues for enhancing detection and mitigation strategies against these threats. This paper addresses both spoofing and jamming by tackling real-world challenges through machine learning, deep learning, and computer vision techniques. Through extensive experiments on two real-world datasets related to spoofing and jamming detection using advanced algorithms, we achieved state of the art results. In the GNSS/GPS jamming detection task, we attained approximately 99% accuracy, improving performance by around 5% compared to previous studies. Additionally, we addressed a challenging tasks related to spoofing detection, yielding results that underscore the potential of machine learning and deep learning in this domain.
<div id='section'>Paperid: <span id='pid'>226, <a href='https://arxiv.org/pdf/2408.14829.pdf' target='_blank'>https://arxiv.org/pdf/2408.14829.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Moritz Finke, Alexandra Dmitrienko
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.14829">Time-Aware Face Anti-Spoofing with Rotation Invariant Local Binary Patterns and Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Facial recognition systems have become an integral part of the modern world. These methods accomplish the task of human identification in an automatic, fast, and non-interfering way. Past research has uncovered high vulnerability to simple imitation attacks that could lead to erroneous identification and subsequent authentication of attackers. Similar to face recognition, imitation attacks can also be detected with Machine Learning. Attack detection systems use a variety of facial features and advanced machine learning models for uncovering the presence of attacks. In this work, we assess existing work on liveness detection and propose a novel approach that promises high classification accuracy by combining previously unused features with time-aware deep learning strategies.
<div id='section'>Paperid: <span id='pid'>227, <a href='https://arxiv.org/pdf/2407.20111.pdf' target='_blank'>https://arxiv.org/pdf/2407.20111.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yikang Wang, Xingming Wang, Hiromitsu Nishizaki, Ming Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.20111">Enhancing Anti-spoofing Countermeasures Robustness through Joint Optimization and Transfer Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Current research in synthesized speech detection primarily focuses on the generalization of detection systems to unknown spoofing methods of noise-free speech. However, the performance of anti-spoofing countermeasures (CM) system is often don't work as well in more challenging scenarios, such as those involving noise and reverberation. To address the problem of enhancing the robustness of CM systems, we propose a transfer learning-based speech enhancement front-end joint optimization (TL-SEJ) method, investigating its effectiveness in improving robustness against noise and reverberation. We evaluated the proposed method's performance through a series of comparative and ablation experiments. The experimental results show that, across different signal-to-noise ratio test conditions, the proposed TL-SEJ method improves recognition accuracy by 2.7% to 15.8% compared to the baseline. Compared to conventional data augmentation methods, our system achieves an accuracy improvement ranging from 0.7% to 5.8% in various noisy conditions and from 1.7% to 2.8% under different RT60 reverberation scenarios. These experiments demonstrate that the proposed method effectively enhances system robustness in noisy and reverberant conditions.
<div id='section'>Paperid: <span id='pid'>228, <a href='https://arxiv.org/pdf/2407.05605.pdf' target='_blank'>https://arxiv.org/pdf/2407.05605.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenchun Lei, Hui Yan, Changhong Liu, Minglei Ma, Yingen Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2407.05605">Two-Path GMM-ResNet and GMM-SENet for ASV Spoofing Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The automatic speaker verification system is sometimes vulnerable to various spoofing attacks. The 2-class Gaussian Mixture Model classifier for genuine and spoofed speech is usually used as the baseline for spoofing detection. However, the GMM classifier does not separately consider the scores of feature frames on each Gaussian component. In addition, the GMM accumulates the scores on all frames independently, and does not consider their correlations. We propose the two-path GMM-ResNet and GMM-SENet models for spoofing detection, whose input is the Gaussian probability features based on two GMMs trained on genuine and spoofed speech respectively. The models consider not only the score distribution on GMM components, but also the relationship between adjacent frames. A two-step training scheme is applied to improve the system robustness. Experiments on the ASVspoof 2019 show that the LFCC+GMM-ResNet system can relatively reduce min-tDCF and EER by 76.1% and 76.3% on logical access scenario compared with the GMM, and the LFCC+GMM-SENet system by 94.4% and 95.4% on physical access scenario. After score fusion, the systems give the second-best results on both scenarios.
<div id='section'>Paperid: <span id='pid'>229, <a href='https://arxiv.org/pdf/2406.08825.pdf' target='_blank'>https://arxiv.org/pdf/2406.08825.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Menglu Li, Xiao-Ping Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.08825">Interpretable Temporal Class Activation Representation for Audio Spoofing Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Explaining the decisions made by audio spoofing detection models is crucial for fostering trust in detection outcomes. However, current research on the interpretability of detection models is limited to applying XAI tools to post-trained models. In this paper, we utilize the wav2vec 2.0 model and attentive utterance-level features to integrate interpretability directly into the model's architecture, thereby enhancing transparency of the decision-making process. Specifically, we propose a class activation representation to localize the discriminative frames contributing to detection. Furthermore, we demonstrate that multi-label training based on spoofing types, rather than binary labels as bonafide and spoofed, enables the model to learn distinct characteristics of different attacks, significantly improving detection performance. Our model achieves state-of-the-art results, with an EER of 0.51% and a min t-DCF of 0.0165 on the ASVspoof2019-LA set.
<div id='section'>Paperid: <span id='pid'>230, <a href='https://arxiv.org/pdf/2311.12773.pdf' target='_blank'>https://arxiv.org/pdf/2311.12773.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Darshika Jauhari, Renu Sharma, Cunjian Chen, Nelson Sepulveda, Arun Ross
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.12773">Iris Presentation Attack: Assessing the Impact of Combining Vanadium Dioxide Films with Artificial Eyes</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Iris recognition systems, operating in the near infrared spectrum (NIR), have demonstrated vulnerability to presentation attacks, where an adversary uses artifacts such as cosmetic contact lenses, artificial eyes or printed iris images in order to circumvent the system. At the same time, a number of effective presentation attack detection (PAD) methods have been developed. These methods have demonstrated success in detecting artificial eyes (e.g., fake Van Dyke eyes) as presentation attacks. In this work, we seek to alter the optical characteristics of artificial eyes by affixing Vanadium Dioxide (VO2) films on their surface in various spatial configurations. VO2 films can be used to selectively transmit NIR light and can, therefore, be used to regulate the amount of NIR light from the object that is captured by the iris sensor. We study the impact of such images produced by the sensor on two state-of-the-art iris PA detection methods. We observe that the addition of VO2 films on the surface of artificial eyes can cause the PA detection methods to misclassify them as bonafide eyes in some cases. This represents a vulnerability that must be systematically analyzed and effectively addressed.
<div id='section'>Paperid: <span id='pid'>231, <a href='https://arxiv.org/pdf/2310.11043.pdf' target='_blank'>https://arxiv.org/pdf/2310.11043.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Daniel Romero, Tien Ngoc Ha, Peter Gerstoft
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.11043">Spoofing Attack Detection in the Physical Layer with Robustness to User Movement</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In a spoofing attack, an attacker impersonates a legitimate user to access or modify data belonging to the latter. Typical approaches for spoofing detection in the physical layer declare an attack when a change is observed in certain channel features, such as the received signal strength (RSS) measured by spatially distributed receivers. However, since channels change over time, for example due to user movement, such approaches are impractical. To sidestep this limitation, this paper proposes a scheme that combines the decisions of a position-change detector based on a deep neural network to distinguish spoofing from movement. Building upon community detection on graphs, the sequence of received frames is partitioned into subsequences to detect concurrent transmissions from distinct locations. The scheme can be easily deployed in practice since it just involves collecting a small dataset of measurements at a few tens of locations that need not even be computed or recorded. The scheme is evaluated on real data collected for this purpose.
<div id='section'>Paperid: <span id='pid'>232, <a href='https://arxiv.org/pdf/2310.07361.pdf' target='_blank'>https://arxiv.org/pdf/2310.07361.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mateusz Michalkiewicz, Masoud Faraki, Xiang Yu, Manmohan Chandraker, Mahsa Baktashmotlagh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.07361">Domain Generalization Guided by Gradient Signal to Noise Ratio of Parameters</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Overfitting to the source domain is a common issue in gradient-based training of deep neural networks. To compensate for the over-parameterized models, numerous regularization techniques have been introduced such as those based on dropout. While these methods achieve significant improvements on classical benchmarks such as ImageNet, their performance diminishes with the introduction of domain shift in the test set i.e. when the unseen data comes from a significantly different distribution. In this paper, we move away from the classical approach of Bernoulli sampled dropout mask construction and propose to base the selection on gradient-signal-to-noise ratio (GSNR) of network's parameters. Specifically, at each training step, parameters with high GSNR will be discarded. Furthermore, we alleviate the burden of manually searching for the optimal dropout ratio by leveraging a meta-learning approach. We evaluate our method on standard domain generalization benchmarks and achieve competitive results on classification and face anti-spoofing problems.
<div id='section'>Paperid: <span id='pid'>233, <a href='https://arxiv.org/pdf/2307.01546.pdf' target='_blank'>https://arxiv.org/pdf/2307.01546.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yikang Wang, Hiromitsu Nishizaki, Ming Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.01546">Pretraining Conformer with ASR or ASV for Anti-Spoofing Countermeasure</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Finding synthetic artifacts of spoofing data will help the anti-spoofing countermeasures (CMs) system discriminate between spoofed and real speech. The Conformer combines the best of convolutional neural network and the Transformer, allowing it to aggregate global and local information. This may benefit the CM system to capture the synthetic artifacts hidden both locally and globally. In this paper, we present the transfer learning based MFA-Conformer structure for CM systems. By pre-training the Conformer encoder with different tasks, the robustness of the CM system is enhanced. The proposed method is evaluated on both Chinese and English spoofing detection databases. In the FAD clean set, proposed method achieves an EER of 0.04%, which dramatically outperforms the baseline. Our system is also comparable to the pre-training methods base on Wav2Vec 2.0. Moreover, we also provide a detailed analysis of the robustness of different models.
<div id='section'>Paperid: <span id='pid'>234, <a href='https://arxiv.org/pdf/2302.09461.pdf' target='_blank'>https://arxiv.org/pdf/2302.09461.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Youngjun Kwak, Minyoung Jung, Hunjae Yoo, JinHo Shin, Changick Kim
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.09461">Liveness score-based regression neural networks for face anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Previous anti-spoofing methods have used either pseudo maps or user-defined labels, and the performance of each approach depends on the accuracy of the third party networks generating pseudo maps and the way in which the users define the labels. In this paper, we propose a liveness score-based regression network for overcoming the dependency on third party networks and users. First, we introduce a new labeling technique, called pseudo-discretized label encoding for generating discretized labels indicating the amount of information related to real images. Secondly, we suggest the expected liveness score based on a regression network for training the difference between the proposed supervision and the expected liveness score. Finally, extensive experiments were conducted on four face anti-spoofing benchmarks to verify our proposed method on both intra-and cross-dataset tests. The experimental results show our approach outperforms previous methods.
<div id='section'>Paperid: <span id='pid'>235, <a href='https://arxiv.org/pdf/2411.17305.pdf' target='_blank'>https://arxiv.org/pdf/2411.17305.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vedrana Krivokuca Hahn, Jeremy Maceiras, Alain Komaty, Philip Abbet, Sebastien Marcel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2411.17305">in-Car Biometrics (iCarB) Datasets for Driver Recognition: Face, Fingerprint, and Voice</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present three biometric datasets (iCarB-Face, iCarB-Fingerprint, iCarB-Voice) containing face videos, fingerprint images, and voice samples, collected inside a car from 200 consenting volunteers. The data was acquired using a near-infrared camera, two fingerprint scanners, and two microphones, while the volunteers were seated in the driver's seat of the car. The data collection took place while the car was parked both indoors and outdoors, and different "noises" were added to simulate non-ideal biometric data capture that may be encountered in real-life driver recognition. Although the datasets are specifically tailored to in-vehicle biometric recognition, their utility is not limited to the automotive environment. The iCarB datasets, which are available to the research community, can be used to: (i) evaluate and benchmark face, fingerprint, and voice recognition systems (we provide several evaluation protocols); (ii) create multimodal pseudo-identities, to train/test multimodal fusion algorithms; (iii) create Presentation Attacks from the biometric data, to evaluate Presentation Attack Detection algorithms; (iv) investigate demographic and environmental biases in biometric systems, using the provided metadata. To the best of our knowledge, ours are the largest and most diverse publicly available in-vehicle biometric datasets. Most other datasets contain only one biometric modality (usually face), while our datasets consist of three modalities, all acquired in the same automotive environment. Moreover, iCarB-Fingerprint seems to be the first publicly available in-vehicle fingerprint dataset. Finally, the iCarB datasets boast a rare level of demographic diversity among the 200 data subjects, including a 50/50 gender split, skin colours across the whole Fitzpatrick-scale spectrum, and a wide age range (18-60+). So, these datasets will be valuable for advancing biometrics research.
<div id='section'>Paperid: <span id='pid'>236, <a href='https://arxiv.org/pdf/2408.15775.pdf' target='_blank'>https://arxiv.org/pdf/2408.15775.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Octavian Pascu, Dan Oneata, Horia Cucu, Nicolas M. MÃ¼ller
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.15775">Easy, Interpretable, Effective: openSMILE for voice deepfake detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, we demonstrate that attacks in the latest ASVspoof5 dataset -- a de facto standard in the field of voice authenticity and deepfake detection -- can be identified with surprising accuracy using a small subset of very simplistic features. These are derived from the openSMILE library, and are scalar-valued, easy to compute, and human interpretable. For example, attack A10`s unvoiced segments have a mean length of 0.09 +- 0.02, while bona fide instances have a mean length of 0.18 +- 0.07. Using this feature alone, a threshold classifier achieves an Equal Error Rate (EER) of 10.3% for attack A10. Similarly, across all attacks, we achieve up to 0.8% EER, with an overall EER of 15.7 +- 6.0%. We explore the generalization capabilities of these features and find that some of them transfer effectively between attacks, primarily when the attacks originate from similar Text-to-Speech (TTS) architectures. This finding may indicate that voice anti-spoofing is, in part, a problem of identifying and remembering signatures or fingerprints of individual TTS systems. This allows to better understand anti-spoofing models and their challenges in real-world application.
<div id='section'>Paperid: <span id='pid'>237, <a href='https://arxiv.org/pdf/2408.09933.pdf' target='_blank'>https://arxiv.org/pdf/2408.09933.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yuxiong Xu, Jiafeng Zhong, Sengui Zheng, Zefeng Liu, Bin Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.09933">SZU-AFS Antispoofing System for the ASVspoof 5 Challenge</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents the SZU-AFS anti-spoofing system, designed for Track 1 of the ASVspoof 5 Challenge under open conditions. The system is built with four stages: selecting a baseline model, exploring effective data augmentation (DA) methods for fine-tuning, applying a co-enhancement strategy based on gradient norm aware minimization (GAM) for secondary fine-tuning, and fusing logits scores from the two best-performing fine-tuned models. The system utilizes the Wav2Vec2 front-end feature extractor and the AASIST back-end classifier as the baseline model. During model fine-tuning, three distinct DA policies have been investigated: single-DA, random-DA, and cascade-DA. Moreover, the employed GAM-based co-enhancement strategy, designed to fine-tune the augmented model at both data and optimizer levels, helps the Adam optimizer find flatter minima, thereby boosting model generalization. Overall, the final fusion system achieves a minDCF of 0.115 and an EER of 4.04% on the evaluation set.
<div id='section'>Paperid: <span id='pid'>238, <a href='https://arxiv.org/pdf/2406.12258.pdf' target='_blank'>https://arxiv.org/pdf/2406.12258.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Hyojin Kim, Jiyoon Lee, Yonghyun Jeong, Haneol Jang, YoungJoon Yoo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.12258">Advancing Cross-Domain Generalizability in Face Anti-Spoofing: Insights, Design, and Metrics</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper presents a novel perspective for enhancing anti-spoofing performance in zero-shot data domain generalization. Unlike traditional image classification tasks, face anti-spoofing datasets display unique generalization characteristics, necessitating novel zero-shot data domain generalization. One step forward to the previous frame-wise spoofing prediction, we introduce a nuanced metric calculation that aggregates frame-level probabilities for a video-wise prediction, to tackle the gap between the reported frame-wise accuracy and instability in real-world use-case. This approach enables the quantification of bias and variance in model predictions, offering a more refined analysis of model generalization. Our investigation reveals that simply scaling up the backbone of models does not inherently improve the mentioned instability, leading us to propose an ensembled backbone method from a Bayesian perspective. The probabilistically ensembled backbone both improves model robustness measured from the proposed metric and spoofing accuracy, and also leverages the advantages of measuring uncertainty, allowing for enhanced sampling during training that contributes to model generalization across new datasets. We evaluate the proposed method from the benchmark OMIC dataset and also the public CelebA-Spoof and SiW-Mv2. Our final model outperforms existing state-of-the-art methods across the datasets, showcasing advancements in Bias, Variance, HTER, and AUC metrics.
<div id='section'>Paperid: <span id='pid'>239, <a href='https://arxiv.org/pdf/2402.17127.pdf' target='_blank'>https://arxiv.org/pdf/2402.17127.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Taein Kang, Soyul Han, Sunmook Choi, Jaejin Seo, Sanghyeok Chung, Seungeun Lee, Seungsang Oh, Il-Youp Kwak
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2402.17127">Experimental Study: Enhancing Voice Spoofing Detection Models with wav2vec 2.0</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Conventional spoofing detection systems have heavily relied on the use of handcrafted features derived from speech data. However, a notable shift has recently emerged towards the direct utilization of raw speech waveforms, as demonstrated by methods like SincNet filters. This shift underscores the demand for more sophisticated audio sample features. Moreover, the success of deep learning models, particularly those utilizing large pretrained wav2vec 2.0 as a featurization front-end, highlights the importance of refined feature encoders. In response, this research assessed the representational capability of wav2vec 2.0 as an audio feature extractor, modifying the size of its pretrained Transformer layers through two key adjustments: (1) selecting a subset of layers starting from the leftmost one and (2) fine-tuning a portion of the selected layers from the rightmost one. We complemented this analysis with five spoofing detection back-end models, with a primary focus on AASIST, enabling us to pinpoint the optimal configuration for the selection and fine-tuning process. In contrast to conventional handcrafted features, our investigation identified several spoofing detection systems that achieve state-of-the-art performance in the ASVspoof 2019 LA dataset. This comprehensive exploration offers valuable insights into feature selection strategies, advancing the field of spoofing detection.
<div id='section'>Paperid: <span id='pid'>240, <a href='https://arxiv.org/pdf/2311.11753.pdf' target='_blank'>https://arxiv.org/pdf/2311.11753.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sai Amrit Patnaik, Shivali Chansoriya, Anil K. Jain, Anoop M. Namboodiri
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2311.11753">AdvGen: Physical Adversarial Attack on Face Presentation Attack Detection Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Evaluating the risk level of adversarial images is essential for safely deploying face authentication models in the real world. Popular approaches for physical-world attacks, such as print or replay attacks, suffer from some limitations, like including physical and geometrical artifacts. Recently, adversarial attacks have gained attraction, which try to digitally deceive the learning strategy of a recognition system using slight modifications to the captured image. While most previous research assumes that the adversarial image could be digitally fed into the authentication systems, this is not always the case for systems deployed in the real world. This paper demonstrates the vulnerability of face authentication systems to adversarial images in physical world scenarios. We propose AdvGen, an automated Generative Adversarial Network, to simulate print and replay attacks and generate adversarial images that can fool state-of-the-art PADs in a physical domain attack setting. Using this attack strategy, the attack success rate goes up to 82.01%. We test AdvGen extensively on four datasets and ten state-of-the-art PADs. We also demonstrate the effectiveness of our attack by conducting experiments in a realistic, physical environment.
<div id='section'>Paperid: <span id='pid'>241, <a href='https://arxiv.org/pdf/2310.11758.pdf' target='_blank'>https://arxiv.org/pdf/2310.11758.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zong-Wei Hong, Yu-Chen Lin, Hsuan-Tung Liu, Yi-Ren Yeh, Chu-Song Chen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.11758">Domain-Generalized Face Anti-Spoofing with Unknown Attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Although face anti-spoofing (FAS) methods have achieved remarkable performance on specific domains or attack types, few studies have focused on the simultaneous presence of domain changes and unknown attacks, which is closer to real application scenarios. To handle domain-generalized unknown attacks, we introduce a new method, DGUA-FAS, which consists of a Transformer-based feature extractor and a synthetic unknown attack sample generator (SUASG). The SUASG network simulates unknown attack samples to assist the training of the feature extractor. Experimental results show that our method achieves superior performance on domain generalization FAS with known or unknown attacks.
<div id='section'>Paperid: <span id='pid'>242, <a href='https://arxiv.org/pdf/2310.05534.pdf' target='_blank'>https://arxiv.org/pdf/2310.05534.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Itshak Lapidot, Jean-Francois Bonastre
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.05534">Thech. Report: Genuinization of Speech waveform PMF for speaker detection spoofing and countermeasures</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the context of spoofing attacks in speaker recognition systems, we observed that the waveform probability mass function (PMF) of genuine speech differs significantly from the PMF of speech resulting from the attacks. This is true for synthesized or converted speech as well as replayed speech. We also noticed that this observation seems to have a significant impact on spoofing detection performance. In this article, we propose an algorithm, denoted genuinization, capable of reducing the waveform distribution gap between authentic speech and spoofing speech. Our genuinization algorithm is evaluated on ASVspoof 2019 challenge datasets, using the baseline system provided by the challenge organization. We first assess the influence of genuinization on spoofing performance. Using genuinization for the spoofing attacks degrades spoofing detection performance by up to a factor of 10. Next, we integrate the genuinization algorithm in the spoofing countermeasures and we observe a huge spoofing detection improvement in different cases. The results of our experiments show clearly that waveform distribution plays an important role and must be taken into account by anti-spoofing systems.
<div id='section'>Paperid: <span id='pid'>243, <a href='https://arxiv.org/pdf/2307.12459.pdf' target='_blank'>https://arxiv.org/pdf/2307.12459.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yunseung Lee, Youngjun Kwak, Jinho Shin
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2307.12459">Robust face anti-spoofing framework with Convolutional Vision Transformer</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Owing to the advances in image processing technology and large-scale datasets, companies have implemented facial authentication processes, thereby stimulating increased focus on face anti-spoofing (FAS) against realistic presentation attacks. Recently, various attempts have been made to improve face recognition performance using both global and local learning on face images; however, to the best of our knowledge, this is the first study to investigate whether the robustness of FAS against domain shifts is improved by considering global information and local cues in face images captured using self-attention and convolutional layers. This study proposes a convolutional vision transformer-based framework that achieves robust performance for various unseen domain data. Our model resulted in 7.3%$p$ and 12.9%$p$ increases in FAS performance compared to models using only a convolutional neural network or vision transformer, respectively. It also shows the highest average rank in sub-protocols of cross-dataset setting over the other nine benchmark models for domain generalization.
<div id='section'>Paperid: <span id='pid'>244, <a href='https://arxiv.org/pdf/2304.14509.pdf' target='_blank'>https://arxiv.org/pdf/2304.14509.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rudresh Dwivedi, Ritesh Kumar, Deepak Chopra, Pranay Kothari, Manjot Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.14509">An Efficient Ensemble Explainable AI (XAI) Approach for Morphed Face Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The extensive utilization of biometric authentication systems have emanated attackers / imposters to forge user identity based on morphed images. In this attack, a synthetic image is produced and merged with genuine. Next, the resultant image is user for authentication. Numerous deep neural convolutional architectures have been proposed in literature for face Morphing Attack Detection (MADs) to prevent such attacks and lessen the risks associated with them. Although, deep learning models achieved optimal results in terms of performance, it is difficult to understand and analyse these networks since they are black box/opaque in nature. As a consequence, incorrect judgments may be made. There is, however, a dearth of literature that explains decision-making methods of black box deep learning models for biometric Presentation Attack Detection (PADs) or MADs that can aid the biometric community to have trust in deep learning-based biometric systems for identification and authentication in various security applications such as border control, criminal database establishment etc. In this work, we present a novel visual explanation approach named Ensemble XAI integrating Saliency maps, Class Activation Maps (CAM) and Gradient-CAM (Grad-CAM) to provide a more comprehensive visual explanation for a deep learning prognostic model (EfficientNet-B1) that we have employed to predict whether the input presented to a biometric authentication system is morphed or genuine. The experimentations have been performed on three publicly available datasets namely Face Research Lab London Set, Wide Multi-Channel Presentation Attack (WMCA), and Makeup Induced Face Spoofing (MIFS). The experimental evaluations affirms that the resultant visual explanations highlight more fine-grained details of image features/areas focused by EfficientNet-B1 to reach decisions along with appropriate reasoning.
<div id='section'>Paperid: <span id='pid'>245, <a href='https://arxiv.org/pdf/2303.08514.pdf' target='_blank'>https://arxiv.org/pdf/2303.08514.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yimin Yin, Siliang He, Renye Zhang, Hongli Chang, Xu Han, Jinghua Zhang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2303.08514">Deep Learning for Iris Recognition: A Review</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Iris recognition is a secure biometric technology known for its stability and privacy. With no two irises being identical and little change throughout a person's lifetime, iris recognition is considered more reliable and less susceptible to external factors than other biometric recognition methods. Unlike traditional machine learning-based iris recognition methods, deep learning technology does not rely on feature engineering and boasts excellent performance. This paper collects 120 relevant papers to summarize the development of iris recognition based on deep learning. We first introduce the background of iris recognition and the motivation and contribution of this survey. Then, we present the common datasets widely used in iris recognition. After that, we summarize the key tasks involved in the process of iris recognition based on deep learning technology, including identification, segmentation, presentation attack detection, and localization. Finally, we discuss the challenges and potential development of iris recognition. This review provides a comprehensive sight of the research of iris recognition based on deep learning.
<div id='section'>Paperid: <span id='pid'>246, <a href='https://arxiv.org/pdf/2211.07383.pdf' target='_blank'>https://arxiv.org/pdf/2211.07383.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>M. Ibsen, C. Rathgeb, F. Brechtel, R. Klepp, K. PÃ¶ppelmann, A. George, S. Marcel, C. Busch
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2211.07383">Attacking Face Recognition with T-shirts: Database, Vulnerability Assessment and Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition systems are widely deployed for biometric authentication. Despite this, it is well-known that, without any safeguards, face recognition systems are highly vulnerable to presentation attacks. In response to this security issue, several promising methods for detecting presentation attacks have been proposed which show high performance on existing benchmarks. However, an ongoing challenge is the generalization of presentation attack detection methods to unseen and new attack types. To this end, we propose a new T-shirt Face Presentation Attack (TFPA) database of 1,608 T-shirt attacks using 100 unique presentation attack instruments. In an extensive evaluation, we show that this type of attack can compromise the security of face recognition systems and that some state-of-the-art attack detection mechanisms trained on popular benchmarks fail to robustly generalize to the new attacks. Further, we propose three new methods for detecting T-shirt attack images, one which relies on the statistical differences between depth maps of bona fide images and T-shirt attacks, an anomaly detection approach trained on features only extracted from bona fide RGB images, and a fusion approach which achieves competitive detection performance.
<div id='section'>Paperid: <span id='pid'>247, <a href='https://arxiv.org/pdf/2210.02731.pdf' target='_blank'>https://arxiv.org/pdf/2210.02731.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Yangfu Li, Xiaodan Lin, Jiaxin Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2210.02731">PSVRF: Learning to restore Pitch-Shifted Voice without reference</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Pitch scaling algorithms have a significant impact on the security of Automatic Speaker Verification (ASV) systems. Although numerous anti-spoofing algorithms have been proposed to identify the pitch-shifted voice and even restore it to the original version, they either have poor performance or require the original voice as a reference, limiting the prospects of applications. In this paper, we propose a no-reference approach termed PSVRF$^1$ for high-quality restoration of pitch-shifted voice. Experiments on AISHELL-1 and AISHELL-3 demonstrate that PSVRF can restore the voice disguised by various pitch-scaling techniques, which obviously enhances the robustness of ASV systems to pitch-scaling attacks. Furthermore, the performance of PSVRF even surpasses that of the state-of-the-art reference-based approach.
<div id='section'>Paperid: <span id='pid'>248, <a href='https://arxiv.org/pdf/2203.08972.pdf' target='_blank'>https://arxiv.org/pdf/2203.08972.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Johannes Schuiki, Michael Linortner, Georg Wimmer, Andreas Uhl
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2203.08972">Extensive Threat Analysis of Vein Attack Databases and Attack Detection by Fusion of Comparison Scores</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The last decade has brought forward many great contributions regarding presentation attack detection for the domain of finger and hand vein biometrics. Among those contributions, one is able to find a variety of different attack databases that are either private or made publicly available to the research community. However, it is not always shown whether the used attack samples hold the capability to actually deceive a realistic vein recognition system. Inspired by previous works, this study provides a systematic threat evaluation including three publicly available finger vein attack databases and one private dorsal hand vein database. To do so, 14 distinct vein recognition schemes are confronted with attack samples and the percentage of wrongly accepted attack samples is then reported as the Impostor Attack Presentation Match Rate. As a second step, comparison scores from different recognition schemes are combined using score level fusion with the goal of performing presentation attack detection.
<div id='section'>Paperid: <span id='pid'>249, <a href='https://arxiv.org/pdf/2510.25411.pdf' target='_blank'>https://arxiv.org/pdf/2510.25411.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sana Hafeez, Ghulam E Mustafa Abro, Hifza Mustafa
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.25411">Quantum-Resilient Threat Modelling for Secure RIS-Assisted ISAC in 6G UAV Corridors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The rapid deployment of unmanned aerial vehicle (UAV) corridors in sixth-generation (6G) networks requires safe, intelligence-driven integrated sensing and communications (ISAC). Reconfigurable intelligent surfaces (RIS) enhance spectrum efficiency, localisation accuracy, and situational awareness, while introducing new vulnerabilities. The rise of quantum computing increases the risks associated with harvest-now-decrypt-later strategies and quantum-enhanced spoofing. We propose a Quantum-Resilient Threat Modelling (QRTM) framework for RIS-assisted ISAC in UAV corridors to address these challenges. QRTM integrates classical, quantum-ready, and quantum-aided adversaries, countered using post-quantum cryptographic (PQC) primitives: ML-KEM for key establishment and Falcon for authentication, both embedded within RIS control signalling and UAV coordination. To strengthen security sensing, the framework introduces RIS-coded scene watermarking validated through a generalised likelihood ratio test (GLRT), with its detection probability characterised by the Marcum Q function. Furthermore, a Secure ISAC Utility (SIU) jointly optimises secrecy rate, spoofing detection, and throughput under RIS constraints, enabled by a scheduler with computational complexity of O(n^2). Monte Carlo evaluations using 3GPP Release 19 mid-band urban-canyon models (7-15 GHz) demonstrate a spoof-detection probability approaching 0.99 at a false-alarm rate of 1e-3, secrecy-rate retention exceeding 90 percent against quantum-capable adversaries, and signal-interference utilisation improvements of about 25 percent compared with baselines. These results show a standards-compliant path towards reliable, quantum-resilient ISAC for UAV corridors in smart cities and non-terrestrial networks.
<div id='section'>Paperid: <span id='pid'>250, <a href='https://arxiv.org/pdf/2510.19890.pdf' target='_blank'>https://arxiv.org/pdf/2510.19890.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jan Zelinka, Oliver Kost, Marek Hrúz
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2510.19890">Deep Sequence-to-Sequence Models for GNSS Spoofing Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>We present a data generation framework designed to simulate spoofing attacks and randomly place attack scenarios worldwide. We apply deep neural network-based models for spoofing detection, utilizing Long Short-Term Memory networks and Transformer-inspired architectures. These models are specifically designed for online detection and are trained using the generated dataset. Our results demonstrate that deep learning models can accurately distinguish spoofed signals from genuine ones, achieving high detection performance. The best results are achieved by Transformer-inspired architectures with early fusion of the inputs resulting in an error rate of 0.16%.
<div id='section'>Paperid: <span id='pid'>251, <a href='https://arxiv.org/pdf/2508.01015.pdf' target='_blank'>https://arxiv.org/pdf/2508.01015.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Byron Dowling, Jozef Probcin, Adam Czajka
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2508.01015">AutoSIGHT: Automatic Eye Tracking-based System for Immediate Grading of Human experTise</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Can we teach machines to assess the expertise of humans solving visual tasks automatically based on eye tracking features? This paper proposes AutoSIGHT, Automatic System for Immediate Grading of Human experTise, that classifies expert and non-expert performers, and builds upon an ensemble of features extracted from eye tracking data while the performers were solving a visual task. Results on the task of iris Presentation Attack Detection (PAD) used for this study show that with a small evaluation window of just 5 seconds, AutoSIGHT achieves an average average Area Under the ROC curve performance of 0.751 in subject-disjoint train-test regime, indicating that such detection is viable. Furthermore, when a larger evaluation window of up to 30 seconds is available, the Area Under the ROC curve (AUROC) increases to 0.8306, indicating the model is effectively leveraging more information at a cost of slightly delayed decisions. This work opens new areas of research on how to incorporate the automatic weighing of human and machine expertise into human-AI pairing setups, which need to react dynamically to nonstationary expertise distribution between the human and AI players (e.g. when the experts need to be replaced, or the task at hand changes rapidly). Along with this paper, we offer the eye tracking data used in this study collected from 6 experts and 53 non-experts solving iris PAD visual task.
<div id='section'>Paperid: <span id='pid'>252, <a href='https://arxiv.org/pdf/2506.17329.pdf' target='_blank'>https://arxiv.org/pdf/2506.17329.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pedro H. Lui, Lucas P. Siqueira, Juliano F. Kazienko, Vagner E. Quincozes, Silvio E. Quincozes, Daniel Welfer
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.17329">On the Performance of Cyber-Biomedical Features for Intrusion Detection in Healthcare 5.0</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Healthcare 5.0 integrates Artificial Intelligence (AI), the Internet of Things (IoT), real-time monitoring, and human-centered design toward personalized medicine and predictive diagnostics. However, the increasing reliance on interconnected medical technologies exposes them to cyber threats. Meanwhile, current AI-driven cybersecurity models often neglect biomedical data, limiting their effectiveness and interpretability. This study addresses this gap by applying eXplainable AI (XAI) to a Healthcare 5.0 dataset that integrates network traffic and biomedical sensor data. Classification outputs indicate that XGBoost achieved 99% F1-score for benign and data alteration, and 81% for spoofing. Explainability findings reveal that network data play a dominant role in intrusion detection whereas biomedical features contributed to spoofing detection, with temperature reaching a Shapley values magnitude of 0.37.
<div id='section'>Paperid: <span id='pid'>253, <a href='https://arxiv.org/pdf/2506.14116.pdf' target='_blank'>https://arxiv.org/pdf/2506.14116.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Rongyu Yu, Kan Chen, Zeyu Deng, Chen Wang, Burak Kizilkaya, Liying Emma Li
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.14116">Haptic-Based User Authentication for Tele-robotic System</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Tele-operated robots rely on real-time user behavior mapping for remote tasks, but ensuring secure authentication remains a challenge. Traditional methods, such as passwords and static biometrics, are vulnerable to spoofing and replay attacks, particularly in high-stakes, continuous interactions. This paper presents a novel anti-spoofing and anti-replay authentication approach that leverages distinctive user behavioral features extracted from haptic feedback during human-robot interactions. To evaluate our authentication approach, we collected a time-series force feedback dataset from 15 participants performing seven distinct tasks. We then developed a transformer-based deep learning model to extract temporal features from the haptic signals. By analyzing user-specific force dynamics, our method achieves over 90 percent accuracy in both user identification and task classification, demonstrating its potential for enhancing access control and identity assurance in tele-robotic systems.
<div id='section'>Paperid: <span id='pid'>254, <a href='https://arxiv.org/pdf/2506.02590.pdf' target='_blank'>https://arxiv.org/pdf/2506.02590.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Dimitrios Koutsianos, Stavros Zacharopoulos, Yannis Panagakis, Themos Stafylakis
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2506.02590">Synthetic Speech Source Tracing using Metric Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>This paper addresses source tracing in synthetic speech-identifying generative systems behind manipulated audio via speaker recognition-inspired pipelines. While prior work focuses on spoofing detection, source tracing lacks robust solutions. We evaluate two approaches: classification-based and metric-learning. We tested our methods on the MLAADv5 benchmark using ResNet and self-supervised learning (SSL) backbones. The results show that ResNet achieves competitive performance with the metric learning approach, matching and even exceeding SSL-based systems. Our work demonstrates ResNet's viability for source tracing while underscoring the need to optimize SSL representations for this task. Our work bridges speaker recognition methodologies with audio forensic challenges, offering new directions for combating synthetic media manipulation.
<div id='section'>Paperid: <span id='pid'>255, <a href='https://arxiv.org/pdf/2505.17513.pdf' target='_blank'>https://arxiv.org/pdf/2505.17513.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Binh Nguyen, Shuji Shi, Ryan Ofman, Thai Le
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2505.17513">What You Read Isn't What You Hear: Linguistic Sensitivity in Deepfake Speech Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Recent advances in text-to-speech technologies have enabled realistic voice generation, fueling audio-based deepfake attacks such as fraud and impersonation. While audio anti-spoofing systems are critical for detecting such threats, prior work has predominantly focused on acoustic-level perturbations, leaving the impact of linguistic variation largely unexplored. In this paper, we investigate the linguistic sensitivity of both open-source and commercial anti-spoofing detectors by introducing transcript-level adversarial attacks. Our extensive evaluation reveals that even minor linguistic perturbations can significantly degrade detection accuracy: attack success rates surpass 60% on several open-source detector-voice pairs, and notably one commercial detection accuracy drops from 100% on synthetic audio to just 32%. Through a comprehensive feature attribution analysis, we identify that both linguistic complexity and model-level audio embedding similarity contribute strongly to detector vulnerability. We further demonstrate the real-world risk via a case study replicating the Brad Pitt audio deepfake scam, using transcript adversarial attacks to completely bypass commercial detectors. These results highlight the need to move beyond purely acoustic defenses and account for linguistic variation in the design of robust anti-spoofing systems. All source code will be publicly available.
<div id='section'>Paperid: <span id='pid'>256, <a href='https://arxiv.org/pdf/2503.19223.pdf' target='_blank'>https://arxiv.org/pdf/2503.19223.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Najeebullah, Maaz Salman, Zar Nawab Khan Swati
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.19223">Face Spoofing Detection using Deep Learning</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Digital image spoofing has emerged as a significant security threat in biometric authentication systems, particularly those relying on facial recognition. This study evaluates the performance of three vision based models, MobileNetV2, ResNET50, and Vision Transformer, ViT, for spoof detection in image classification, utilizing a dataset of 150,986 images divided into training , 140,002, testing, 10,984, and validation ,39,574, sets. Spoof detection is critical for enhancing the security of image recognition systems, and this research compares the models effectiveness through accuracy, precision, recall, and F1 score metrics. Results reveal that MobileNetV2 outperforms other architectures on the test dataset, achieving an accuracy of 91.59%, precision of 91.72%, recall of 91.59%, and F1 score of 91.58%, compared to ViT 86.54%, 88.28%, 86.54%, and 86.39%, respectively. On the validation dataset, MobileNetV2, and ViT excel, with MobileNetV2 slightly ahead at 97.17% accuracy versus ViT 96.36%. MobileNetV2 demonstrates faster convergence during training and superior generalization to unseen data, despite both models showing signs of overfitting. These findings highlight MobileNetV2 balanced performance and robustness, making it the preferred choice for spoof detection applications where reliability on new data is essential. The study underscores the importance of model selection in security sensitive contexts and suggests MobileNetV2 as a practical solution for real world deployment.
<div id='section'>Paperid: <span id='pid'>257, <a href='https://arxiv.org/pdf/2503.05247.pdf' target='_blank'>https://arxiv.org/pdf/2503.05247.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Anudeep Vurity, Emanuela Marasco, Raghavendra Ramachandra, Jongwoo Park
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2503.05247">ColFigPhotoAttnNet: Reliable Finger Photo Presentation Attack Detection Leveraging Window-Attention on Color Spaces</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Finger photo Presentation Attack Detection (PAD) can significantly strengthen smartphone device security. However, these algorithms are trained to detect certain types of attacks. Furthermore, they are designed to operate on images acquired by specific capture devices, leading to poor generalization and a lack of robustness in handling the evolving nature of mobile hardware. The proposed investigation is the first to systematically analyze the performance degradation of existing deep learning PAD systems, convolutional and transformers, in cross-capture device settings. In this paper, we introduce the ColFigPhotoAttnNet architecture designed based on window attention on color channels, followed by the nested residual network as the predictor to achieve a reliable PAD. Extensive experiments using various capture devices, including iPhone13 Pro, GooglePixel 3, Nokia C5, and OnePlusOne, were carried out to evaluate the performance of proposed and existing methods on three publicly available databases. The findings underscore the effectiveness of our approach.
<div id='section'>Paperid: <span id='pid'>258, <a href='https://arxiv.org/pdf/2502.07403.pdf' target='_blank'>https://arxiv.org/pdf/2502.07403.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zicheng Shen, Feng Zhao, Yibo Ni, Yuanmu Yang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2502.07403">Extended monocular 3D imaging</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>3D vision is of paramount importance for numerous applications ranging from machine intelligence to precision metrology. Despite much recent progress, the majority of 3D imaging hardware remains bulky and complicated and provides much lower image resolution compared to their 2D counterparts. Moreover, there are many well-known scenarios that existing 3D imaging solutions frequently fail. Here, we introduce an extended monocular 3D imaging (EM3D) framework that fully exploits the vectorial wave nature of light. Via the multi-stage fusion of diffraction- and polarization-based depth cues, using a compact monocular camera equipped with a diffractive-refractive hybrid lens, we experimentally demonstrate the snapshot acquisition of a million-pixel and accurate 3D point cloud for extended scenes that are traditionally challenging, including those with low texture, being highly reflective, or nearly transparent, without a data prior. Furthermore, we discover that the combination of depth and polarization information can unlock unique new opportunities in material identification, which may further expand machine intelligence for applications like target recognition and face anti-spoofing. The straightforward yet powerful architecture thus opens up a new path for a higher-dimensional machine vision in a minimal form factor, facilitating the deployment of monocular cameras for applications in much more diverse scenarios.
<div id='section'>Paperid: <span id='pid'>259, <a href='https://arxiv.org/pdf/2410.24031.pdf' target='_blank'>https://arxiv.org/pdf/2410.24031.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ariel Larey, Eyal Rond, Omer Achrack
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2410.24031">A Multi-Modal Approach for Face Anti-Spoofing in Non-Calibrated Systems using Disparity Maps</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition technologies are increasingly used in various applications, yet they are vulnerable to face spoofing attacks. These spoofing attacks often involve unique 3D structures, such as printed papers or mobile device screens. Although stereo-depth cameras can detect such attacks effectively, their high-cost limits their widespread adoption. Conversely, two-sensor systems without extrinsic calibration offer a cost-effective alternative but are unable to calculate depth using stereo techniques. In this work, we propose a method to overcome this challenge by leveraging facial attributes to derive disparity information and estimate relative depth for anti-spoofing purposes, using non-calibrated systems. We introduce a multi-modal anti-spoofing model, coined Disparity Model, that incorporates created disparity maps as a third modality alongside the two original sensor modalities. We demonstrate the effectiveness of the Disparity Model in countering various spoof attacks using a comprehensive dataset collected from the Intel RealSense ID Solution F455. Our method outperformed existing methods in the literature, achieving an Equal Error Rate (EER) of 1.71% and a False Negative Rate (FNR) of 2.77% at a False Positive Rate (FPR) of 1%. These errors are lower by 2.45% and 7.94% than the errors of the best comparison method, respectively. Additionally, we introduce a model ensemble that addresses 3D spoof attacks as well, achieving an EER of 2.04% and an FNR of 3.83% at an FPR of 1%. Overall, our work provides a state-of-the-art solution for the challenging task of anti-spoofing in non-calibrated systems that lack depth information.
<div id='section'>Paperid: <span id='pid'>260, <a href='https://arxiv.org/pdf/2408.13341.pdf' target='_blank'>https://arxiv.org/pdf/2408.13341.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Zhenyu Wang, John H. L. Hansen
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.13341">Toward Improving Synthetic Audio Spoofing Detection Robustness via Meta-Learning and Disentangled Training With Adversarial Examples</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Advances in automatic speaker verification (ASV) promote research into the formulation of spoofing detection systems for real-world applications. The performance of ASV systems can be degraded severely by multiple types of spoofing attacks, namely, synthetic speech (SS), voice conversion (VC), replay, twins and impersonation, especially in the case of unseen synthetic spoofing attacks. A reliable and robust spoofing detection system can act as a security gate to filter out spoofing attacks instead of having them reach the ASV system. A weighted additive angular margin loss is proposed to address the data imbalance issue, and different margins has been assigned to improve generalization to unseen spoofing attacks in this study. Meanwhile, we incorporate a meta-learning loss function to optimize differences between the embeddings of support versus query set in order to learn a spoofing-category-independent embedding space for utterances. Furthermore, we craft adversarial examples by adding imperceptible perturbations to spoofing speech as a data augmentation strategy, then we use an auxiliary batch normalization (BN) to guarantee that corresponding normalization statistics are performed exclusively on the adversarial examples. Additionally, A simple attention module is integrated into the residual block to refine the feature extraction process. Evaluation results on the Logical Access (LA) track of the ASVspoof 2019 corpus provides confirmation of our proposed approaches' effectiveness in terms of a pooled EER of 0.87%, and a min t-DCF of 0.0277. These advancements offer effective options to reduce the impact of spoofing attacks on voice recognition/authentication systems.
<div id='section'>Paperid: <span id='pid'>261, <a href='https://arxiv.org/pdf/2408.13251.pdf' target='_blank'>https://arxiv.org/pdf/2408.13251.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Vaibhav Sundharam, Abhijit Sarkar, A. Lynn Abbott
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2408.13251">Re-evaluation of Face Anti-spoofing Algorithm in Post COVID-19 Era Using Mask Based Occlusion Attack</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face anti-spoofing algorithms play a pivotal role in the robust deployment of face recognition systems against presentation attacks. Conventionally, full facial images are required by such systems to correctly authenticate individuals, but the widespread requirement of masks due to the current COVID-19 pandemic has introduced new challenges for these biometric authentication systems. Hence, in this work, we investigate the performance of presentation attack detection (PAD) algorithms under synthetic facial occlusions using masks and glasses. We have used five variants of masks to cover the lower part of the face with varying coverage areas (low-coverage, medium-coverage, high-coverage, round coverage), and 3D cues. We have also used different variants of glasses that cover the upper part of the face. We systematically tested the performance of four PAD algorithms under these occlusion attacks using a benchmark dataset. We have specifically looked at four different baseline PAD algorithms that focus on, texture, image quality, frame difference/motion, and abstract features through a convolutional neural network (CNN). Additionally we have introduced a new hybrid model that uses CNN and local binary pattern textures. Our experiment shows that adding the occlusions significantly degrades the performance of all of the PAD algorithms. Our results show the vulnerability of face anti-spoofing algorithms with occlusions, which could be in the usage of such algorithms in the post-pandemic era.
<div id='section'>Paperid: <span id='pid'>262, <a href='https://arxiv.org/pdf/2406.13860.pdf' target='_blank'>https://arxiv.org/pdf/2406.13860.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Arman Keresh, Pakizar Shamoi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2406.13860">Liveness Detection in Computer Vision: Transformer-based Self-Supervised Learning for Face Anti-Spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition systems are increasingly used in biometric security for convenience and effectiveness. However, they remain vulnerable to spoofing attacks, where attackers use photos, videos, or masks to impersonate legitimate users. This research addresses these vulnerabilities by exploring the Vision Transformer (ViT) architecture, fine-tuned with the DINO framework. The DINO framework facilitates self-supervised learning, enabling the model to learn distinguishing features from unlabeled data. We compared the performance of the proposed fine-tuned ViT model using the DINO framework against a traditional CNN model, EfficientNet b2, on the face anti-spoofing task. Numerous tests on standard datasets show that the ViT model performs better than the CNN model in terms of accuracy and resistance to different spoofing methods. Additionally, we collected our own dataset from a biometric application to validate our findings further. This study highlights the superior performance of transformer-based architecture in identifying complex spoofing cues, leading to significant advancements in biometric security.
<div id='section'>Paperid: <span id='pid'>263, <a href='https://arxiv.org/pdf/2404.02150.pdf' target='_blank'>https://arxiv.org/pdf/2404.02150.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Pouria Rad, Gokila Dorai, Mohsen Jozani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2404.02150">From Seaweed to Security: The Emergence of Alginate in Compromising IoT Fingerprint Sensors</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The increasing integration of capacitive fingerprint recognition sensors in IoT devices presents new challenges in digital forensics, particularly in the context of advanced fingerprint spoofing. Previous research has highlighted the effectiveness of materials such as latex and silicone in deceiving biometric systems. In this study, we introduce Alginate, a biopolymer derived from brown seaweed, as a novel material with the potential for spoofing IoT-specific capacitive fingerprint sensors. Our research uses Alginate and cutting-edge image recognition techniques to unveil a nuanced IoT vulnerability that raises significant security and privacy concerns. Our proof-of-concept experiments employed authentic fingerprint molds to create Alginate replicas, which exhibited remarkable visual and tactile similarities to real fingerprints. The conductivity and resistivity properties of Alginate, closely resembling human skin, make it a subject of interest in the digital forensics field, especially regarding its ability to spoof IoT device sensors. This study calls upon the digital forensics community to develop advanced anti-spoofing strategies to protect the evolving IoT infrastructure against such sophisticated threats.
<div id='section'>Paperid: <span id='pid'>264, <a href='https://arxiv.org/pdf/2403.05380.pdf' target='_blank'>https://arxiv.org/pdf/2403.05380.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mahyar Gohari, Paolo Bestagini, Sergio Benini, Nicola Adami
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2403.05380">Spectrogram-Based Detection of Auto-Tuned Vocals in Music Recordings</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In the domain of music production and audio processing, the implementation of automatic pitch correction of the singing voice, also known as Auto-Tune, has significantly transformed the landscape of vocal performance. While auto-tuning technology has offered musicians the ability to tune their vocal pitches and achieve a desired level of precision, its use has also sparked debates regarding its impact on authenticity and artistic integrity. As a result, detecting and analyzing Auto-Tuned vocals in music recordings has become essential for music scholars, producers, and listeners. However, to the best of our knowledge, no prior effort has been made in this direction. This study introduces a data-driven approach leveraging triplet networks for the detection of Auto-Tuned songs, backed by the creation of a dataset composed of original and Auto-Tuned audio clips. The experimental results demonstrate the superiority of the proposed method in both accuracy and robustness compared to Rawnet2, an end-to-end model proposed for anti-spoofing and widely used for other audio forensic tasks.
<div id='section'>Paperid: <span id='pid'>265, <a href='https://arxiv.org/pdf/2401.05614.pdf' target='_blank'>https://arxiv.org/pdf/2401.05614.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Lian Huang, Chi-Man Pun
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2401.05614">Self-Attention and Hybrid Features for Replay and Deep-Fake Audio Detection</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Due to the successful application of deep learning, audio spoofing detection has made significant progress. Spoofed audio with speech synthesis or voice conversion can be well detected by many countermeasures. However, an automatic speaker verification system is still vulnerable to spoofing attacks such as replay or Deep-Fake audio. Deep-Fake audio means that the spoofed utterances are generated using text-to-speech (TTS) and voice conversion (VC) algorithms. Here, we propose a novel framework based on hybrid features with the self-attention mechanism. It is expected that hybrid features can be used to get more discrimination capacity. Firstly, instead of only one type of conventional feature, deep learning features and Mel-spectrogram features will be extracted by two parallel paths: convolution neural networks and a short-time Fourier transform (STFT) followed by Mel-frequency. Secondly, features will be concatenated by a max-pooling layer. Thirdly, there is a Self-attention mechanism for focusing on essential elements. Finally, ResNet and a linear layer are built to get the results. Experimental results reveal that the hybrid features, compared with conventional features, can cover more details of an utterance. We achieve the best Equal Error Rate (EER) of 9.67\% in the physical access (PA) scenario and 8.94\% in the Deep fake task on the ASVspoof 2021 dataset. Compared with the best baseline system, the proposed approach improves by 74.60\% and 60.05\%, respectively.
<div id='section'>Paperid: <span id='pid'>266, <a href='https://arxiv.org/pdf/2310.14885.pdf' target='_blank'>https://arxiv.org/pdf/2310.14885.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aneet Kumar Dutta, Sebastian Brandt, Mridula Singh
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2310.14885">Location Estimation and Recovery using 5G Positioning: Thwarting GNSS Spoofing Attacks</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The availability of cheap GNSS spoofers can prevent safe navigation and tracking of road users. It can lead to loss of assets, inaccurate fare estimation, enforcing the wrong speed limit, miscalculated toll tax, passengers reaching an incorrect location, etc. The techniques designed to prevent and detect spoofing by using cryptographic solutions or receivers capable of differentiating legitimate and attack signals are insufficient in detecting GNSS spoofing of road users. Recent studies, testbeds, and 3GPP standards are exploring the possibility of hybrid positioning, where GNSS data will be combined with the 5G-NR positioning to increase the security and accuracy of positioning. We design the Location Estimation and Recovery(LER) systems to estimate the correct absolute position using the combination of GNSS and 5G positioning with other road users, where a subset of road users can be malicious and collude to prevent spoofing detection. Our Location Verification Protocol extends the understanding of Message Time of Arrival Codes (MTAC) to prevent attacks against malicious provers. The novel Recovery and Meta Protocol uses road users' dynamic and unpredictable nature to detect GNSS spoofing. This protocol provides fast detection of GNSS spoofing with a very low rate of false positives and can be customized to a large family of settings. Even in a (highly unrealistic) worst-case scenario where each user is malicious with a probability of as large as 0.3, our protocol detects GNSS spoofing with high probability after communication and ranging with at most 20 road users, with a false positive rate close to 0. SUMO simulations for road traffic show that we can detect GNSS spoofing in 2.6 minutes since its start under moderate traffic conditions.
<div id='section'>Paperid: <span id='pid'>267, <a href='https://arxiv.org/pdf/2309.17298.pdf' target='_blank'>https://arxiv.org/pdf/2309.17298.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Ivan Yakovlev, Mikhail Melnikov, Nikita Bukhal, Rostislav Makarov, Alexander Alenin, Nikita Torgashov, Anton Okhotnikov
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.17298">LRPD: Large Replay Parallel Dataset</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The latest research in the field of voice anti-spoofing (VAS) shows that deep neural networks (DNN) outperform classic approaches like GMM in the task of presentation attack detection. However, DNNs require a lot of data to converge, and still lack generalization ability. In order to foster the progress of neural network systems, we introduce a Large Replay Parallel Dataset (LRPD) aimed for a detection of replay attacks. LRPD contains more than 1M utterances collected by 19 recording devices in 17 various environments. We also provide an example training pipeline in PyTorch [1] and a baseline system, that achieves 0.28% Equal Error Rate (EER) on evaluation subset of LRPD and 11.91% EER on publicly available ASVpoof 2017 [2] eval set. These results show that model trained with LRPD dataset has a consistent performance on the fully unknown conditions. Our dataset is free for research purposes and hosted on GDrive. Baseline code and pre-trained models are available at GitHub.
<div id='section'>Paperid: <span id='pid'>268, <a href='https://arxiv.org/pdf/2308.04765.pdf' target='_blank'>https://arxiv.org/pdf/2308.04765.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiushi Guo, Shisha Liao
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.04765">FaceSkin: A Privacy Preserving Facial skin patch Dataset for multi Attributes classification</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Human facial skin images contain abundant textural information that can serve as valuable features for attribute classification, such as age, race, and gender. Additionally, facial skin images offer the advantages of easy collection and minimal privacy concerns. However, the availability of well-labeled human skin datasets with a sufficient number of images is limited. To address this issue, we introduce a dataset called FaceSkin, which encompasses a diverse range of ages and races. Furthermore, to broaden the application scenarios, we incorporate synthetic skin-patches obtained from 2D and 3D attack images, including printed paper, replays, and 3D masks. We evaluate the FaceSkin dataset across distinct categories and present experimental results demonstrating its effectiveness in attribute classification, as well as its potential for various downstream tasks, such as Face anti-spoofing and Age estimation.
<div id='section'>Paperid: <span id='pid'>269, <a href='https://arxiv.org/pdf/2305.15518.pdf' target='_blank'>https://arxiv.org/pdf/2305.15518.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Aoi Ito, Shota Horiguchi
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2305.15518">Spoofing Attacker Also Benefits from Self-Supervised Pretrained Model</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Large-scale pretrained models using self-supervised learning have reportedly improved the performance of speech anti-spoofing. However, the attacker side may also make use of such models. Also, since it is very expensive to train such models from scratch, pretrained models on the Internet are often used, but the attacker and defender may possibly use the same pretrained model. This paper investigates whether the improvement in anti-spoofing with pretrained models holds under the condition that the models are available to attackers. As the attacker, we train a model that enhances spoofed utterances so that the speaker embedding extractor based on the pretrained models cannot distinguish between bona fide and spoofed utterances. Experimental results show that the gains the anti-spoofing models obtained by using the pretrained models almost disappear if the attacker also makes use of the pretrained models.
<div id='section'>Paperid: <span id='pid'>270, <a href='https://arxiv.org/pdf/2304.05312.pdf' target='_blank'>https://arxiv.org/pdf/2304.05312.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Riley Kiefer, Jacob Stevens, Ashok Patel
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2304.05312">Fingerprint Liveness Detection using Minutiae-Independent Dense Sampling of Local Patches</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Fingerprint recognition and matching is a common form of user authentication. While a fingerprint is unique to each individual, authentication is vulnerable when an attacker can forge a copy of the fingerprint (spoof). To combat these spoofed fingerprints, spoof detection and liveness detection algorithms are currently being researched as countermeasures to this security vulnerability. This paper introduces a fingerprint anti-spoofing mechanism using machine learning.
<div id='section'>Paperid: <span id='pid'>271, <a href='https://arxiv.org/pdf/2301.09542.pdf' target='_blank'>https://arxiv.org/pdf/2301.09542.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Sebastian Gonzalez, Juan Tapia
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2301.09542">Improving Presentation Attack Detection for ID Cards on Remote Verification Systems</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>In this paper, an updated two-stage, end-to-end Presentation Attack Detection method for remote biometric verification systems of ID cards, based on MobileNetV2, is presented. Several presentation attack species such as printed, display, composite (based on cropped and spliced areas), plastic (PVC), and synthetic ID card images using different capture sources are used. This proposal was developed using a database consisting of 190.000 real case Chilean ID card images with the support of a third-party company. Also, a new framework called PyPAD, used to estimate multi-class metrics compliant with the ISO/IEC 30107-3 standard was developed, and will be made available for research purposes. Our method is trained on two convolutional neural networks separately, reaching BPCER\textsubscript{100} scores on ID cards attacks of 1.69\% and 2.36\% respectively. The two-stage method using both models together can reach a BPCER\textsubscript{100} score of 0.92\%.
<div id='section'>Paperid: <span id='pid'>272, <a href='https://arxiv.org/pdf/2005.04513.pdf' target='_blank'>https://arxiv.org/pdf/2005.04513.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mohammad Sabouri, Sara Siamak, Maryam Dehghani, Mohsen Mohammadi, Mohammad Hassan Asemani
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2005.04513">Intelligent GPS Spoofing Attack Detection in Power Grids</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The GPS is vulnerable to GPS spoofing attack (GSA), which leads to disorder in time and position results of the GPS receiver. In power grids, phasor measurement units (PMUs) use GPS to build time-tagged measurements, so they are susceptible to this attack. As a result of this attack, sampling time and phase angle of the PMU measurements change. In this paper, a neural network GPS spoofing detection (NNGSD) with employing PMU data from the dynamic power system is presented to detect GSAs. Numerical results in different conditions show the real-time performance of the proposed detection method.
<div id='section'>Paperid: <span id='pid'>273, <a href='https://arxiv.org/pdf/2509.21601.pdf' target='_blank'>https://arxiv.org/pdf/2509.21601.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Jason Anderson
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2509.21601">World's First Authenticated Satellite Pseudorange from Orbit</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Cryptographic Ranging Authentication is here! We present initial results on the Pulsar authenticated ranging service broadcast from space with Pulsar-0 utilizing a recording taken at Xona headquarters in Burlingame, CA. No assumptions pertaining to the ownership or leakage of encryption keys are required. This work discusses the Pulsar watermark design and security analysis. We derive the Pulsar watermark's probabilities of missed detection and false alarm, and we discuss the required receiver processing needed to utilize the Pulsar watermark. We present validation results of the Pulsar watermark utilizing the transmissions from orbit. Lastly, we provide results that demonstrate the spoofing detection efficacy with a spoofing scenario that incorporates the authentic transmissions from orbit. Because we make no assumption about the leakage of symmetric encryption keys, this work provides mathematical justification of the watermark's security, and our July 2025 transmissions from orbit, we claim the world's first authenticated satellite pseudorange from orbit.
<div id='section'>Paperid: <span id='pid'>274, <a href='https://arxiv.org/pdf/2309.09485.pdf' target='_blank'>https://arxiv.org/pdf/2309.09485.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Mouxiao Huang
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2309.09485">Distributional Estimation of Data Uncertainty for Surveillance Face Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>Face recognition systems have become increasingly vulnerable to security threats in recent years, prompting the use of Face Anti-spoofing (FAS) to protect against various types of attacks, such as phone unlocking, face payment, and self-service security inspection. While FAS has demonstrated its effectiveness in traditional settings, securing it in long-distance surveillance scenarios presents a significant challenge. These scenarios often feature low-quality face images, necessitating the modeling of data uncertainty to improve stability under extreme conditions. To address this issue, this work proposes Distributional Estimation (DisE), a method that converts traditional FAS point estimation to distributional estimation by modeling data uncertainty during training, including feature (mean) and uncertainty (variance). By adjusting the learning strength of clean and noisy samples for stability and accuracy, the learned uncertainty enhances DisE's performance. The method is evaluated on SuHiFiMask [1], a large-scale and challenging FAS dataset in surveillance scenarios. Results demonstrate that DisE achieves comparable performance on both ACER and AUC metrics.
<div id='section'>Paperid: <span id='pid'>275, <a href='https://arxiv.org/pdf/2308.04798.pdf' target='_blank'>https://arxiv.org/pdf/2308.04798.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Qiushi Guo
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2308.04798">Enhancing Mobile Privacy and Security: A Face Skin Patch-Based Anti-Spoofing Approach</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>As Facial Recognition System(FRS) is widely applied in areas such as access control and mobile payments due to its convenience and high accuracy. The security of facial recognition is also highly regarded. The Face anti-spoofing system(FAS) for face recognition is an important component used to enhance the security of face recognition systems. Traditional FAS used images containing identity information to detect spoofing traces, however there is a risk of privacy leakage during the transmission and storage of these images. Besides, the encryption and decryption of these privacy-sensitive data takes too long compared to inference time by FAS model. To address the above issues, we propose a face anti-spoofing algorithm based on facial skin patches leveraging pure facial skin patch images as input, which contain no privacy information, no encryption or decryption is needed for these images. We conduct experiments on several public datasets, the results prove that our algorithm has demonstrated superiority in both accuracy and speed.
<div id='section'>Paperid: <span id='pid'>276, <a href='https://arxiv.org/pdf/2302.08674.pdf' target='_blank'>https://arxiv.org/pdf/2302.08674.pdf</a></span>  </div></span></div><div id = 'author'>Authors:<span id = 'author'>Tianyi Zheng
</span></div><div id="title">Title: <a href="https://arxiv.org/html/2302.08674">EnfoMax: Domain Entropy and Mutual Information Maximization for Domain Generalized Face Anti-spoofing</a></div></span></div><div id = 'abs'>Abstract:</br> <span id = 'abs'>The face anti-spoofing (FAS) method performs well under intra-domain setups. However, its cross-domain performance is unsatisfactory. As a result, the domain generalization (DG) method has gained more attention in FAS. Existing methods treat FAS as a simple binary classification task and propose a heuristic training objective to learn domain-invariant features. However, there is no theoretical explanation of what a domain-invariant feature is. Additionally, the lack of theoretical support makes domain generalization techniques such as adversarial training lack training stability. To address these issues, this paper proposes the EnfoMax framework, which uses information theory to analyze cross-domain FAS tasks. This framework provides theoretical guarantees and optimization objectives for domain-generalized FAS tasks. EnfoMax maximizes the domain entropy and mutual information of live samples in source domains without using adversarial learning. Experimental results demonstrate that our approach performs well on extensive public datasets and outperforms state-of-the-art methods.
